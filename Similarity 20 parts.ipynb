{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3545a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import arxiv\n",
    "\n",
    "import urllib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import fitz\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6341cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219b5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de0ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847318b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "bucket_name = \"arxiv-dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52397703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use tranfer learning\n",
    "#takes longer to load than dan\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af622944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193635\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (6,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = pd.read_csv('combined_table.csv').drop('Unnamed: 0', axis =1)\n",
    "# test = table.head() #for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ce871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_pdf_similarity(embed, tab_old, result=None, max_iter=1, r_state = 2):\n",
    "    \"\"\"\n",
    "    Wanted statistics?: number of words, similarity, number of pages, percentage of words exactly the same,\n",
    "    in = table\n",
    "    \"\"\" \n",
    "    # for each random row in table, replace=False all rows only sampled once\n",
    "    sample = tab_old.sample(n=max_iter, replace=False, random_state=r_state)\n",
    "    not_sample = tab_old.drop(sample.index)\n",
    "    \n",
    "    #download two papers from table\n",
    "    loc_name_Arxiv = 'pdf sim/Arxiv.pdf'\n",
    "    loc_name_Anth = 'pdf sim/Anth.pdf'\n",
    "    \n",
    "    #needs to be changed\n",
    "    sample[['Succes', 'w_Anth', 'w_Arxiv', 'pages_Anth', 'pages_Arxiv', 'cosine', 'ref_Anth', 'ref_Arxiv', 'Jaccard' ]] =np.nan\n",
    "    \n",
    "    \n",
    "    for index,series in sample.iterrows():\n",
    "        sample.loc[[index],['Succes']]=0\n",
    "        source_blob_name = \"arxiv/acc-phys/pdf/9411/9411001v1.pdf\"\n",
    "# destination_file_name = \"C:\\Users\\20193635\\OneDrive - TU Eindhoven\\Documents\\Data Science Year 3\\BEP\\google\"\n",
    "        destination_file_name_anth = \"pdf sim/Anth.pdf\"\n",
    "        destination_file_name_arxiv = \"pdf sim/Arxiv.pdf\"\n",
    "        \n",
    "        \n",
    "#         if True:\n",
    "        #open paper in jupiter/blocks\n",
    "        try: #sometimes download not available. Then download works but does not give a good pdf so reading does not work\n",
    "\n",
    "            source_blob_name = \"arxiv/acc-phys/pdf/9411/9411001v1.pdf\"\n",
    "            \n",
    "            \n",
    "            print('start with two papers')\n",
    "            doc_Arxiv = fitz.open(loc_name_Arxiv)\n",
    "            doc_Anth = fitz.open(loc_name_Anth)\n",
    "\n",
    "            b_Anth = get_blocks(doc_Anth)\n",
    "            b_Arxiv = get_blocks(doc_Arxiv)\n",
    "            \n",
    "            #try removing sidebar from arxiv\n",
    "            # if we DO find something\n",
    "            if [i for i, x in enumerate(b_Arxiv) if x.find('arXiv:')>= 0] !=[]:\n",
    "                i_sidebar = [i for i, x in enumerate(b_Arxiv) if x.find('arXiv:')>= 0][0]\n",
    "                if len(b_Arxiv[i_sidebar])< 50: #dont remove references by accident, normal sidebar is length 41\n",
    "                    x = b_Arxiv.pop(i_sidebar)\n",
    "#                     print(x)\n",
    "            \n",
    "            #remove footnote from anthology (could/did not remove pagenumbers)\n",
    "            if b_Anth[0][0:18] == 'Proceedings of the' and len(b_Anth[0])<150:\n",
    "                b_Anth=b_Anth[1:]\n",
    "\n",
    "#             elem_both_list = set()\n",
    "            elem_both_list = set(b_Anth)&set(b_Arxiv)\n",
    "            #sometimes same occurs twice in paper then remove this from elem_both_list\n",
    "            dup = [x for x in elem_both_list if b_Anth.count(x)>1]\n",
    "            dup = set(dup + [x for x in elem_both_list if b_Anth.count(x)>1])\n",
    "            for el in dup:\n",
    "                elem_both_list.remove(el)\n",
    "                \n",
    "        \n",
    "            #number of citations\n",
    "            if [i for i, x in enumerate(b_Anth) if x.find('References')>= 0] ==[]:\n",
    "                ref_Anth='NF'\n",
    "                ref_Arxiv='NF'\n",
    "            elif [i for i, x in enumerate(b_Anth) if x.find('References')>= 0] ==[]:\n",
    "                ref_Anth='NF'\n",
    "                ref_Arxiv='NF'\n",
    "            else:              \n",
    "                start_ref_Anth = [i for i, x in enumerate(b_Anth) if x.find('References')>= 0][0]\n",
    "                start_ref_Arxiv = [i for i, x in enumerate(b_Arxiv) if x.find('References')>= 0][0]\n",
    "                \n",
    "  \n",
    "                amount_pattern = r'(?:[1][89][0-9]{2}[^0-9]|[2][0][012][0-9][^0-9])'\n",
    "                amount_expr = re.compile(amount_pattern, re.IGNORECASE)\n",
    "                l = []\n",
    "                for i in b_Anth[start_ref_Anth:]:\n",
    "                    l+=(amount_expr.findall(i))\n",
    "                ref_Anth=len(l)\n",
    "                l = []\n",
    "                for i in b_Arxiv[start_ref_Anth:]:\n",
    "                    l+=(amount_expr.findall(i))\n",
    "                ref_Arxiv=len(l)\n",
    "                \n",
    "    \n",
    "            #similarity\n",
    "            cosine_avg, w_Anth, w_Arxiv, jacc = similarity(b_Anth,b_Arxiv,embedding=embed)\n",
    "            \n",
    "            # add statistics to table 'sample'\n",
    "            sample.loc[[index],['cosine_avg', 'w_Anth', 'w_Arxiv', 'ref_Anth', 'ref_Arxiv', 'Jaccard']]= cosine_avg, w_Anth, w_Arxiv, ref_Anth, ref_Arxiv, jacc\n",
    "            sample.loc[[index],['pages_Anth', 'pages_Arxiv']] = [doc_Anth.page_count, doc_Arxiv.page_count]\n",
    "            \n",
    "            sample.loc[[index],['Succes']]=1\n",
    "            \n",
    "\n",
    "        except: #error with downloading \n",
    "            print('Exception found some error')\n",
    "            next \n",
    "              \n",
    "        time.sleep(3)\n",
    "        \n",
    "    #end loop\n",
    "    # join tables\n",
    "    if type(result) ==pd.DataFrame:\n",
    "        sample = sample.merge(result,how='outer')\n",
    "    return not_sample, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea08d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    # The ID of your GCS object\n",
    "    # source_blob_name = \"storage-object-name\"\n",
    "\n",
    "    # The path to which the file should be downloaded\n",
    "    # destination_file_name = \"local/path/to/file\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Construct a client side representation of a blob.\n",
    "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
    "    # any content from Google Cloud Storage. As we don't need additional data,\n",
    "    # using `Bucket.blob` is preferred here.\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(\n",
    "        \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
    "            source_blob_name, bucket_name, destination_file_name\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aff24fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>address</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>language</th>\n",
       "      <th>month</th>\n",
       "      <th>note</th>\n",
       "      <th>number</th>\n",
       "      <th>pages</th>\n",
       "      <th>publisher</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>clean</th>\n",
       "      <th>title_Arxiv</th>\n",
       "      <th>pdf_url_Arxiv</th>\n",
       "      <th>published_Arxiv</th>\n",
       "      <th>result_Arxiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Proceedings of the 5th Workshop on Online Abus...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>Proceedings of the 5th Workshop on Online Abus...</td>\n",
       "      <td>NF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 5th Workshop on Online Abus...</td>\n",
       "      <td>10.18653/v1/2021.woah-1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1--5</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Exploiting Auxiliary Data for Offensive Langua...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>Exploiting Auxiliary Data for Offensive Langua...</td>\n",
       "      <td>NF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 5th Workshop on Online Abus...</td>\n",
       "      <td>10.18653/v1/2021.woah-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6--16</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Modeling Profanity and Hate Speech in Social M...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>Modeling Profanity and Hate Speech in Social M...</td>\n",
       "      <td>Modeling Profanity and Hate Speech in Social M...</td>\n",
       "      <td>http://arxiv.org/pdf/2106.07505v2</td>\n",
       "      <td>2021-06-14 15:34:37+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2106.07505v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 5th Workshop on Online Abus...</td>\n",
       "      <td>10.18653/v1/2021.woah-1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17--25</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>HateBERT: Retraining BERT for Abusive Language...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>HateBERT  Retraining BERT for Abusive Language...</td>\n",
       "      <td>HateBERT: Retraining BERT for Abusive Language...</td>\n",
       "      <td>http://arxiv.org/pdf/2010.12472v2</td>\n",
       "      <td>2020-10-23 15:14:14+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2010.12472v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 5th Workshop on Online Abus...</td>\n",
       "      <td>10.18653/v1/2021.woah-1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26--35</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>Memes in the Wild: Assessing the Generalizabil...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>Memes in the Wild  Assessing the Generalizabil...</td>\n",
       "      <td>Memes in the Wild: Assessing the Generalizabil...</td>\n",
       "      <td>http://arxiv.org/pdf/2107.04313v1</td>\n",
       "      <td>2021-07-09 09:04:05+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2107.04313v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ISBN address                                          booktitle  \\\n",
       "0  NaN  Online                                                NaN   \n",
       "1  NaN  Online  Proceedings of the 5th Workshop on Online Abus...   \n",
       "2  NaN  Online  Proceedings of the 5th Workshop on Online Abus...   \n",
       "3  NaN  Online  Proceedings of the 5th Workshop on Online Abus...   \n",
       "4  NaN  Online  Proceedings of the 5th Workshop on Online Abus...   \n",
       "\n",
       "                         doi journal language   month note  number   pages  \\\n",
       "0                        NaN     NaN      NaN  August  NaN     NaN     NaN   \n",
       "1  10.18653/v1/2021.woah-1.1     NaN      NaN  August  NaN     NaN    1--5   \n",
       "2  10.18653/v1/2021.woah-1.2     NaN      NaN  August  NaN     NaN   6--16   \n",
       "3  10.18653/v1/2021.woah-1.3     NaN      NaN  August  NaN     NaN  17--25   \n",
       "4  10.18653/v1/2021.woah-1.4     NaN      NaN  August  NaN     NaN  26--35   \n",
       "\n",
       "                                   publisher  \\\n",
       "0  Association for Computational Linguistics   \n",
       "1  Association for Computational Linguistics   \n",
       "2  Association for Computational Linguistics   \n",
       "3  Association for Computational Linguistics   \n",
       "4  Association for Computational Linguistics   \n",
       "\n",
       "                                               title  \\\n",
       "0  Proceedings of the 5th Workshop on Online Abus...   \n",
       "1  Exploiting Auxiliary Data for Offensive Langua...   \n",
       "2  Modeling Profanity and Hate Speech in Social M...   \n",
       "3  HateBERT: Retraining BERT for Abusive Language...   \n",
       "4  Memes in the Wild: Assessing the Generalizabil...   \n",
       "\n",
       "                                      url  volume  year  \\\n",
       "0  https://aclanthology.org/2021.woah-1.0     NaN  2021   \n",
       "1  https://aclanthology.org/2021.woah-1.1     NaN  2021   \n",
       "2  https://aclanthology.org/2021.woah-1.2     NaN  2021   \n",
       "3  https://aclanthology.org/2021.woah-1.3     NaN  2021   \n",
       "4  https://aclanthology.org/2021.woah-1.4     NaN  2021   \n",
       "\n",
       "                                               clean  \\\n",
       "0  Proceedings of the 5th Workshop on Online Abus...   \n",
       "1  Exploiting Auxiliary Data for Offensive Langua...   \n",
       "2  Modeling Profanity and Hate Speech in Social M...   \n",
       "3  HateBERT  Retraining BERT for Abusive Language...   \n",
       "4  Memes in the Wild  Assessing the Generalizabil...   \n",
       "\n",
       "                                         title_Arxiv  \\\n",
       "0                                                 NF   \n",
       "1                                                 NF   \n",
       "2  Modeling Profanity and Hate Speech in Social M...   \n",
       "3  HateBERT: Retraining BERT for Abusive Language...   \n",
       "4  Memes in the Wild: Assessing the Generalizabil...   \n",
       "\n",
       "                       pdf_url_Arxiv            published_Arxiv  \\\n",
       "0                                NaN                        NaN   \n",
       "1                                NaN                        NaN   \n",
       "2  http://arxiv.org/pdf/2106.07505v2  2021-06-14 15:34:37+00:00   \n",
       "3  http://arxiv.org/pdf/2010.12472v2  2020-10-23 15:14:14+00:00   \n",
       "4  http://arxiv.org/pdf/2107.04313v1  2021-07-09 09:04:05+00:00   \n",
       "\n",
       "                        result_Arxiv  \n",
       "0                                NaN  \n",
       "1                                NaN  \n",
       "2  http://arxiv.org/abs/2106.07505v2  \n",
       "3  http://arxiv.org/abs/2010.12472v2  \n",
       "4  http://arxiv.org/abs/2107.04313v1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5d8d80c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15396/2921274274.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtab2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tab' is not defined"
     ]
    }
   ],
   "source": [
    "tab2 = prepare_table(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76dbd274",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15396/133341327.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlibreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mlibreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://export.arxiv.org/api/query?search_query=all:electron&start=0&max_results=1'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    535\u001b[0m                                   '_open', req)\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "import urllib.request as libreq\n",
    "with libreq.urlopen('http://export.arxiv.org/api/query?search_query=all:electron&start=0&max_results=1') as url:\n",
    "    r = url.read()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad2c89c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15396/2226190005.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpdf_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'http://export.arxiv.org/pdf/2010.12472v1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mloc_name_Arxiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pdf sim/Arxiv.pdf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc_name_Arxiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    535\u001b[0m                                   '_open', req)\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "pdf_url = 'http://export.arxiv.org/pdf/2010.12472v1'\n",
    "loc_name_Arxiv = 'pdf sim/Arxiv.pdf'\n",
    "urllib.request.urlretrieve(pdf_url, loc_name_Arxiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2a7d6",
   "metadata": {},
   "source": [
    "# Change to export\n",
    "export.arxiv.org\n",
    "\n",
    "bursts at 4 requests per second with a 1 second sleep, per burst\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91c93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "40451aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start with two papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time taken:      16.661s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "not_sample, sample = run(embed, tab2,max_iter = 1)\n",
    "end = time.time()\n",
    "# print(\"Time taken:            {:.3f}s\".format(end - start))   \n",
    "print(\"Time taken:      {:.3f}s\".format(end - start), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "15553859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>title_Arxiv</th>\n",
       "      <th>pdf_url_Arxiv</th>\n",
       "      <th>published_Arxiv</th>\n",
       "      <th>result_Arxiv</th>\n",
       "      <th>Succes</th>\n",
       "      <th>w_Anth</th>\n",
       "      <th>w_Arxiv</th>\n",
       "      <th>pages_Anth</th>\n",
       "      <th>pages_Arxiv</th>\n",
       "      <th>cosine</th>\n",
       "      <th>ref_Anth</th>\n",
       "      <th>ref_Arxiv</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>cosine_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Measuring and Improving Model-Moderator Collab...</td>\n",
       "      <td>2021</td>\n",
       "      <td>August</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.5</td>\n",
       "      <td>Measuring and Improving Model-Moderator Collab...</td>\n",
       "      <td>http://arxiv.org/pdf/2107.04212v1</td>\n",
       "      <td>2021-07-09 05:07:25+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2107.04212v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>10017.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.977536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  year   month  \\\n",
       "5  Measuring and Improving Model-Moderator Collab...  2021  August   \n",
       "\n",
       "                                      url  \\\n",
       "5  https://aclanthology.org/2021.woah-1.5   \n",
       "\n",
       "                                         title_Arxiv  \\\n",
       "5  Measuring and Improving Model-Moderator Collab...   \n",
       "\n",
       "                       pdf_url_Arxiv            published_Arxiv  \\\n",
       "5  http://arxiv.org/pdf/2107.04212v1  2021-07-09 05:07:25+00:00   \n",
       "\n",
       "                        result_Arxiv  Succes   w_Anth  w_Arxiv  pages_Anth  \\\n",
       "5  http://arxiv.org/abs/2107.04212v1     1.0  10041.0  10017.0        18.0   \n",
       "\n",
       "   pages_Arxiv  cosine  ref_Anth  ref_Arxiv   Jaccard  cosine_avg  \n",
       "5         18.0     NaN      70.0       78.0  0.968085    0.977536  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample.columns\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f2f10",
   "metadata": {},
   "source": [
    "# test on random papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7740f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran = pd.read_csv('ran_sample.csv').drop('Unnamed: 0', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "cb626449",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pred = prepare_table(table)\n",
    "cop = table_pred.copy()\n",
    "cop = cop.reset_index()\n",
    "# ran = table_pred.head(10)#['title', 'year', 'month', 'url'] #[5:10]#['title', 'year', 'month', 'url']]\n",
    "# ran2 = table_pred.tail(10)\n",
    "ran = cop.loc[:9,['title', 'url']]\n",
    "ran2 = cop.loc[len(table_pred)-10:len(table_pred),['title_Arxiv', 'pdf_url_Arxiv', 'result_Arxiv']]\n",
    "ran2 = ran2.reset_index()\n",
    "random = ran.join(ran2)\n",
    "# random.loc[[3],['title_Arxiv', 'pdf_url_Arxiv', 'published_Arxiv', 'result_Arxiv']] = ran2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "bf84c202",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>index</th>\n",
       "      <th>title_Arxiv</th>\n",
       "      <th>pdf_url_Arxiv</th>\n",
       "      <th>result_Arxiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modeling Profanity and Hate Speech in Social M...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.2</td>\n",
       "      <td>8875</td>\n",
       "      <td>Overcoming the Curse of Sentence Length for Ne...</td>\n",
       "      <td>http://arxiv.org/pdf/1409.1257v1</td>\n",
       "      <td>http://arxiv.org/abs/1409.1257v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HateBERT: Retraining BERT for Abusive Language...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.3</td>\n",
       "      <td>8876</td>\n",
       "      <td>A Novel Two-stage Framework for Extracting Opi...</td>\n",
       "      <td>http://arxiv.org/pdf/2101.09743v1</td>\n",
       "      <td>http://arxiv.org/abs/2101.09743v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Memes in the Wild: Assessing the Generalizabil...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.4</td>\n",
       "      <td>8877</td>\n",
       "      <td>Arabic Spelling Correction using Supervised Le...</td>\n",
       "      <td>http://arxiv.org/pdf/1409.8309v1</td>\n",
       "      <td>http://arxiv.org/abs/1409.8309v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Measuring and Improving Model-Moderator Collab...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.5</td>\n",
       "      <td>8878</td>\n",
       "      <td>Arabizi Detection and Conversion to Arabic</td>\n",
       "      <td>http://arxiv.org/pdf/1306.6755v1</td>\n",
       "      <td>http://arxiv.org/abs/1306.6755v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Improving Counterfactual Generation for Fair H...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.10</td>\n",
       "      <td>8879</td>\n",
       "      <td>DiscoTK: Using Discourse Structure for Machine...</td>\n",
       "      <td>http://arxiv.org/pdf/1911.12547v1</td>\n",
       "      <td>http://arxiv.org/abs/1911.12547v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mitigating Biases in Toxic Language Detection ...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.12</td>\n",
       "      <td>8880</td>\n",
       "      <td>Credibility Adjusted Term Frequency: A Supervi...</td>\n",
       "      <td>http://arxiv.org/pdf/1405.3518v1</td>\n",
       "      <td>http://arxiv.org/abs/1405.3518v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When the Echo Chamber Shatters: Examining the ...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.18</td>\n",
       "      <td>8881</td>\n",
       "      <td>Improving Agreement and Disagreement Identific...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.05706v1</td>\n",
       "      <td>http://arxiv.org/abs/1606.05706v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Text Simplification for Comprehension-based Qu...</td>\n",
       "      <td>https://aclanthology.org/2021.wnut-1.1</td>\n",
       "      <td>8882</td>\n",
       "      <td>Finding Eyewitness Tweets During Crises</td>\n",
       "      <td>http://arxiv.org/pdf/1403.1773v1</td>\n",
       "      <td>http://arxiv.org/abs/1403.1773v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Detecting Depression in Thai Blog Posts: a Dat...</td>\n",
       "      <td>https://aclanthology.org/2021.wnut-1.3</td>\n",
       "      <td>8883</td>\n",
       "      <td>Temporal Analysis of Language through Neural L...</td>\n",
       "      <td>http://arxiv.org/pdf/1405.3515v1</td>\n",
       "      <td>http://arxiv.org/abs/1405.3515v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can images help recognize entities? A study of...</td>\n",
       "      <td>https://aclanthology.org/2021.wnut-1.11</td>\n",
       "      <td>8884</td>\n",
       "      <td>A Deep Architecture for Semantic Parsing</td>\n",
       "      <td>http://arxiv.org/pdf/1404.7296v1</td>\n",
       "      <td>http://arxiv.org/abs/1404.7296v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Modeling Profanity and Hate Speech in Social M...   \n",
       "1  HateBERT: Retraining BERT for Abusive Language...   \n",
       "2  Memes in the Wild: Assessing the Generalizabil...   \n",
       "3  Measuring and Improving Model-Moderator Collab...   \n",
       "4  Improving Counterfactual Generation for Fair H...   \n",
       "5  Mitigating Biases in Toxic Language Detection ...   \n",
       "6  When the Echo Chamber Shatters: Examining the ...   \n",
       "7  Text Simplification for Comprehension-based Qu...   \n",
       "8  Detecting Depression in Thai Blog Posts: a Dat...   \n",
       "9  Can images help recognize entities? A study of...   \n",
       "\n",
       "                                       url  index  \\\n",
       "0   https://aclanthology.org/2021.woah-1.2   8875   \n",
       "1   https://aclanthology.org/2021.woah-1.3   8876   \n",
       "2   https://aclanthology.org/2021.woah-1.4   8877   \n",
       "3   https://aclanthology.org/2021.woah-1.5   8878   \n",
       "4  https://aclanthology.org/2021.woah-1.10   8879   \n",
       "5  https://aclanthology.org/2021.woah-1.12   8880   \n",
       "6  https://aclanthology.org/2021.woah-1.18   8881   \n",
       "7   https://aclanthology.org/2021.wnut-1.1   8882   \n",
       "8   https://aclanthology.org/2021.wnut-1.3   8883   \n",
       "9  https://aclanthology.org/2021.wnut-1.11   8884   \n",
       "\n",
       "                                         title_Arxiv  \\\n",
       "0  Overcoming the Curse of Sentence Length for Ne...   \n",
       "1  A Novel Two-stage Framework for Extracting Opi...   \n",
       "2  Arabic Spelling Correction using Supervised Le...   \n",
       "3         Arabizi Detection and Conversion to Arabic   \n",
       "4  DiscoTK: Using Discourse Structure for Machine...   \n",
       "5  Credibility Adjusted Term Frequency: A Supervi...   \n",
       "6  Improving Agreement and Disagreement Identific...   \n",
       "7            Finding Eyewitness Tweets During Crises   \n",
       "8  Temporal Analysis of Language through Neural L...   \n",
       "9           A Deep Architecture for Semantic Parsing   \n",
       "\n",
       "                       pdf_url_Arxiv                       result_Arxiv  \n",
       "0   http://arxiv.org/pdf/1409.1257v1   http://arxiv.org/abs/1409.1257v2  \n",
       "1  http://arxiv.org/pdf/2101.09743v1  http://arxiv.org/abs/2101.09743v1  \n",
       "2   http://arxiv.org/pdf/1409.8309v1   http://arxiv.org/abs/1409.8309v1  \n",
       "3   http://arxiv.org/pdf/1306.6755v1   http://arxiv.org/abs/1306.6755v1  \n",
       "4  http://arxiv.org/pdf/1911.12547v1  http://arxiv.org/abs/1911.12547v1  \n",
       "5   http://arxiv.org/pdf/1405.3518v1   http://arxiv.org/abs/1405.3518v2  \n",
       "6  http://arxiv.org/pdf/1606.05706v1  http://arxiv.org/abs/1606.05706v1  \n",
       "7   http://arxiv.org/pdf/1403.1773v1   http://arxiv.org/abs/1403.1773v1  \n",
       "8   http://arxiv.org/pdf/1405.3515v1   http://arxiv.org/abs/1405.3515v1  \n",
       "9   http://arxiv.org/pdf/1404.7296v1   http://arxiv.org/abs/1404.7296v1  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f1e48990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n",
      "start with two papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time taken:      280.505s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "r_not_sample, r_sample = run(embed, random,max_iter = 10)\n",
    "end = time.time()\n",
    "# print(\"Time taken:            {:.3f}s\".format(end - start))   \n",
    "print(\"Time taken:      {:.3f}s\".format(end - start), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4440a778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>index</th>\n",
       "      <th>title_Arxiv</th>\n",
       "      <th>pdf_url_Arxiv</th>\n",
       "      <th>result_Arxiv</th>\n",
       "      <th>Succes</th>\n",
       "      <th>w_Anth</th>\n",
       "      <th>w_Arxiv</th>\n",
       "      <th>w_both</th>\n",
       "      <th>pages_Anth</th>\n",
       "      <th>pages_Arxiv</th>\n",
       "      <th>cosine</th>\n",
       "      <th>len_blocks</th>\n",
       "      <th>len_Anth</th>\n",
       "      <th>len_Arxiv</th>\n",
       "      <th>len_both</th>\n",
       "      <th>ref_Anth</th>\n",
       "      <th>ref_Arxiv</th>\n",
       "      <th>Jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Improving Counterfactual Generation for Fair H...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.10</td>\n",
       "      <td>8879</td>\n",
       "      <td>DiscoTK: Using Discourse Structure for Machine...</td>\n",
       "      <td>http://arxiv.org/pdf/1911.12547v1</td>\n",
       "      <td>http://arxiv.org/abs/1911.12547v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5436.0</td>\n",
       "      <td>4296.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.490809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.095070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HateBERT: Retraining BERT for Abusive Language...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.3</td>\n",
       "      <td>8876</td>\n",
       "      <td>A Novel Two-stage Framework for Extracting Opi...</td>\n",
       "      <td>http://arxiv.org/pdf/2101.09743v1</td>\n",
       "      <td>http://arxiv.org/abs/2101.09743v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4919.0</td>\n",
       "      <td>5728.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.492599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.106205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mitigating Biases in Toxic Language Detection ...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.12</td>\n",
       "      <td>8880</td>\n",
       "      <td>Credibility Adjusted Term Frequency: A Supervi...</td>\n",
       "      <td>http://arxiv.org/pdf/1405.3518v1</td>\n",
       "      <td>http://arxiv.org/abs/1405.3518v2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4248.0</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.393532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.096110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modeling Profanity and Hate Speech in Social M...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.2</td>\n",
       "      <td>8875</td>\n",
       "      <td>Overcoming the Curse of Sentence Length for Ne...</td>\n",
       "      <td>http://arxiv.org/pdf/1409.1257v1</td>\n",
       "      <td>http://arxiv.org/abs/1409.1257v2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7037.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.501211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.105679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Text Simplification for Comprehension-based Qu...</td>\n",
       "      <td>https://aclanthology.org/2021.wnut-1.1</td>\n",
       "      <td>8882</td>\n",
       "      <td>Finding Eyewitness Tweets During Crises</td>\n",
       "      <td>http://arxiv.org/pdf/1403.1773v1</td>\n",
       "      <td>http://arxiv.org/abs/1403.1773v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5292.0</td>\n",
       "      <td>6346.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.529852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.115042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Memes in the Wild: Assessing the Generalizabil...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.4</td>\n",
       "      <td>8877</td>\n",
       "      <td>Arabic Spelling Correction using Supervised Le...</td>\n",
       "      <td>http://arxiv.org/pdf/1409.8309v1</td>\n",
       "      <td>http://arxiv.org/abs/1409.8309v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4865.0</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.378114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.104698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Measuring and Improving Model-Moderator Collab...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.5</td>\n",
       "      <td>8878</td>\n",
       "      <td>Arabizi Detection and Conversion to Arabic</td>\n",
       "      <td>http://arxiv.org/pdf/1306.6755v1</td>\n",
       "      <td>http://arxiv.org/abs/1306.6755v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10061.0</td>\n",
       "      <td>4631.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.450464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.097291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When the Echo Chamber Shatters: Examining the ...</td>\n",
       "      <td>https://aclanthology.org/2021.woah-1.18</td>\n",
       "      <td>8881</td>\n",
       "      <td>Improving Agreement and Disagreement Identific...</td>\n",
       "      <td>http://arxiv.org/pdf/1606.05706v1</td>\n",
       "      <td>http://arxiv.org/abs/1606.05706v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8666.0</td>\n",
       "      <td>6637.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.521938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.114820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Can images help recognize entities? A study of...</td>\n",
       "      <td>https://aclanthology.org/2021.wnut-1.11</td>\n",
       "      <td>8884</td>\n",
       "      <td>A Deep Architecture for Semantic Parsing</td>\n",
       "      <td>http://arxiv.org/pdf/1404.7296v1</td>\n",
       "      <td>http://arxiv.org/abs/1404.7296v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6047.0</td>\n",
       "      <td>3070.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.120555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Detecting Depression in Thai Blog Posts: a Dat...</td>\n",
       "      <td>https://aclanthology.org/2021.wnut-1.3</td>\n",
       "      <td>8883</td>\n",
       "      <td>Temporal Analysis of Language through Neural L...</td>\n",
       "      <td>http://arxiv.org/pdf/1405.3515v1</td>\n",
       "      <td>http://arxiv.org/abs/1405.3515v1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>2732.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.326489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.110707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "4  Improving Counterfactual Generation for Fair H...   \n",
       "1  HateBERT: Retraining BERT for Abusive Language...   \n",
       "5  Mitigating Biases in Toxic Language Detection ...   \n",
       "0  Modeling Profanity and Hate Speech in Social M...   \n",
       "7  Text Simplification for Comprehension-based Qu...   \n",
       "2  Memes in the Wild: Assessing the Generalizabil...   \n",
       "3  Measuring and Improving Model-Moderator Collab...   \n",
       "6  When the Echo Chamber Shatters: Examining the ...   \n",
       "9  Can images help recognize entities? A study of...   \n",
       "8  Detecting Depression in Thai Blog Posts: a Dat...   \n",
       "\n",
       "                                       url  index  \\\n",
       "4  https://aclanthology.org/2021.woah-1.10   8879   \n",
       "1   https://aclanthology.org/2021.woah-1.3   8876   \n",
       "5  https://aclanthology.org/2021.woah-1.12   8880   \n",
       "0   https://aclanthology.org/2021.woah-1.2   8875   \n",
       "7   https://aclanthology.org/2021.wnut-1.1   8882   \n",
       "2   https://aclanthology.org/2021.woah-1.4   8877   \n",
       "3   https://aclanthology.org/2021.woah-1.5   8878   \n",
       "6  https://aclanthology.org/2021.woah-1.18   8881   \n",
       "9  https://aclanthology.org/2021.wnut-1.11   8884   \n",
       "8   https://aclanthology.org/2021.wnut-1.3   8883   \n",
       "\n",
       "                                         title_Arxiv  \\\n",
       "4  DiscoTK: Using Discourse Structure for Machine...   \n",
       "1  A Novel Two-stage Framework for Extracting Opi...   \n",
       "5  Credibility Adjusted Term Frequency: A Supervi...   \n",
       "0  Overcoming the Curse of Sentence Length for Ne...   \n",
       "7            Finding Eyewitness Tweets During Crises   \n",
       "2  Arabic Spelling Correction using Supervised Le...   \n",
       "3         Arabizi Detection and Conversion to Arabic   \n",
       "6  Improving Agreement and Disagreement Identific...   \n",
       "9           A Deep Architecture for Semantic Parsing   \n",
       "8  Temporal Analysis of Language through Neural L...   \n",
       "\n",
       "                       pdf_url_Arxiv                       result_Arxiv  \\\n",
       "4  http://arxiv.org/pdf/1911.12547v1  http://arxiv.org/abs/1911.12547v1   \n",
       "1  http://arxiv.org/pdf/2101.09743v1  http://arxiv.org/abs/2101.09743v1   \n",
       "5   http://arxiv.org/pdf/1405.3518v1   http://arxiv.org/abs/1405.3518v2   \n",
       "0   http://arxiv.org/pdf/1409.1257v1   http://arxiv.org/abs/1409.1257v2   \n",
       "7   http://arxiv.org/pdf/1403.1773v1   http://arxiv.org/abs/1403.1773v1   \n",
       "2   http://arxiv.org/pdf/1409.8309v1   http://arxiv.org/abs/1409.8309v1   \n",
       "3   http://arxiv.org/pdf/1306.6755v1   http://arxiv.org/abs/1306.6755v1   \n",
       "6  http://arxiv.org/pdf/1606.05706v1  http://arxiv.org/abs/1606.05706v1   \n",
       "9   http://arxiv.org/pdf/1404.7296v1   http://arxiv.org/abs/1404.7296v1   \n",
       "8   http://arxiv.org/pdf/1405.3515v1   http://arxiv.org/abs/1405.3515v1   \n",
       "\n",
       "   Succes   w_Anth  w_Arxiv  w_both  pages_Anth  pages_Arxiv    cosine  \\\n",
       "4     1.0   5436.0   4296.0     NaN        10.0          8.0  0.490809   \n",
       "1     1.0   4919.0   5728.0     NaN         9.0          9.0  0.492599   \n",
       "5     1.0   4248.0   2542.0     NaN         7.0          5.0  0.393532   \n",
       "0     1.0   7037.0   4359.0     NaN        11.0          7.0  0.501211   \n",
       "7     1.0   5292.0   6346.0     NaN        10.0         11.0  0.529852   \n",
       "2     1.0   4865.0   3723.0     NaN        10.0          6.0  0.378114   \n",
       "3     1.0  10061.0   4631.0     NaN        18.0          8.0  0.450464   \n",
       "6     1.0   8666.0   6637.0     NaN        15.0         10.0  0.521938   \n",
       "9     1.0   6047.0   3070.0     NaN        10.0          6.0  0.478675   \n",
       "8     1.0   3460.0   2732.0     NaN         6.0          5.0  0.326489   \n",
       "\n",
       "   len_blocks  len_Anth  len_Arxiv  len_both  ref_Anth  ref_Arxiv   Jaccard  \n",
       "4         NaN       NaN        NaN       NaN      75.0       22.0  0.095070  \n",
       "1         NaN       NaN        NaN       NaN      65.0       26.0  0.106205  \n",
       "5         NaN       NaN        NaN       NaN      36.0       22.0  0.096110  \n",
       "0         NaN       NaN        NaN       NaN      28.0       57.0  0.105679  \n",
       "7         NaN       NaN        NaN       NaN      40.0       23.0  0.115042  \n",
       "2         NaN       NaN        NaN       NaN      87.0       16.0  0.104698  \n",
       "3         NaN       NaN        NaN       NaN     405.0        3.0  0.097291  \n",
       "6         NaN       NaN        NaN       NaN      78.0       35.0  0.114820  \n",
       "9         NaN       NaN        NaN       NaN      27.0       24.0  0.120555  \n",
       "8         NaN       NaN        NaN       NaN      37.0       17.0  0.110707  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_sample #new 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
