{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3762bb55",
   "metadata": {},
   "source": [
    "# Getting both versions from arxiv and anthology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f185b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with: title, name pdf arxiv, name pdf anthology\n",
    "# time between first and official version\n",
    "# how to handle version changes in publized anthology\n",
    "# data ArXiv is specifically named in the columnnames, No mention means anthology so url and Arxiv url\n",
    "# posibillity to change naming of pdf to the same id?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5bd31c",
   "metadata": {},
   "source": [
    "look into:\n",
    "- duplicates in Athology\n",
    "- missing values, no link disregard, no date then what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38006f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.join(df2, on = 'title' how='inner')\n",
    "# df.to_csv('file1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba034a5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d32d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import arxiv\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e184b204",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16f834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_papers(quewords, Anthology = Anth):\n",
    "    \"\"\"\n",
    "    Get papers from ArXiv based on quewords\n",
    "    Merge with papers from Anthology\n",
    "    Returns joined dataframe\n",
    "    can be used as df = get_papers(quewords) or\n",
    "    df.append(get_papers(quewords))   (possibility for duplicates)\n",
    "    \"\"\"\n",
    "    query = pd.DataFrame(columns = ['title', 'pdf_url  Arxiv', 'published  Arxiv', 'result  Arxiv'])\n",
    "    i=0\n",
    "    for index, series in Anth.iterrows():\n",
    "        t = series['title'].replace('_', '').replace('-', '').replace('/', '').replace('?', '').replace('+', '')\n",
    "        search = arxiv.Search(query = \"%22\"+str(t)+\"%22\", \n",
    "                              max_results = 1,\n",
    "                              sort_by = arxiv.SortCriterion.SubmittedDate)\n",
    "        for result in search.results():\n",
    "            title = result.title.replace('_', '').replace('-', '').replace('/', '').replace('?', '').replace('+', '')\n",
    "            if title == t:\n",
    "                print(result.title)\n",
    "                i+=1\n",
    "                print(i)\n",
    "                query.loc[len(query.index)] = [result.title, result.pdf_url, result.published, result]\n",
    "    joined = query.merge(Anth, on='title')\n",
    "    \n",
    "    return joined\n",
    "\n",
    "\n",
    "def clean_title(clean):\n",
    "    \"\"\"\n",
    "    Clean title from illigal instances like ?!'\n",
    "    So it can be used to save to pdf\n",
    "    \"\"\"\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('_', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('-', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('?', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('!', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('+', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('#', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('%', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('{', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('}', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('*', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('$', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace(':', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('|', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('=', ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace(\"'\", ''),axis =1)\n",
    "    clean['title'] = clean.apply(lambda x: x['title'].replace('\"', ''),axis =1)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e796e",
   "metadata": {},
   "source": [
    "# Getting all anthology papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91d41591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Anth = pd.read_csv('anthology_table.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46db2178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74520"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Anth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0501f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anth = Anth.dropna(subset = ['month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57009c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66501"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Anth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3c054e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN         65096\n",
       "address        847\n",
       "booktitle     2546\n",
       "doi          39275\n",
       "journal      65800\n",
       "language     63473\n",
       "month            0\n",
       "note         66301\n",
       "number       66019\n",
       "pages        10150\n",
       "publisher     4110\n",
       "title            0\n",
       "url              0\n",
       "volume       66019\n",
       "year             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Anth.isnull().sum() #title,url, year all present. 8019 missing months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935f637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da276e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(df['url'][1]+'.pdf', \"pdf\\Anthology.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c64323",
   "metadata": {},
   "source": [
    "# Structure of querying parts of ArXiv papers and immediate combining with Anthology\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccebcb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "quewords = 'NLP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f46ee",
   "metadata": {},
   "source": [
    "Get papers with function get_papers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84074f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling Profanity and Hate Speech in Social Media with Semantic Subspaces\n",
      "1\n",
      "HateBERT: Retraining BERT for Abusive Language Detection in English\n",
      "2\n",
      "Memes in the Wild: Assessing the Generalizability of the Hateful Memes Challenge Dataset\n",
      "3\n",
      "Improving Counterfactual Generation for Fair Hate Speech Detection\n",
      "4\n",
      "Mitigating Biases in Toxic Language Detection through Invariant Rationalization\n",
      "5\n",
      "Detecting Depression in Thai Blog Posts: a Dataset and a Baseline\n",
      "6\n",
      "Can images help recognize entities? A study of the role of images for Multimodal NER\n",
      "7\n",
      "Perceived and Intended Sarcasm Detection with Graph Attention Networks\n",
      "8\n",
      "Hierarchical Character Tagger for Short Text Spelling Error Correction\n",
      "9\n",
      "PoliWAM: An Exploration of a Large Scale Corpus of Political Discussions on WhatsApp Messenger\n",
      "10\n",
      "Improving Punctuation Restoration for Speech Transcripts via External Data\n",
      "11\n",
      "Learning to Rank Question Answer Pairs with Bilateral Contrastive Data Augmentation\n",
      "12\n",
      "Mitigation of Diachronic Bias in Fake News Detection Dataset\n",
      "13\n",
      "Understanding the Impact of UGC Specificities on Translation Quality\n",
      "14\n",
      "Changes in Twitter geolocations: Insights and suggestions for future usage\n",
      "15\n",
      "NADE: A Benchmark for Robust Adverse Drug Events Extraction in Face of Negations\n",
      "16\n",
      "Knowledge Distillation with Noisy Labels for Natural Language Understanding\n",
      "17\n",
      "Robustness and Sensitivity of BERT Models Predicting Alzheimer's Disease from Text\n",
      "18\n",
      "Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction\n",
      "19\n",
      "WeChat Neural Machine Translation Systems for WMT21\n",
      "20\n",
      "The NiuTrans Machine Translation Systems for WMT21\n",
      "21\n",
      "Improving Similar Language Translation With Transfer Learning\n",
      "22\n",
      "MMTAfrica: Multilingual Machine Translation for African Languages\n",
      "23\n",
      "Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task\n",
      "24\n",
      "To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for Machine Translation\n",
      "25\n",
      "Evaluating Multiway Multilingual NMT in the Turkic Languages\n",
      "26\n",
      "Extending Challenge Sets to Uncover Gender Bias in Machine Translation: Impact of Stereotypical Verbs and Adjectives\n",
      "27\n",
      "Multilingual Domain Adaptation for NMT: Decoupling Language and Domain Information with Adapters\n",
      "28\n",
      "Translation Transformers Rediscover Inherent Data Domains\n",
      "29\n",
      "Pushing the Right Buttons: Adversarial Evaluation of Quality Estimation\n",
      "30\n",
      "QEMind: Alibaba's Submission to the WMT21 Quality Estimation Shared Task\n",
      "31\n",
      "Regressive Ensemble for Machine Translation Quality Evaluation\n",
      "32\n",
      "Learning Feature Weights using Reward Modeling for Denoising Parallel Corpora\n",
      "33\n",
      "Simultaneous Neural Machine Translation with Constituent Label Prediction\n",
      "34\n",
      "TEET! Tunisian Dataset for Toxic Speech Detection\n",
      "35\n",
      "Input Augmentation Improves Constrained Beam Search for Neural Machine Translation: NTT at WAT 2021\n",
      "36\n",
      "ToxCCIn: Toxic Content Classification with Interpretability\n",
      "37\n",
      "Emotion Ratings: How Intensity, Annotation Confidence and Agreements are Entangled\n",
      "38\n",
      "Analyzing Curriculum Learning for Sentiment Analysis along Task Difficulty, Pacing and Visualization Axes\n",
      "39\n",
      "Hate Towards the Political Opponent: A Twitter Corpus Study of the 2020 US Elections on the Basis of Offensive Speech and Stance Detection\n",
      "40\n",
      "Nearest neighbour approaches for Emotion Detection in Tweets\n",
      "41\n",
      "DiaLex: A Benchmark for Evaluating Multidialectal Arabic Word Embeddings\n",
      "42\n",
      "Automatic Difficulty Classification of Arabic Sentences\n",
      "43\n",
      "Arabic Offensive Language on Twitter: Analysis and Experiments\n",
      "44\n",
      "Empathetic BERT2BERT Conversational Model: Learning Arabic Language Generation with Little Data\n",
      "45\n",
      "Automatic Romanization of Arabic Bibliographic Records\n",
      "46\n",
      "NADI 2021: The Second Nuanced Arabic Dialect Identification Shared Task\n",
      "47\n",
      "Adapting MARBERT for Improved Arabic Dialect Identification: Submission to the NADI 2021 Shared Task\n",
      "48\n",
      "Dialect Identification in Nuanced Arabic Tweets Using Farasa Segmentation and AraBERT\n",
      "49\n",
      "AraBERT and Farasa Segmentation Based Approach For Sarcasm and Sentiment Detection in Arabic Tweets\n",
      "50\n",
      "Hierarchical Transformer for Multilingual Machine Translation\n",
      "51\n",
      "Representations of Language Varieties Are Reliable Given Corpus Similarity Measures\n",
      "52\n",
      "Discriminating Between Similar Nordic Languages\n",
      "53\n",
      "UnibucKernel: Geolocating Swiss German Jodels Using Ensemble Learning\n",
      "54\n",
      "Comparing Approaches to Dravidian Language Identification\n",
      "55\n",
      "Let's be explicit about that: Distant supervision for implicit discourse relation classification via connective prediction\n",
      "56\n",
      "Improvements and Extensions on Metaphor Detection\n",
      "57\n",
      "For the Purpose of Curry: A UD Treebank for Ashokan Prakrit\n",
      "58\n",
      "Accountable Error Characterization\n",
      "59\n",
      "Towards Benchmarking the Utility of Explanations for Model Debugging\n",
      "60\n",
      "How Universal is Genre in Universal Dependencies?\n",
      "61\n",
      "Parsing with Pretrained Language Models, Multiple Datasets, and Dataset Embeddings\n",
      "62\n",
      "Modeling Graph Structure via Relative Position for Text Generation from Knowledge Graphs\n",
      "63\n",
      "On Geodesic Distances and Contextual Embedding Compression for Text Classification\n",
      "64\n",
      "Teaching a Massive Open Online Course on Natural Language Processing\n",
      "65\n",
      "Natural Language Processing 4 All (NLP4All): A New Online Platform for Teaching and Learning NLP Concepts\n",
      "66\n",
      "Applied Language Technology: NLP for the Humanities\n",
      "67\n",
      "A dissemination workshop for introducing young Italian students to NLP\n",
      "68\n",
      "The Flipped Classroom model for teaching Conditional Random Fields in an NLP course\n",
      "69\n",
      "Introducing Information Retrieval for Biomedical Informatics Students\n",
      "70\n",
      "The Online Pivot: Lessons Learned from Teaching a Text and Data Mining Course in Lockdown, Enhancing online Teaching with Pair Programming and Digital Badges\n",
      "71\n",
      "Teaching NLP outside Linguistics and Computer Science classrooms: Some challenges and some opportunities\n",
      "72\n",
      "Teaching NLP with Bracelets and Restaurant Menus: An Interactive Workshop for Italian Students\n",
      "73\n",
      "Semantic Categorization of Social Knowledge for Commonsense Question Answering\n",
      "74\n",
      "Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing\n",
      "75\n",
      "Shrinking Bigfoot: Reducing wav2vec 2.0 footprint\n",
      "76\n",
      "Efficient Domain Adaptation of Language Models via Adaptive Tokenization\n",
      "77\n",
      "Unsupervised Contextualized Document Representation\n",
      "78\n",
      "Did the Cat Drink the Coffee? Challenging Transformers with Generalized Event Knowledge\n",
      "79\n",
      "Can Transformer Language Models Predict Psychometric Properties?\n",
      "80\n",
      "Generating Hypothetical Events for Abductive Inference\n",
      "81\n",
      "NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning\n",
      "82\n",
      "Toward Diverse Precondition Generation\n",
      "83\n",
      "Overcoming Poor Word Embeddings with Word Definitions\n",
      "84\n",
      "Denoising Word Embeddings by Averaging in a Shared Space\n",
      "85\n",
      "Adversarial Training for Machine Reading Comprehension with Virtual Embeddings\n",
      "86\n",
      "RewardsOfSum: Exploring Reinforcement Learning Rewards for Summarisation\n",
      "87\n",
      "Learning compositional structures for semantic graph parsing\n",
      "88\n",
      "Mode recovery in neural autoregressive sequence modeling\n",
      "89\n",
      "A Globally Normalized Neural Model for Semantic Parsing\n",
      "90\n",
      "Towards Navigation by Reasoning over Spatial Configurations\n",
      "91\n",
      "Evaluating Deception Detection Model Robustness To Linguistic Variation\n",
      "92\n",
      "PANDORA Talks: Personality and Demographics on Reddit\n",
      "93\n",
      "Room to Grow: Understanding Personal Characteristics Behind Self Improvement Using Social Media\n",
      "94\n",
      "BERT based Transformers lead the way in Extraction of Health Information from Social Media\n",
      "95\n",
      "Neural Text Classification and Stacked Heterogeneous Embeddings for Named Entity Recognition in SMM4H 2021\n",
      "96\n",
      "OTEANN: Estimating the Transparency of Orthographies with an Artificial Neural Network\n",
      "97\n",
      "Morph Call: Probing Morphosyntactic Content of Multilingual Transformers\n",
      "98\n",
      "SIGTYP 2021 Shared Task: Robust Spoken Language Identification\n",
      "99\n",
      "ARTA: Collection and Classification of Ambiguous Requests and Thoughtful Actions\n",
      "100\n",
      "CIDER: Commonsense Inference for Dialogue Explanation and Reasoning\n",
      "101\n",
      "Annotation Inconsistency and Entity Bias in MultiWOZ\n",
      "102\n",
      "How Should Agents Ask Questions For Situated Learning? An Annotated Dialogue Corpus\n",
      "103\n",
      "A Brief Study on the Effects of Training Generative Dialogue Models with a Semantic loss\n",
      "104\n",
      "Conversational Negation using Worldly Context in Compositional Distributional Semantics\n",
      "105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should Semantic Vector Composition be Explicit? Can it be Linear?\n",
      "106\n",
      "Determining the Credibility of Science Communication\n",
      "107\n",
      "Unsupervised Document Expansion for Information Retrieval with Stochastic Text Generation\n",
      "108\n",
      "Extractive Research Slide Generation Using Windowed Labeling Ranking\n",
      "109\n",
      "Multitask Learning for Citation Purpose Classification\n",
      "110\n",
      "Tuiteamos o pongamos un tuit? Investigating the Social Constraints of Loanword Integration in Spanish Social Media\n",
      "111\n",
      "Pragmatically Informative Color Generation by Grounding Contextual Modifiers\n",
      "112\n",
      "Supersense and Sensibility: Proxy Tasks for Semantic Annotation of Prepositions\n",
      "113\n",
      "Will it Unblend?\n",
      "114\n",
      "Probing Multilingual Language Models for Discourse\n",
      "115\n",
      "Comprehension Based Question Answering using Bloom's Taxonomy\n",
      "116\n",
      "Learning Sparse Sentence Encoding without Supervision: An Exploration of Sparsity in Variational Autoencoders\n",
      "117\n",
      "Knodle: Modular Weakly Supervised Learning with PyTorch\n",
      "118\n",
      "Unsupervised Representation Disentanglement of Text: An Evaluation on Synthetic Datasets\n",
      "119\n",
      "Predicting the Success of Domain Adaptation in Text Similarity\n",
      "120\n",
      "Deriving Contextualised Semantic Features from BERT (and Other Transformer Model) Embeddings\n",
      "121\n",
      "Syntactic Perturbations Reveal Representational Correlates of Hierarchical Phrase Structure in Pretrained Language Models\n",
      "122\n",
      "Scaling Deep Contrastive Learning Batch Size under Memory Limited Setup\n",
      "123\n",
      "Direction is what you need: Improving Word Embedding Compression in Large Language Models\n",
      "124\n",
      "On the Evolution of Word Order\n",
      "125\n",
      "PyEuroVoc: A Tool for Multilingual Legal Document Classification with EuroVoc Descriptors\n",
      "126\n",
      "A Dynamic Head Importance Computation Mechanism for Neural Machine Translation\n",
      "127\n",
      "SocialVisTUM: An Interactive Visualization Toolkit for Correlated Neural Topic Models on Social Media Opinion Mining\n",
      "128\n",
      "BERT Embeddings for Automatic Readability Assessment\n",
      "129\n",
      "System Combination for Grammatical Error Correction Based on Integer Programming\n",
      "130\n",
      "NEREL: A Russian Dataset with Nested Named Entities, Relations and Events\n",
      "131\n",
      "A Hierarchical Entity Graph Convolutional Network for Relation Extraction across Documents\n",
      "132\n",
      "One Size Does Not Fit All: Finding the Optimal Subword Sizes for FastText Models across Languages\n",
      "133\n",
      "Multilingual Coreference Resolution with Harmonized Annotations\n",
      "134\n",
      "Are the Multilingual Models Better? Improving Czech Sentiment with Transformers\n",
      "135\n",
      "Metric Learning in Multilingual Sentence Similarity Measurement for Document Alignment\n",
      "136\n",
      "Opinion Prediction with User Fingerprinting\n",
      "137\n",
      "Recognizing and Splitting Conditional Sentences for Automation of Business Processes Management\n",
      "138\n",
      "Sentence Structure and Word Relationship Modeling for Emphasis Selection\n",
      "139\n",
      "Interpretable Propaganda Detection in News Articles\n",
      "140\n",
      "Dependency distance minimization predicts compression\n",
      "141\n",
      "On a Utilitarian Approach to Privacy Preserving Text Generation\n",
      "142\n",
      "Hierarchical Encoders for Modeling and Interpreting Screenplays\n",
      "143\n",
      "Learning Similarity between Movie Characters and Its Potential Implications on Understanding Human Experiences\n",
      "144\n",
      "Automatic Story Generation: Challenges and Attempts\n",
      "145\n",
      "Fabula Entropy Indexing: Objective Measures of Story Coherence\n",
      "146\n",
      "Operationalizing a National Digital Library: The Case for a Norwegian Transformer Model\n",
      "147\n",
      "Neural Morphology Dataset and Models for Multiple Languages, from the Large to the Endangered\n",
      "148\n",
      "SuperSim: a test set for word similarity and relatedness in Swedish\n",
      "149\n",
      "NLI Data Sanity Check: Assessing the Effect of Data Corruption on Model Performance\n",
      "150\n",
      "What Taggers Fail to Learn, Parsers Need the Most\n",
      "151\n",
      "Should we Stop Training More Monolingual Models, and Simply Use Machine Translation Instead?\n",
      "152\n",
      "Grammatical Error Generation Based on Translated Fragments\n",
      "153\n",
      "NorDial: A Preliminary Corpus of Written Norwegian Dialect Use\n",
      "154\n",
      "Reading StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation\n",
      "155\n",
      "Identifying Automatically Generated Headlines using Transformers\n",
      "156\n",
      "Never guess what I heard... Rumor Detection in Finnish News: a Dataset and a Baseline\n",
      "157\n",
      "Overcoming Conflicting Data when Updating a Neural Semantic Parser\n",
      "158\n",
      "Amendable Generation for Dialogue State Tracking\n",
      "159\n",
      "XPersona: Evaluating Multilingual Personalized Chatbot\n",
      "160\n",
      "Improving Dialogue State Tracking by Joint Slot Modeling\n",
      "161\n",
      "Using Pause Information for More Accurate Entity Recognition\n",
      "162\n",
      "Teach Me What to Say and I Will Learn What to Pick: Unsupervised Knowledge Selection Through Response Generation with Pretrained Generative Models\n",
      "163\n",
      "Automated Extraction of Sentencing Decisions from Court Cases in the Hebrew Language\n",
      "164\n",
      "Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser\n",
      "165\n",
      "Evaluation of Summarization Systems across Gender, Age, and Race\n",
      "166\n",
      "Evaluation of Abstractive Summarisation Models with Machine Translation in Deliberative Processes\n",
      "167\n",
      "Supporting Context Monotonicity Abstractions in Neural NLI Models\n",
      "168\n",
      "Pretrained Transformers for Text Ranking: BERT and Beyond\n",
      "169\n",
      "Sampling and Filtering of Neural Machine Translation Distillation Data\n",
      "170\n",
      "Sentence Concatenation Approach to Data Augmentation for Neural Machine Translation\n",
      "171\n",
      "Distantly Supervised Relation Extraction with Sentence Reconstruction and Knowledge Base Priors\n",
      "172\n",
      "A Frustratingly Easy Approach for Entity and Relation Extraction\n",
      "173\n",
      "Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers\n",
      "174\n",
      "Mediators in Determining what Processing BERT Performs First\n",
      "175\n",
      "Automatic Generation of Contrast Sets from Scene Graphs: Probing the Compositional Consistency of GQA\n",
      "176\n",
      "Multilingual Language Models Predict Human Reading Behavior\n",
      "177\n",
      "Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing\n",
      "178\n",
      "Concealed Data Poisoning Attacks on NLP Models\n",
      "179\n",
      "Backtranslation Feedback Improves User Confidence in MT, Not Quality\n",
      "180\n",
      "Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation\n",
      "181\n",
      "Neural Machine Translation without Embeddings\n",
      "182\n",
      "A Million Tweets Are Worth a Few Points: Tuning Transformers for Customer Service Tasks\n",
      "183\n",
      "Fast and Scalable Dialogue State Tracking with Explicit Modular Decomposition\n",
      "184\n",
      "Fool Me Twice: Entailment from Wikipedia Gamification\n",
      "185\n",
      "When Being Unseen from mBERT is just the Beginning: Handling New Languages With Multilingual Language Models\n",
      "186\n",
      "Open Domain Question Answering over Tables via Dense Retrieval\n",
      "187\n",
      "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence\n",
      "188\n",
      "Representing Numbers in NLP: a Survey and a Vision\n",
      "189\n",
      "Identifying Helpful Sentences in Product Reviews\n",
      "190\n",
      "Enhancing Factual Consistency of Abstractive Summarization\n",
      "191\n",
      "Linking Entities to Unseen Knowledge Bases with Arbitrary Schemas\n",
      "192\n",
      "Neural Language Modeling for Contextualized Temporal Graph Generation\n",
      "193\n",
      "Probabilistic Box Embeddings for Uncertain Knowledge Graph Reasoning\n",
      "194\n",
      "Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?\n",
      "195\n",
      "An Empirical Comparison of Instance Attribution Methods for NLP\n",
      "196\n",
      "Measuring Social Biases in Grounded Vision and Language Embeddings\n",
      "197\n",
      "Modular Networks for Compositional Instruction Following\n",
      "198\n",
      "Understanding Hard Negatives in Noise Contrastive Estimation\n",
      "199\n",
      "Harnessing Multilinguality in Unsupervised Machine Translation for Rare Languages\n",
      "200\n",
      "The Curious Case of Hallucinations in Neural Machine Translation\n",
      "201\n",
      "Towards Continual Learning for Multilingual Machine Translation via Vocabulary Substitution\n",
      "202\n",
      "Capturing Row and Column Semantics in Transformer Based Question Answering over Tables\n",
      "203\n",
      "Text Modular Networks: Learning to Decompose Tasks in the Language of Existing Models\n",
      "204\n",
      "On the Transferability of Minimal Prediction Preserving Inputs in Question Answering\n",
      "205\n",
      "Understanding by Understanding Not: Modeling Negation in Language Models\n",
      "206\n",
      "Temporal Reasoning on Implicit Events from Distant Supervision\n",
      "207\n",
      "A New Approach to Overgenerating and Scoring Abstractive Summaries\n",
      "208\n",
      "Efficient Attentions for Long Document Summarization\n",
      "209\n",
      "RefSum: Refactoring Neural Summarization\n",
      "210\n",
      "Neural Sequence Segmentation as Determining the Leftmost Segments\n",
      "211\n",
      "Put Chatbot into Its Interlocutor's Shoes: New Framework to Learn Chatbot Responding with Intention\n",
      "212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RST Parsing from Scratch\n",
      "213\n",
      "Did they answer? Subjective acts and intents in conversational discourse\n",
      "214\n",
      "Evaluating the Impact of a Hierarchical Discourse Representation on Entity Coreference Resolution Performance\n",
      "215\n",
      "Explicitly Modeling Syntax in Language Models with Incremental Parsing and a Dynamic Oracle\n",
      "216\n",
      "Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation\n",
      "217\n",
      "Mask Attention Networks: Rethinking and Strengthen Transformer\n",
      "218\n",
      "Modeling Event Plausibility with Consistent Conceptual Abstraction\n",
      "219\n",
      "UmlsBERT: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus\n",
      "220\n",
      "MelBERT: Metaphor Detection via Contextualized Late Interaction using Metaphorical Identification Theories\n",
      "221\n",
      "Everything Has a Cause: Leveraging Causal Inference in Legal Text Analysis\n",
      "222\n",
      "Active$^2$ Learning: Actively reducing redundancies in Active Learning methods for Sequence Tagging and Machine Translation\n",
      "223\n",
      "Model Extraction and Adversarial Transferability, Your BERT is Vulnerable!\n",
      "224\n",
      "Masked Conditional Random Fields for Sequence Labeling\n",
      "225\n",
      "Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models\n",
      "226\n",
      "ASAP: A Chinese Review Dataset Towards Aspect Category Sentiment Analysis and Rating Prediction\n",
      "227\n",
      "Are NLP Models really able to Solve Simple Math Word Problems?\n",
      "228\n",
      "KPQA: A Metric for Generative Question Answering Using Keyphrase Weights\n",
      "229\n",
      "Blow the Dog Whistle: A Chinese Dataset for Cant Understanding with Common Sense and World Knowledge\n",
      "230\n",
      "The structure of online social networks modulates the rate of lexical change\n",
      "231\n",
      "Modeling Framing in Immigration Discourse on Social Media\n",
      "232\n",
      "Modeling the Severity of Complaints in Social Media\n",
      "233\n",
      "Lifelong Learning of Hate Speech Classification on Social Media\n",
      "234\n",
      "Learning to Recognize Dialect Features\n",
      "235\n",
      "Static Embeddings as Efficient Knowledge Bases?\n",
      "236\n",
      "Highly Efficient Knowledge Graph Embedding Learning with Orthogonal Procrustes Analysis\n",
      "237\n",
      "Detoxifying Language Models Risks Marginalizing Minority Voices\n",
      "238\n",
      "Improving Generation and Evaluation of Visual Stories via Semantic Consistency\n",
      "239\n",
      "Video Question Answering with Phrases via Semantic Roles\n",
      "240\n",
      "KILT: a Benchmark for Knowledge Intensive Language Tasks\n",
      "241\n",
      "UDALM: Unsupervised Domain Adaptation through Language Modeling\n",
      "242\n",
      "Can Latent Alignments Improve Autoregressive Machine Translation?\n",
      "243\n",
      "Smoothing and Shrinking the Sparse Seq2Seq Search Space\n",
      "244\n",
      "On the Embeddings of Variables in Recurrent Neural Networks for Source Code\n",
      "245\n",
      "Semantic Frame Forecast\n",
      "246\n",
      "Continual Learning for Text Classification with Information Disentanglement Based Regularization\n",
      "247\n",
      "Learning from Executions for Semantic Parsing\n",
      "248\n",
      "Learning to Synthesize Data for Semantic Parsing\n",
      "249\n",
      "Edge: Enriching Knowledge Graph Embeddings with External Text\n",
      "250\n",
      "FLIN: A Flexible Natural Language Interface for Web Navigation\n",
      "251\n",
      "Incorporating External Knowledge to Enhance Tabular Reasoning\n",
      "252\n",
      "A Disentangled Adversarial Neural Topic Model for Separating Opinions from Plots in User Reviews\n",
      "253\n",
      "Controlling Dialogue Generation with Semantic Exemplars\n",
      "254\n",
      "COIL: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List\n",
      "255\n",
      "Faithfully Explainable Recommendation via Neural Logic Reasoning\n",
      "256\n",
      "Reading and Acting while Blindfolded: The Need for Semantics in Text Game Agents\n",
      "257\n",
      "CaSiNo: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems\n",
      "258\n",
      "News Headline Grouping as a Challenging NLU Task\n",
      "259\n",
      "HTCInfoMax: A Global Model for Hierarchical Text Classification via Information Maximization\n",
      "260\n",
      "Ensemble of MRR and NDCG models for Visual Dialog\n",
      "261\n",
      "CREAD: Combined Resolution of Ellipses and Anaphora in Dialogues\n",
      "262\n",
      "TABBIE: Pretrained Representations of Tabular Data\n",
      "263\n",
      "Better Feature Integration for Named Entity Recognition\n",
      "264\n",
      "FUDGE: Controlled Text Generation With Future Discriminators\n",
      "265\n",
      "Controllable Text Simplification with Explicit Paraphrasing\n",
      "266\n",
      "Explicit Alignment Objectives for Multilingual Bidirectional Encoders\n",
      "267\n",
      "multiPRover: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning\n",
      "268\n",
      "Refining Targeted Syntactic Evaluation of Language Models\n",
      "269\n",
      "Universal Adversarial Attacks with Natural Triggers for Text Classification\n",
      "270\n",
      "Beyond Fair Pay: Ethical Implications of NLP Crowdsourcing\n",
      "271\n",
      "Case Study: Deontological Ethics in NLP\n",
      "272\n",
      "On the Impact of Random Seeds on the Fairness of Clinical Classifiers\n",
      "273\n",
      "Discourse Probing of Pretrained Language Models\n",
      "274\n",
      "UniDrop: A Simple yet Effective Technique to Improve Transformer without Extra Cost\n",
      "275\n",
      "Learning to Learn to be Right for the Right Reasons\n",
      "276\n",
      "Double Perturbation: On the Robustness of Robustness and Counterfactual Bias Evaluation\n",
      "277\n",
      "Restoring and Mining the Records of the Joseon Dynasty via Neural Language Modeling and Machine Translation\n",
      "278\n",
      "Modeling Diagnostic Label Correlation for Automatic ICD Coding\n",
      "279\n",
      "A recipe for annotating grounded clarifications\n",
      "280\n",
      "Causal Effects of Linguistic Properties\n",
      "281\n",
      "Dynabench: Rethinking Benchmarking in NLP\n",
      "282\n",
      "Translational NLP: A New Paradigm and General Principles for Natural Language Processing Research\n",
      "283\n",
      "Probing for Bridging Inference in Transformer Language Models\n",
      "284\n",
      "Is Incoherence Surprising? Targeted Evaluation of Coherence Prediction from Language Models\n",
      "285\n",
      "Redefining Absent Keyphrases and their Effect on Retrieval Effectiveness\n",
      "286\n",
      "CoRT: Complementary Rankings from Transformers\n",
      "287\n",
      "MERMAID: Metaphor Generation with Symbolism and Discriminative Decoding\n",
      "288\n",
      "On Learning Text Style Transfer with Direct Rewards\n",
      "289\n",
      "NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints\n",
      "290\n",
      "Ask what's missing and what's useful: Improving Clarification Question Generation using Global Knowledge\n",
      "291\n",
      "Progressive Generation of Long Text with Pretrained Language Models\n",
      "292\n",
      "Swords: A Benchmark for Lexical Substitution with Improved Data Coverage and Quality\n",
      "293\n",
      "On Biasing Transformer Attention Towards Monotonicity\n",
      "294\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19156/1619138042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpapers_NLP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_papers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NLP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19156/88660466.py\u001b[0m in \u001b[0;36mget_papers\u001b[1;34m(quewords, Anthology)\u001b[0m\n\u001b[0;32m     14\u001b[0m                               \u001b[0mmax_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                               sort_by = arxiv.SortCriterion.SubmittedDate)\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\arxiv\\arxiv.py\u001b[0m in \u001b[0;36mresults\u001b[1;34m(self, search)\u001b[0m\n\u001b[0;32m    583\u001b[0m             ))\n\u001b[0;32m    584\u001b[0m             \u001b[0mpage_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_feed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_page\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m                 \u001b[1;31m# NOTE: this is an ugly fix for a known bug. The totalresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\arxiv\\arxiv.py\u001b[0m in \u001b[0;36m_parse_feed\u001b[1;34m(self, url, first_page)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \"\"\"\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# Invoke the recursive helper with initial available retries.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         return self.__try_parse_feed(\n\u001b[0m\u001b[0;32m    640\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[0mfirst_page\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_page\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\arxiv\\arxiv.py\u001b[0m in \u001b[0;36m__try_parse_feed\u001b[1;34m(self, url, first_page, retries_left, last_err)\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[1;34m'last_err'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlast_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlast_err\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         })\n\u001b[1;32m--> 672\u001b[1;33m         \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeedparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_request_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\feedparser\\api.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers, response_headers, resolve_relative_uris, sanitize_html)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_resource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodified\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferrer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         result.update({\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\feedparser\\api.py\u001b[0m in \u001b[0;36m_open_resource\u001b[1;34m(url_file_stream_or_string, etag, modified, agent, referrer, handlers, request_headers, result)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m        \u001b[1;32mand\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'http'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'https'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ftp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'feed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_file_stream_or_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodified\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferrer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_headers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;31m# try to open with native open function (if url_file_stream_or_string is a filename)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\feedparser\\http.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, etag, modified, agent, referrer, handlers, request_headers, result)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandlers\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_FeedURLHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# RMK - must clear so we only send our custom User-Agent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    535\u001b[0m                                   '_open', req)\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "papers_NLP = get_papers('NLP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b233a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ad47e",
   "metadata": {},
   "source": [
    "Or get papers and join with existing table of papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined.append(get_papers(quewords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a90fffa",
   "metadata": {},
   "source": [
    "Table looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e794a700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pdf_url  Arxiv</th>\n",
       "      <th>published  Arxiv</th>\n",
       "      <th>result  Arxiv</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>address</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>language</th>\n",
       "      <th>month</th>\n",
       "      <th>note</th>\n",
       "      <th>number</th>\n",
       "      <th>pages</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Secure and Efficient Federated Learning Fram...</td>\n",
       "      <td>http://arxiv.org/pdf/2201.11934v1</td>\n",
       "      <td>2022-01-28 05:01:25+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2201.11934v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online and Punta Cana, Dominican Republic</td>\n",
       "      <td>Proceedings of the 2021 Conference on Empirica...</td>\n",
       "      <td>10.18653/v1/2021.emnlp-main.606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7676--7682</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.emnlp-main.606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indian Language Wordnets and their Linkages wi...</td>\n",
       "      <td>http://arxiv.org/pdf/2201.02977v1</td>\n",
       "      <td>2022-01-09 10:12:31+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2201.02977v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miyazaki, Japan</td>\n",
       "      <td>Proceedings of the Eleventh International Conf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>European Language Resources Association (ELRA)</td>\n",
       "      <td>https://aclanthology.org/L18-1728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semi-automatic WordNet Linking using Word Embe...</td>\n",
       "      <td>http://arxiv.org/pdf/2201.01747v1</td>\n",
       "      <td>2022-01-05 18:15:55+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2201.01747v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nanyang Technological University (NTU), Singapore</td>\n",
       "      <td>Proceedings of the 9th Global Wordnet Conference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266--271</td>\n",
       "      <td>Global Wordnet Association</td>\n",
       "      <td>https://aclanthology.org/2018.gwc-1.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Utilizing Wordnets for Cognate Detection among...</td>\n",
       "      <td>http://arxiv.org/pdf/2112.15124v1</td>\n",
       "      <td>2021-12-30 16:46:28+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2112.15124v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wroclaw, Poland</td>\n",
       "      <td>Proceedings of the 10th Global Wordnet Conference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404--412</td>\n",
       "      <td>Global Wordnet Association</td>\n",
       "      <td>https://aclanthology.org/2019.gwc-1.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does QA-based intermediate training help fine-...</td>\n",
       "      <td>http://arxiv.org/pdf/2112.15051v1</td>\n",
       "      <td>2021-12-30 13:30:25+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2112.15051v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the The 19th Annual Workshop of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>December</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158--162</td>\n",
       "      <td>Australasian Language Technology Association</td>\n",
       "      <td>https://aclanthology.org/2021.alta-1.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Perturbing Inputs for Fragile Interpretations ...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.04990v2</td>\n",
       "      <td>2021-08-11 02:07:21+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.04990v2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Punta Cana, Dominican Republic</td>\n",
       "      <td>Proceedings of the Fourth BlackboxNLP Workshop...</td>\n",
       "      <td>10.18653/v1/2021.blackboxnlp-1.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420--434</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.blackboxnlp-1.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Finetuning Pretrained Transformers into Variat...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.02446v3</td>\n",
       "      <td>2021-08-05 08:27:26+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.02446v3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online and Punta Cana, Dominican Republic</td>\n",
       "      <td>Proceedings of the Second Workshop on Insights...</td>\n",
       "      <td>10.18653/v1/2021.insights-1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29--35</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.insights-1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Robust Transfer Learning with Pretrained Langu...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.02340v1</td>\n",
       "      <td>2021-08-05 02:30:13+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.02340v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 59th Annual Meeting of the ...</td>\n",
       "      <td>10.18653/v1/2021.acl-short.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>854--861</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.acl-short.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Changes in European Solidarity Before and Duri...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.01042v1</td>\n",
       "      <td>2021-08-02 17:03:12+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.01042v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 59th Annual Meeting of the ...</td>\n",
       "      <td>10.18653/v1/2021.acl-long.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1623--1637</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.acl-long.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Term Expansion and FinBERT fine-tuning for Hyp...</td>\n",
       "      <td>http://arxiv.org/pdf/2107.13764v1</td>\n",
       "      <td>2021-07-29 06:17:44+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2107.13764v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the Third Workshop on Financial...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19 August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46--51</td>\n",
       "      <td>-</td>\n",
       "      <td>https://aclanthology.org/2021.finnlp-1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    A Secure and Efficient Federated Learning Fram...   \n",
       "1    Indian Language Wordnets and their Linkages wi...   \n",
       "2    Semi-automatic WordNet Linking using Word Embe...   \n",
       "3    Utilizing Wordnets for Cognate Detection among...   \n",
       "4    Does QA-based intermediate training help fine-...   \n",
       "..                                                 ...   \n",
       "153  Perturbing Inputs for Fragile Interpretations ...   \n",
       "154  Finetuning Pretrained Transformers into Variat...   \n",
       "155  Robust Transfer Learning with Pretrained Langu...   \n",
       "156  Changes in European Solidarity Before and Duri...   \n",
       "157  Term Expansion and FinBERT fine-tuning for Hyp...   \n",
       "\n",
       "                        pdf_url  Arxiv          published  Arxiv  \\\n",
       "0    http://arxiv.org/pdf/2201.11934v1 2022-01-28 05:01:25+00:00   \n",
       "1    http://arxiv.org/pdf/2201.02977v1 2022-01-09 10:12:31+00:00   \n",
       "2    http://arxiv.org/pdf/2201.01747v1 2022-01-05 18:15:55+00:00   \n",
       "3    http://arxiv.org/pdf/2112.15124v1 2021-12-30 16:46:28+00:00   \n",
       "4    http://arxiv.org/pdf/2112.15051v1 2021-12-30 13:30:25+00:00   \n",
       "..                                 ...                       ...   \n",
       "153  http://arxiv.org/pdf/2108.04990v2 2021-08-11 02:07:21+00:00   \n",
       "154  http://arxiv.org/pdf/2108.02446v3 2021-08-05 08:27:26+00:00   \n",
       "155  http://arxiv.org/pdf/2108.02340v1 2021-08-05 02:30:13+00:00   \n",
       "156  http://arxiv.org/pdf/2108.01042v1 2021-08-02 17:03:12+00:00   \n",
       "157  http://arxiv.org/pdf/2107.13764v1 2021-07-29 06:17:44+00:00   \n",
       "\n",
       "                         result  Arxiv ISBN  \\\n",
       "0    http://arxiv.org/abs/2201.11934v1  NaN   \n",
       "1    http://arxiv.org/abs/2201.02977v1  NaN   \n",
       "2    http://arxiv.org/abs/2201.01747v1  NaN   \n",
       "3    http://arxiv.org/abs/2112.15124v1  NaN   \n",
       "4    http://arxiv.org/abs/2112.15051v1  NaN   \n",
       "..                                 ...  ...   \n",
       "153  http://arxiv.org/abs/2108.04990v2  NaN   \n",
       "154  http://arxiv.org/abs/2108.02446v3  NaN   \n",
       "155  http://arxiv.org/abs/2108.02340v1  NaN   \n",
       "156  http://arxiv.org/abs/2108.01042v1  NaN   \n",
       "157  http://arxiv.org/abs/2107.13764v1  NaN   \n",
       "\n",
       "                                               address  \\\n",
       "0            Online and Punta Cana, Dominican Republic   \n",
       "1                                      Miyazaki, Japan   \n",
       "2    Nanyang Technological University (NTU), Singapore   \n",
       "3                                      Wroclaw, Poland   \n",
       "4                                               Online   \n",
       "..                                                 ...   \n",
       "153                     Punta Cana, Dominican Republic   \n",
       "154          Online and Punta Cana, Dominican Republic   \n",
       "155                                             Online   \n",
       "156                                             Online   \n",
       "157                                             Online   \n",
       "\n",
       "                                             booktitle  \\\n",
       "0    Proceedings of the 2021 Conference on Empirica...   \n",
       "1    Proceedings of the Eleventh International Conf...   \n",
       "2     Proceedings of the 9th Global Wordnet Conference   \n",
       "3    Proceedings of the 10th Global Wordnet Conference   \n",
       "4    Proceedings of the The 19th Annual Workshop of...   \n",
       "..                                                 ...   \n",
       "153  Proceedings of the Fourth BlackboxNLP Workshop...   \n",
       "154  Proceedings of the Second Workshop on Insights...   \n",
       "155  Proceedings of the 59th Annual Meeting of the ...   \n",
       "156  Proceedings of the 59th Annual Meeting of the ...   \n",
       "157  Proceedings of the Third Workshop on Financial...   \n",
       "\n",
       "                                   doi journal language      month note  \\\n",
       "0      10.18653/v1/2021.emnlp-main.606     NaN      NaN   November  NaN   \n",
       "1                                  NaN     NaN      NaN        May  NaN   \n",
       "2                                  NaN     NaN      NaN    January  NaN   \n",
       "3                                  NaN     NaN      NaN       July  NaN   \n",
       "4                                  NaN     NaN      NaN   December  NaN   \n",
       "..                                 ...     ...      ...        ...  ...   \n",
       "153  10.18653/v1/2021.blackboxnlp-1.33     NaN      NaN   November  NaN   \n",
       "154      10.18653/v1/2021.insights-1.5     NaN      NaN   November  NaN   \n",
       "155     10.18653/v1/2021.acl-short.108     NaN      NaN     August  NaN   \n",
       "156      10.18653/v1/2021.acl-long.129     NaN      NaN     August  NaN   \n",
       "157                                NaN     NaN      NaN  19 August  NaN   \n",
       "\n",
       "    number       pages                                       publisher  \\\n",
       "0      NaN  7676--7682       Association for Computational Linguistics   \n",
       "1      NaN         NaN  European Language Resources Association (ELRA)   \n",
       "2      NaN    266--271                      Global Wordnet Association   \n",
       "3      NaN    404--412                      Global Wordnet Association   \n",
       "4      NaN    158--162    Australasian Language Technology Association   \n",
       "..     ...         ...                                             ...   \n",
       "153    NaN    420--434       Association for Computational Linguistics   \n",
       "154    NaN      29--35       Association for Computational Linguistics   \n",
       "155    NaN    854--861       Association for Computational Linguistics   \n",
       "156    NaN  1623--1637       Association for Computational Linguistics   \n",
       "157    NaN      46--51                                               -   \n",
       "\n",
       "                                                url  volume  year  \n",
       "0      https://aclanthology.org/2021.emnlp-main.606     NaN  2021  \n",
       "1                 https://aclanthology.org/L18-1728     NaN  2018  \n",
       "2            https://aclanthology.org/2018.gwc-1.31     NaN  2018  \n",
       "3            https://aclanthology.org/2019.gwc-1.51     NaN  2019  \n",
       "4           https://aclanthology.org/2021.alta-1.16     NaN  2021  \n",
       "..                                              ...     ...   ...  \n",
       "153  https://aclanthology.org/2021.blackboxnlp-1.33     NaN  2021  \n",
       "154      https://aclanthology.org/2021.insights-1.5     NaN  2021  \n",
       "155     https://aclanthology.org/2021.acl-short.108     NaN  2021  \n",
       "156      https://aclanthology.org/2021.acl-long.129     NaN  2021  \n",
       "157        https://aclanthology.org/2021.finnlp-1.8     NaN  2021  \n",
       "\n",
       "[158 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbe9b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 0\n",
       "pdf_url  Arxiv        0\n",
       "published  Arxiv      0\n",
       "result  Arxiv         0\n",
       "ISBN                157\n",
       "address               0\n",
       "booktitle             1\n",
       "doi                  13\n",
       "journal             157\n",
       "language            157\n",
       "month                 1\n",
       "note                158\n",
       "number              158\n",
       "pages                 1\n",
       "publisher             0\n",
       "url                   0\n",
       "volume              157\n",
       "year                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_NLP.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5c5f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pdf_url  Arxiv</th>\n",
       "      <th>published  Arxiv</th>\n",
       "      <th>result  Arxiv</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>address</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>language</th>\n",
       "      <th>month</th>\n",
       "      <th>note</th>\n",
       "      <th>number</th>\n",
       "      <th>pages</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Secure and Efficient Federated Learning Fram...</td>\n",
       "      <td>http://arxiv.org/pdf/2201.11934v1</td>\n",
       "      <td>2022-01-28 05:01:25+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2201.11934v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online and Punta Cana, Dominican Republic</td>\n",
       "      <td>Proceedings of the 2021 Conference on Empirica...</td>\n",
       "      <td>10.18653/v1/2021.emnlp-main.606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7676--7682</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.emnlp-main.606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indian Language Wordnets and their Linkages wi...</td>\n",
       "      <td>http://arxiv.org/pdf/2201.02977v1</td>\n",
       "      <td>2022-01-09 10:12:31+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2201.02977v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miyazaki, Japan</td>\n",
       "      <td>Proceedings of the Eleventh International Conf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>European Language Resources Association (ELRA)</td>\n",
       "      <td>https://aclanthology.org/L18-1728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semi-automatic WordNet Linking using Word Embe...</td>\n",
       "      <td>http://arxiv.org/pdf/2201.01747v1</td>\n",
       "      <td>2022-01-05 18:15:55+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2201.01747v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nanyang Technological University (NTU), Singapore</td>\n",
       "      <td>Proceedings of the 9th Global Wordnet Conference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>January</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266--271</td>\n",
       "      <td>Global Wordnet Association</td>\n",
       "      <td>https://aclanthology.org/2018.gwc-1.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Utilizing Wordnets for Cognate Detection among...</td>\n",
       "      <td>http://arxiv.org/pdf/2112.15124v1</td>\n",
       "      <td>2021-12-30 16:46:28+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2112.15124v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wroclaw, Poland</td>\n",
       "      <td>Proceedings of the 10th Global Wordnet Conference</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>July</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404--412</td>\n",
       "      <td>Global Wordnet Association</td>\n",
       "      <td>https://aclanthology.org/2019.gwc-1.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does QA-based intermediate training help fine-...</td>\n",
       "      <td>http://arxiv.org/pdf/2112.15051v1</td>\n",
       "      <td>2021-12-30 13:30:25+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2112.15051v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the The 19th Annual Workshop of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>December</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158--162</td>\n",
       "      <td>Australasian Language Technology Association</td>\n",
       "      <td>https://aclanthology.org/2021.alta-1.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Perturbing Inputs for Fragile Interpretations ...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.04990v2</td>\n",
       "      <td>2021-08-11 02:07:21+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.04990v2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Punta Cana, Dominican Republic</td>\n",
       "      <td>Proceedings of the Fourth BlackboxNLP Workshop...</td>\n",
       "      <td>10.18653/v1/2021.blackboxnlp-1.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420--434</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.blackboxnlp-1.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Finetuning Pretrained Transformers into Variat...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.02446v3</td>\n",
       "      <td>2021-08-05 08:27:26+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.02446v3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online and Punta Cana, Dominican Republic</td>\n",
       "      <td>Proceedings of the Second Workshop on Insights...</td>\n",
       "      <td>10.18653/v1/2021.insights-1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>November</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29--35</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.insights-1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Robust Transfer Learning with Pretrained Langu...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.02340v1</td>\n",
       "      <td>2021-08-05 02:30:13+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.02340v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 59th Annual Meeting of the ...</td>\n",
       "      <td>10.18653/v1/2021.acl-short.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>854--861</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.acl-short.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Changes in European Solidarity Before and Duri...</td>\n",
       "      <td>http://arxiv.org/pdf/2108.01042v1</td>\n",
       "      <td>2021-08-02 17:03:12+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2108.01042v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the 59th Annual Meeting of the ...</td>\n",
       "      <td>10.18653/v1/2021.acl-long.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1623--1637</td>\n",
       "      <td>Association for Computational Linguistics</td>\n",
       "      <td>https://aclanthology.org/2021.acl-long.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Term Expansion and FinBERT fine-tuning for Hyp...</td>\n",
       "      <td>http://arxiv.org/pdf/2107.13764v1</td>\n",
       "      <td>2021-07-29 06:17:44+00:00</td>\n",
       "      <td>http://arxiv.org/abs/2107.13764v1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online</td>\n",
       "      <td>Proceedings of the Third Workshop on Financial...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19 August</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46--51</td>\n",
       "      <td>-</td>\n",
       "      <td>https://aclanthology.org/2021.finnlp-1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    A Secure and Efficient Federated Learning Fram...   \n",
       "1    Indian Language Wordnets and their Linkages wi...   \n",
       "2    Semi-automatic WordNet Linking using Word Embe...   \n",
       "3    Utilizing Wordnets for Cognate Detection among...   \n",
       "4    Does QA-based intermediate training help fine-...   \n",
       "..                                                 ...   \n",
       "153  Perturbing Inputs for Fragile Interpretations ...   \n",
       "154  Finetuning Pretrained Transformers into Variat...   \n",
       "155  Robust Transfer Learning with Pretrained Langu...   \n",
       "156  Changes in European Solidarity Before and Duri...   \n",
       "157  Term Expansion and FinBERT fine-tuning for Hyp...   \n",
       "\n",
       "                        pdf_url  Arxiv          published  Arxiv  \\\n",
       "0    http://arxiv.org/pdf/2201.11934v1 2022-01-28 05:01:25+00:00   \n",
       "1    http://arxiv.org/pdf/2201.02977v1 2022-01-09 10:12:31+00:00   \n",
       "2    http://arxiv.org/pdf/2201.01747v1 2022-01-05 18:15:55+00:00   \n",
       "3    http://arxiv.org/pdf/2112.15124v1 2021-12-30 16:46:28+00:00   \n",
       "4    http://arxiv.org/pdf/2112.15051v1 2021-12-30 13:30:25+00:00   \n",
       "..                                 ...                       ...   \n",
       "153  http://arxiv.org/pdf/2108.04990v2 2021-08-11 02:07:21+00:00   \n",
       "154  http://arxiv.org/pdf/2108.02446v3 2021-08-05 08:27:26+00:00   \n",
       "155  http://arxiv.org/pdf/2108.02340v1 2021-08-05 02:30:13+00:00   \n",
       "156  http://arxiv.org/pdf/2108.01042v1 2021-08-02 17:03:12+00:00   \n",
       "157  http://arxiv.org/pdf/2107.13764v1 2021-07-29 06:17:44+00:00   \n",
       "\n",
       "                         result  Arxiv ISBN  \\\n",
       "0    http://arxiv.org/abs/2201.11934v1  NaN   \n",
       "1    http://arxiv.org/abs/2201.02977v1  NaN   \n",
       "2    http://arxiv.org/abs/2201.01747v1  NaN   \n",
       "3    http://arxiv.org/abs/2112.15124v1  NaN   \n",
       "4    http://arxiv.org/abs/2112.15051v1  NaN   \n",
       "..                                 ...  ...   \n",
       "153  http://arxiv.org/abs/2108.04990v2  NaN   \n",
       "154  http://arxiv.org/abs/2108.02446v3  NaN   \n",
       "155  http://arxiv.org/abs/2108.02340v1  NaN   \n",
       "156  http://arxiv.org/abs/2108.01042v1  NaN   \n",
       "157  http://arxiv.org/abs/2107.13764v1  NaN   \n",
       "\n",
       "                                               address  \\\n",
       "0            Online and Punta Cana, Dominican Republic   \n",
       "1                                      Miyazaki, Japan   \n",
       "2    Nanyang Technological University (NTU), Singapore   \n",
       "3                                      Wroclaw, Poland   \n",
       "4                                               Online   \n",
       "..                                                 ...   \n",
       "153                     Punta Cana, Dominican Republic   \n",
       "154          Online and Punta Cana, Dominican Republic   \n",
       "155                                             Online   \n",
       "156                                             Online   \n",
       "157                                             Online   \n",
       "\n",
       "                                             booktitle  \\\n",
       "0    Proceedings of the 2021 Conference on Empirica...   \n",
       "1    Proceedings of the Eleventh International Conf...   \n",
       "2     Proceedings of the 9th Global Wordnet Conference   \n",
       "3    Proceedings of the 10th Global Wordnet Conference   \n",
       "4    Proceedings of the The 19th Annual Workshop of...   \n",
       "..                                                 ...   \n",
       "153  Proceedings of the Fourth BlackboxNLP Workshop...   \n",
       "154  Proceedings of the Second Workshop on Insights...   \n",
       "155  Proceedings of the 59th Annual Meeting of the ...   \n",
       "156  Proceedings of the 59th Annual Meeting of the ...   \n",
       "157  Proceedings of the Third Workshop on Financial...   \n",
       "\n",
       "                                   doi journal language      month note  \\\n",
       "0      10.18653/v1/2021.emnlp-main.606     NaN      NaN   November  NaN   \n",
       "1                                  NaN     NaN      NaN        May  NaN   \n",
       "2                                  NaN     NaN      NaN    January  NaN   \n",
       "3                                  NaN     NaN      NaN       July  NaN   \n",
       "4                                  NaN     NaN      NaN   December  NaN   \n",
       "..                                 ...     ...      ...        ...  ...   \n",
       "153  10.18653/v1/2021.blackboxnlp-1.33     NaN      NaN   November  NaN   \n",
       "154      10.18653/v1/2021.insights-1.5     NaN      NaN   November  NaN   \n",
       "155     10.18653/v1/2021.acl-short.108     NaN      NaN     August  NaN   \n",
       "156      10.18653/v1/2021.acl-long.129     NaN      NaN     August  NaN   \n",
       "157                                NaN     NaN      NaN  19 August  NaN   \n",
       "\n",
       "    number       pages                                       publisher  \\\n",
       "0      NaN  7676--7682       Association for Computational Linguistics   \n",
       "1      NaN         NaN  European Language Resources Association (ELRA)   \n",
       "2      NaN    266--271                      Global Wordnet Association   \n",
       "3      NaN    404--412                      Global Wordnet Association   \n",
       "4      NaN    158--162    Australasian Language Technology Association   \n",
       "..     ...         ...                                             ...   \n",
       "153    NaN    420--434       Association for Computational Linguistics   \n",
       "154    NaN      29--35       Association for Computational Linguistics   \n",
       "155    NaN    854--861       Association for Computational Linguistics   \n",
       "156    NaN  1623--1637       Association for Computational Linguistics   \n",
       "157    NaN      46--51                                               -   \n",
       "\n",
       "                                                url  volume  year  \n",
       "0      https://aclanthology.org/2021.emnlp-main.606     NaN  2021  \n",
       "1                 https://aclanthology.org/L18-1728     NaN  2018  \n",
       "2            https://aclanthology.org/2018.gwc-1.31     NaN  2018  \n",
       "3            https://aclanthology.org/2019.gwc-1.51     NaN  2019  \n",
       "4           https://aclanthology.org/2021.alta-1.16     NaN  2021  \n",
       "..                                              ...     ...   ...  \n",
       "153  https://aclanthology.org/2021.blackboxnlp-1.33     NaN  2021  \n",
       "154      https://aclanthology.org/2021.insights-1.5     NaN  2021  \n",
       "155     https://aclanthology.org/2021.acl-short.108     NaN  2021  \n",
       "156      https://aclanthology.org/2021.acl-long.129     NaN  2021  \n",
       "157        https://aclanthology.org/2021.finnlp-1.8     NaN  2021  \n",
       "\n",
       "[157 rows x 18 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = papers_NLP.dropna(subset = ['month'])\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ff5fb",
   "metadata": {},
   "source": [
    "# Saving table with papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b780136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined.to_csv('joinedpapers_'+quewords+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b37dd",
   "metadata": {},
   "source": [
    "# Download ArXiv from df table, using the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a48b0a",
   "metadata": {},
   "source": [
    "url_st_intro = 'http://arxiv.org/pdf/cond-mat/0102536v1'\n",
    "\n",
    "urllib.request.urlretrieve(url_st_intro, \"pdf\\st-intro.pdf\")\n",
    "\n",
    "or \n",
    "\n",
    "query['result'][0].download_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef981364",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean.apply(lambda y: y['result  Arxiv'].download_pdf(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c40ab3",
   "metadata": {},
   "source": [
    "# Download Anthology from Anth table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99f47043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('?', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('!', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('+', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('#', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('%', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('{', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('}', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('*', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('$', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace(':', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('|', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('=', ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace(\"'\", ''),axis =1)\n",
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_9584/3801093947.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean['title'] = clean.apply(lambda x: x['title'].replace('\"', ''),axis =1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Does QA-based intermediate training help fine-tuning language models for text classification'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = clean_title(clean)\n",
    "clean['title'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bec7caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEET Tunisian Dataset for Toxic Speech Detection\n"
     ]
    }
   ],
   "source": [
    "for index,row in clean.iterrows():\n",
    "    try: urllib.request.urlretrieve(row['url']+'.pdf', 'pdf Anth/'+'Anth-'+row['title']+'.pdf')\n",
    "    except: print(row['title'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0d9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
