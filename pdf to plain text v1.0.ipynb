{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b314cb76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# pip install spacy\n",
    "# !pip install spacypdfreader\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17766235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03aebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacypdfreader import pdf_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e65235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = (pdf_reader('pdf Anth/Anth-A Secure and Efficient Federated Learning Framework for NLP.pdf', nlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eaa3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc\n",
    "\n",
    "# order is not completely correct 5 conclusion before 4 Experiments\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ab1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e2537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc_Arxiv = (pdf_reader(\"pdf Arxiv\\Term_Expansion_and_FinBERT_fine_tuning_for_Hypernym_and_Synonym_Ranking_of_Financial_Terms.pdf\", nlp))\n",
    "doc_Anth = (pdf_reader(\"pdf Anth\\Anth-Term Expansion and FinBERT fine-tuning for Hypernym and Synonym Ranking of Financial Terms.pdf\", nlp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e289e4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Term Expansion and FinBERT ﬁne-tuning for Hypernym and Synonym Ranking\n",
       "of Financial Terms\n",
       "\n",
       "Ankush Chopra∗† , Sohom Ghosh†\n",
       "Fidelity Investments, AI CoE, Bengaluru, India\n",
       "{ankush01729, sohom1ghosh}@gmail.com\n",
       "\n",
       "1\n",
       "2\n",
       "0\n",
       "2\n",
       " \n",
       "l\n",
       "u\n",
       "J\n",
       " \n",
       "9\n",
       "2\n",
       " \n",
       " \n",
       "]\n",
       "L\n",
       "C\n",
       ".\n",
       "s\n",
       "c\n",
       "[\n",
       " \n",
       " \n",
       "1\n",
       "v\n",
       "4\n",
       "6\n",
       "7\n",
       "3\n",
       "1\n",
       ".\n",
       "7\n",
       "0\n",
       "1\n",
       "2\n",
       ":\n",
       "v\n",
       "i\n",
       "X\n",
       "r\n",
       "a\n",
       "\n",
       "Abstract\n",
       "\n",
       "Hypernym and synonym matching are one of the\n",
       "mainstream Natural Language Processing (NLP)\n",
       "tasks.\n",
       "In this paper, we present systems that at-\n",
       "tempt to solve this problem. We designed these\n",
       "systems to participate in the FinSim-3, a shared\n",
       "task of FinNLP workshop at IJCAI-2021. The\n",
       "shared task is focused on solving this problem for\n",
       "the ﬁnancial domain. We experimented with var-\n",
       "ious transformer based pre-trained embeddings by\n",
       "ﬁne-tuning these for either classiﬁcation or phrase\n",
       "similarity tasks. We also augmented the provided\n",
       "dataset with abbreviations derived from prospectus\n",
       "provided by the organizers and deﬁnitions of the\n",
       "ﬁnancial terms from DBpedia [Auer et al., 2007],\n",
       "Investopedia, and the Financial Industry Business\n",
       "Ontology (FIBO). Our best performing system uses\n",
       "both FinBERT [Araci, 2019] and data augmenta-\n",
       "tion from the afore-mentioned sources. We ob-\n",
       "served that term expansion using data augmentation\n",
       "in conjunction with semantic similarity is beneﬁcial\n",
       "for this task and could be useful for the other tasks\n",
       "that deal with short phrases. Our best performing\n",
       "model (Accuracy: 0.917, Rank: 1.156) was devel-\n",
       "oped by ﬁne-tuning SentenceBERT [Reimers et al.,\n",
       "2019] (with FinBERT at the backend) over an ex-\n",
       "tended labelled set created using the hierarchy of\n",
       "labels present in FIBO.\n",
       "\n",
       "1 Introduction\n",
       "Ontologies are rich sources of information that provide deep\n",
       "information about the underlying concepts and entities. This\n",
       "information is described for a speciﬁc domain. It contains the\n",
       "clearly deﬁned relationships, and it is organized in a deﬁned\n",
       "structure mostly as a hierarchy. These properties make on-\n",
       "tologies a great source for getting a deeper understanding of\n",
       "the relationship and properties of resources of the domain in\n",
       "consideration.\n",
       "\n",
       "Public knowledge graphs and ontologies like DBpedia and\n",
       "Yago have been shown to work on various applications like\n",
       "\n",
       "∗Contact Author\n",
       "†Equal Contribution\n",
       "\n",
       "the ones described in [Kobilarov et al., 2009] and [Hahm et\n",
       "al., 2014]. This has motivated and paved ways for the creation\n",
       "of domain focused ontologies like FIBO1.\n",
       "\n",
       "Effective techniques that enable identifying lexical similar-\n",
       "ity between the terms or concepts increase the effectiveness\n",
       "of the ontologies. These methods not only help in building\n",
       "new ontologies faster or augment the existing ones, but also\n",
       "it helps in the effective querying and searching of concepts.\n",
       "\n",
       "FinSim [Maarouf et al., 2020; Mansar et al., 2021] compe-\n",
       "titions are being held to promote the development of effective\n",
       "similarity measures. In the third edition of the competition\n",
       "FinSim-32 (being held in conjunction with the 30th Interna-\n",
       "tional Joint Conference on Artiﬁcial Intelligence (IJCAI-21)),\n",
       "the participants are challenged to develop methods and sys-\n",
       "tems to rank hypernym and synonyms to ﬁnancial terms by\n",
       "mapping them to one of the 17 high-level ﬁnancial concepts\n",
       "present in FIBO.\n",
       "\n",
       "In this paper, we present the systems developed by our\n",
       "team Lipi for hypernym and synonym ranking. We experi-\n",
       "mented with basic featurization methods like TF-IDF and ad-\n",
       "vanced methods like pre-trained embedding models. Our top\n",
       "3 systems use pre-trained FinBERT [Araci, 2019] embedding\n",
       "model that was ﬁne-tuned on the data speciﬁc to ﬁnancial do-\n",
       "main . We also augmented the training data by utilizing the\n",
       "knowledge from DBpedia, Investopedia, FIBO and text cor-\n",
       "pus of prospectus shared with us. We describe the works re-\n",
       "lated to our solution in the next section. Section 3 contains\n",
       "the formal problem statement, followed by data description\n",
       "in section 4. We describe our top three systems in section 5.\n",
       "Section 6 contains the details of the experimentation that we\n",
       "performed and the results obtained from some of them. We\n",
       "draw our conclusions in section 7 while giving a glimpse of\n",
       "things that we would like to try in the future.\n",
       "\n",
       "2 Related Works\n",
       "\n",
       "Hypernym-hyponym extraction and learning text similarity\n",
       "using semantic representations have been very challenging\n",
       "areas of research for the NLP community. SemEval-2018\n",
       "Task 9 [Camacho-Collados et al., 2018] was such an instance.\n",
       "\n",
       "1https://spec.edmcouncil.org/ﬁbo/\n",
       "2https://sites.google.com/nlg.csie.ntu.edu.tw/ﬁnnlp2021/shared-\n",
       "\n",
       "task-ﬁnsim (accessed on 8th July 2021)\n",
       "\n",
       "\n",
       "Team CRIM [Bernier-Colborne and Barri`ere, 2018] per-\n",
       "formed the best in this shared task. They combined a super-\n",
       "vised word embedding based approach with an unsupervised\n",
       "pattern discovery based approach. The FinSim shared tasks\n",
       "[Maarouf et al., 2020; Mansar et al., 2021] deal with adopt-\n",
       "ing these challenges speciﬁc to the Financial Domain. Team\n",
       "IIT-K [Keswani et al., 2020] won FinSim-1 using a combi-\n",
       "nation of context-free static embedding Word2Vec [Mikolov\n",
       "et al., 2013] and contextualized dynamic embedding BERT\n",
       "[Devlin et al., 2019]. Anand et al. [Anand et al., 2020] from\n",
       "the team FINSIM20 explored the use of cosine similarity be-\n",
       "tween terms and labels encoded using Universal Sentence En-\n",
       "coder [Cer et al., 2018]. They also tried to extract hypernyms\n",
       "automatically using graph based approaches. Team PolyU-\n",
       "CBS [Chersoni and Huang, 2021] won FinSim-2 shared\n",
       "task using Logistic Regression trained over word embedding\n",
       "and probabilities derived from BERT [Devlin et al., 2019]\n",
       "model. They also experimented with GPT-2 [Radford et al.,\n",
       "2019]. Team L3i-LBPAM [Nguyen et al., 2021] compris-\n",
       "ing Nguyen et al. performed better than the baseline by us-\n",
       "ing Sentence BERT [Reimers et al., 2019] to calculate co-\n",
       "sine similarity between terms and hypernyms. [Saini, 2020;\n",
       "Pei and Zhang, 2021] and [Jurgens and Pilehvar, 2016] dis-\n",
       "cussed various techniques to enrich the data which was avail-\n",
       "able for training. In this edition of FinSim, the number of\n",
       "training samples and labels (ﬁnancial concepts) were more\n",
       "than the previous two editions.\n",
       "\n",
       "their\n",
       "\n",
       "3 Problem Statement\n",
       "terms\n",
       "Given a set F consisting of n tuples of ﬁnancial\n",
       "i.e.\n",
       "and\n",
       "concepts/labels\n",
       "hypernyms/top-level\n",
       "F = {(t1, h1), (t2, h2), ...(tn, hn)} where hi\n",
       "represents\n",
       "the hypernym corresponding to the ith term ti and hi(cid:15) set of\n",
       "labels mentioned in Table 1. For every unseen ﬁnancial term,\n",
       "our task is to generate a ranked list ˆyi consisting of these 17\n",
       "hypernyms in order of decreasing semantic similarity.\n",
       "\n",
       "Evaluation Metrics The expected output is a raked list of\n",
       "predicted labels for every scored instance. The proposed sys-\n",
       "tems are evaluated based on Accuracy and Mean Rank met-\n",
       "rices as per the shared task rules. Evaluation script was pro-\n",
       "vided by organizers, where accuracy and mean rank were de-\n",
       "ﬁned as:\n",
       "Accuracy = 1\n",
       "n\n",
       "M eanRank = 1\n",
       "i=1( ˆyi.index(yi))\n",
       "n\n",
       "where ˆyi is the ranked list (with index starting from 1) of pre-\n",
       "dicted labels corresponding to the expected label yi. I is an\n",
       "identity matrix.\n",
       "\n",
       "i=1 I(yi = ˆyi[1])\n",
       "(cid:80)n\n",
       "\n",
       "(cid:80)n\n",
       "\n",
       "4 Data\n",
       "4.1 Data Description\n",
       "The training dataset shared for this task has a total of\n",
       "1050 single and multi-word terms tagged to 17 different\n",
       "classes/labels out of which 1040 term-label pairs are unique.\n",
       "More than 91% of the terms have 6 words or less and the\n",
       "longest term has 22 words. There were 10 duplicate entries,\n",
       "and 3 terms were assigned 2 different labels. Along with this,\n",
       "\n",
       "Label\n",
       "Equity Index\n",
       "Regulatory Agency\n",
       "Credit Index\n",
       "Central Securities Depository\n",
       "Debt pricing and yields\n",
       "Bonds\n",
       "Swap\n",
       "Stock Corporation\n",
       "Option\n",
       "Funds\n",
       "Future\n",
       "Credit Events\n",
       "MMIs\n",
       "Stocks\n",
       "Parametric schedules\n",
       "Forward\n",
       "Securities restrictions\n",
       "Total\n",
       "\n",
       "Count\n",
       "280\n",
       "205\n",
       "125\n",
       "107\n",
       "58\n",
       "55\n",
       "36\n",
       "25\n",
       "24\n",
       "22\n",
       "19\n",
       "18\n",
       "17\n",
       "17\n",
       "15\n",
       "9\n",
       "8\n",
       "1040\n",
       "\n",
       "Table 1: Label distribution in the training set\n",
       "\n",
       "a corpus of prospectuses in English that had 211 documents\n",
       "was provided. Some of the terms mentioned in the training\n",
       "data were present in the corpus. Table 1 shows the distribu-\n",
       "tion of these labels in the training set.\n",
       "\n",
       "4.2 Data Augmentation\n",
       "\n",
       "Since the majority of the terms had only a few tokens, we\n",
       "decided to expand the terms wherever possible using various\n",
       "sources. This approach had also been adopted by [Saini,\n",
       "2020] and [Pei and Zhang, 2021] while participating in\n",
       "FinSim-1 and FinSim-2 respectively.\n",
       "\n",
       "Acronym expansion: As mentioned by Keswani et al.\n",
       "[Keswani et al., 2020], the presence of acronyms created a\n",
       "major issue in maintaining consistency. We used the abbre-\n",
       "viation extractor available in spaCy3[Honnibal et al., 2020]\n",
       "package on the corpus of the prospectus to extract all the\n",
       "acronyms and their expansions. Upon manual inspection of\n",
       "a sample output, we identiﬁed that not all the extracted items\n",
       "were valid acronyms and their expansions. We cleaned the\n",
       "extracted list by dropping the records where:\n",
       "\n",
       "• expansion had equal or less length than the acronym.\n",
       "\n",
       "• expansion had parenthesis\n",
       "\n",
       "• extracted acronym was a valid English word such as\n",
       "\n",
       "”fund” or ”Germany”.\n",
       "\n",
       "• the expansion had less than or equal to 5 characters.\n",
       "\n",
       "We managed to extract 635 acronyms from the prospectus\n",
       "corpus after applying the above exclusions. We used this\n",
       "data to expand the matching terms in the given train set and\n",
       "test sets.\n",
       "\n",
       "3https://spacy.io/\n",
       "\n",
       "\n",
       "Deﬁnitions from DBpedia: We used the DBpedia search\n",
       "API4 to extract the description of the terms present in the train\n",
       "and test sets. We present such an example in Figure 1. In ad-\n",
       "dition to the description, the label was also retained from the\n",
       "result payload to identify the right description for the input\n",
       "terms. We tried token overlap-based similarity of input terms\n",
       "with both matching labels and descriptions. We decided to\n",
       "use the label to term match for description matching after go-\n",
       "ing through a randomly drawn sample. We cleaned both input\n",
       "terms and labels from DBpedia results by converting them to\n",
       "lower case, replacing punctuations by space, removing repet-\n",
       "itive spaces, and singularizing the text. We calculated the\n",
       "token overlap ratios for cleaned term and DBpedia labels us-\n",
       "ing these formulas: Ratio1 = length(s1 ∩ s2)/length(s1),\n",
       "Ratio2 = length(s2)/length(s1) where s1 and s2 represents\n",
       "sets of tokenized cleaned terms and tokenized cleaned DBpe-\n",
       "dia labels respectively. We empirically decided to use all the\n",
       "instances with Ratio1 = 1 and Ratio2 <= 1.25 for match-\n",
       "ing a DBpedia label (and hence description) to the input term.\n",
       "\n",
       "Deﬁnitions from Investopedia and FIBO: Inspired by\n",
       "[Saini, 2020], we obtained deﬁnitions of the terms present\n",
       "in Investopedia’s data dictionary5 by crawling it. We down-\n",
       "loaded a glossary of ﬁnancial terms from the website of\n",
       "FIBO. We cleaned all the terms from the train and test set and\n",
       "also the terms present in Investopedia’s data dictionary using\n",
       "the steps described in the above DBpedia section. We then as-\n",
       "signed the Investopedia or FIBO deﬁnition to the terms from\n",
       "the train and test sets where cleaned terms from train and test\n",
       "data matched to cleaned Investopedia terms perfectly.\n",
       "\n",
       "The test set which was provided to us had 326 terms. We\n",
       "augmented the original train and test set with the records\n",
       "where we could either ﬁnd deﬁnition or expansion using the\n",
       "above sources. The train set size increased to 1836 records\n",
       "and the test set size increased to 607 after the data augmen-\n",
       "tation. We present an example of data augmentation for the\n",
       "term “callable bond” in Table 2. Table 3 states the number\n",
       "of instances we used from each of the sources to augment the\n",
       "data we had.\n",
       "\n",
       "5 System Description\n",
       "We tried to solve this problem as the term classiﬁcation and\n",
       "term similarity problems. Two of our 3 submissions are mod-\n",
       "elled as the term classiﬁcation problem, whereas the third sys-\n",
       "tem is designed to be a phrase/sentence similarity problem be-\n",
       "tween terms (or expanded terms from the augmented dataset)\n",
       "and the deﬁnitions of 17 class labels that were extracted from\n",
       "FIBO / Internet. All the systems rely on semantic similarity\n",
       "and use FinBERT model to generate the term or token embed-\n",
       "ding representations. We divided the given data into training\n",
       "and validation sets having 832 and 208 terms respectively.\n",
       "\n",
       "5.1 System - 1 (S1)\n",
       "This is the simplest of our proposed systems, where we did\n",
       "not use the augmented dataset and used only the original set\n",
       "\n",
       "4https://lookup.dbpedia.org/api/search\n",
       "5https://www.investopedia.com/ﬁnancial-term-dictionary-\n",
       "\n",
       "4769738\n",
       "\n",
       "that was shared by organizers. We loaded FinBERT pre-\n",
       "trained model and ﬁne-tuned it by trying to classify the repre-\n",
       "sentation of [CLS] token into one of the 17 labels mentioned\n",
       "previously. Since the original data did not have longer terms,\n",
       "we kept the maximum length to 32, and train and validation\n",
       "batch sizes of 64. We used Adam optimizer with a learning\n",
       "rate of 0.00002. We ran the model for 40 epochs and picked\n",
       "the model saved after 18th epoch based on the performance on\n",
       "the validation set. Finally, we ranked the predictions based on\n",
       "the predicted probability of each class.\n",
       "\n",
       "5.2 System - 2 (S2)\n",
       "This system is similar to System-1 with the only difference\n",
       "that data being the augmented set and not the original dataset.\n",
       "Since the augmented dataset had the descriptions of the terms,\n",
       "the inputs were considerably longer. Hence, we increased the\n",
       "maximum length to 256 while keeping all the other hyper-\n",
       "parameters the same. After, training the model for 40 epochs\n",
       "we selected the model saved after the 17th epoch as the best\n",
       "model based on validation set performance.\n",
       "\n",
       "5.3 System -3 (S3)\n",
       "We explored the FIBO ontology to understand the hierarchy\n",
       "[Stepiˇsnik Perdih et al., 2021] of the 17 labels as depicted\n",
       "in Figure 2. We used the augmented data described in sec-\n",
       "tion 4.2 to create a labelled dataset having similarity scores.\n",
       "For every term deﬁnition (T) to label deﬁnition (L) mapping\n",
       "which existed in the extended training set, we assigned a sim-\n",
       "ilarity score of 1.0 to the (T,L) pair and picked up 10 train-\n",
       "ing instances randomly ensuring none of their label deﬁnition\n",
       "was same as L. For each of the label deﬁnitions (LL) present\n",
       "in this sample, we extracted its root node and ﬁrst child node.\n",
       "We did the same for the original label deﬁnition (L). Then, we\n",
       "compared these nodes. If the root node and ﬁrst child node of\n",
       "L were different from that of LL then we assigned a similar-\n",
       "ity score of 0 to the (T, LL) pair. If the root nodes were the\n",
       "same, we assigned a similarity score of ’k’ when the ﬁrst child\n",
       "nodes differed and a similarity score of ’2k’ when they were\n",
       "the same (where 0 < k < 1). We empirically ﬁgured out that\n",
       "k=0.4 works the best. As expected, the number of instances\n",
       "with a similarity score equal to 0 increased substantially. We\n",
       "under-sampled such instances and the new training set had\n",
       "30% instances with similarity score 1.0, 12% instances with\n",
       "similarity score ’k’, 28% instances with similarity score ’2k’\n",
       "and 30% instances with similarity score 0. After that, we ﬁne-\n",
       "tuned a FinBERT [Araci, 2019] model using Sentence BERT\n",
       "[Reimers et al., 2019] framework with this newly generated\n",
       "labelled data for 25 epochs with a batch size of 20. Our ob-\n",
       "jective was to minimize the multiple negatives ranking loss\n",
       "and online contrastive loss. We used a margin of 0.5 and co-\n",
       "sine distance as a distance metric while training this model.\n",
       "Finally, we converted all of the 17 labels’ deﬁnitions and term\n",
       "deﬁnitions from the validation set to vectors using this ﬁne-\n",
       "tuned model. For every such term deﬁnition, we performed\n",
       "a semantic search over the label vectors and ranked them in\n",
       "decreasing order of cosine similarity.\n",
       "System 2 and 3 take advantage of term expansion during both\n",
       "model training and scoring phases, which causes certain ob-\n",
       "servations to appear more than once (reference: Table 3). We\n",
       "\n",
       "\n",
       "Figure 1: Sample output from DBpedia search API\n",
       "\n",
       "Expanded Term/Term Deﬁnition\n",
       "\n",
       "Callable bond\n",
       "\n",
       "bond that includes a stipulation allowing the issuer\n",
       "the right to repurchase and retire the bond at the call price after the call protection period\n",
       "A callable bond (also called redeemable bond) is a type of bond (debt security) that allows\n",
       "the issuer of the bond to retain the privilege of redeeming the bond at some point before\n",
       "the bond reaches its date of maturity.\n",
       "\n",
       "Table 2: Result of Data Augmentation of the term ”Callable bond”\n",
       "\n",
       "Label\n",
       "\n",
       "Bonds\n",
       "\n",
       "Source\n",
       "original and\n",
       "acronym expansion\n",
       "\n",
       "Bonds\n",
       "\n",
       "FIBO\n",
       "\n",
       "Bonds DBpedia\n",
       "\n",
       "Data Source\n",
       "Original modelling data\n",
       "DBpedia\n",
       "FIBO\n",
       "Investopedia\n",
       "Acronym expansion\n",
       "\n",
       "Count\n",
       "1040\n",
       "257\n",
       "236\n",
       "85\n",
       "218\n",
       "\n",
       "Table 3: Details of various data sources\n",
       "\n",
       "derive the ﬁnal prediction by averaging the output probabili-\n",
       "ties for all the 17 classes for all the occurrences of the term.\n",
       "\n",
       "6 Experimentation and Results\n",
       "We had 1040 observations after removing the duplicates. We\n",
       "did an 80:20 split to create a training and validation set from\n",
       "this. We augmented the given modelling set by incorporating\n",
       "deﬁnitions from DBpedia, FIBO and Investopedia. We used\n",
       "the list of acronyms extracted from the prospectus corpus to\n",
       "create a copy with acronym expansion. This helped us to in-\n",
       "crease the original data to 1836 records (mentioned in Table\n",
       "1). It should be noted that we could not ﬁnd the expansions\n",
       "for all the terms given in the modelling set. Train and valida-\n",
       "tion set sizes for the original modelling set and expanded data\n",
       "were (832 & 208) and (1470 & 366) respectively.\n",
       "\n",
       "We established a baseline by running the scripts provided\n",
       "by the organizers. Then, we considered original modelling\n",
       "data and ﬁne-tuned base BERT-cased model [Devlin et al.,\n",
       "2019] to predict the class label by taking the representa-\n",
       "tion of [CLS] token while passing it through few layers of\n",
       "a feed-forward network. This performed better than base-\n",
       "line. We then tried the same BERT-base model on the ex-\n",
       "panded dataset, which gave us further performance improve-\n",
       "ment. Since the only major change between these runs was\n",
       "\n",
       "the data, the improvement can be attributed to the expanded\n",
       "data.\n",
       "\n",
       "We experimented with a few of the other pre-trained mod-\n",
       "els that are available on the Huggingface model repository\n",
       "[Wolf et al., 2020]. We observed clear improvement when\n",
       "we used the FinBERT model which was trained on data spe-\n",
       "ciﬁc to the ﬁnancial domain. The model performance succes-\n",
       "sively increased when we used a combination of data expan-\n",
       "sion with FinBERT. Furthermore, we tried to ﬁne-tune Fin-\n",
       "BERT using Sentence Transformers [Reimers et al., 2019] to\n",
       "capture semantic textual similarity. For this, we used several\n",
       "combinations of term and term deﬁnitions with label and la-\n",
       "bel deﬁnitions.\n",
       "\n",
       "All the hyperparameters for the ﬁnal 3 models have been\n",
       "already mentioned in the system description. After rigorous\n",
       "experimentation, these hyperparameters were selected empir-\n",
       "ically based on validation set performance. The results are\n",
       "presented in Table 4. Since the number of submissions was\n",
       "restricted to 3 for each team, we do not have the performance\n",
       "numbers of the BERT models in the test set. Analysing the\n",
       "results we see that SentenceBERT trained with FinBERT at\n",
       "the backed as mentioned in section-5.3 performed the best.\n",
       "\n",
       "7 Conclusion and Future Works\n",
       "\n",
       "In this work, we attempted to solve the hypernym and syn-\n",
       "onym discovery hosted at FinSim-3. This challenge aimed\n",
       "to enable the better use of ontologies like FIBO using hy-\n",
       "pernyms and synonyms, and we used these ontologies them-\n",
       "selves to develop our systems which perform signiﬁcantly\n",
       "better than the provided baseline systems. This proves the\n",
       "present use of these ontologies. The presented solution is\n",
       "recursive in a sense as it uses knowledge from ontologies\n",
       "to further increase the effectiveness and use of the same.\n",
       "\n",
       "\n",
       "Figure 2: Label Hierarchy from FIBO. Bold (leaf nodes) denotes the labels.\n",
       "\n",
       "Validation set Test set\n",
       "\n",
       "Data Rank Acc.\n",
       "Model\n",
       "0.498\n",
       "2.158\n",
       "Org.\n",
       "Base-1\n",
       "0.876\n",
       "1.201\n",
       "Org.\n",
       "Base-2\n",
       "0.899\n",
       "1.177\n",
       "Org.\n",
       "BERT\n",
       "0.928\n",
       "1.153\n",
       "BERT\n",
       "Ext.\n",
       "0.928\n",
       "1.117\n",
       "FinBERT(S1) Org.\n",
       "0.942\n",
       "1.110\n",
       "FinBERT(S2) Ext.\n",
       "0.947\n",
       "1.086\n",
       "Ext.\n",
       "SBERT(S3)\n",
       "\n",
       "Rank Acc.\n",
       "0.564\n",
       "1.941\n",
       "0.669\n",
       "1.75\n",
       "-\n",
       "-\n",
       "-\n",
       "-\n",
       "0.886\n",
       "1.257\n",
       "0.895\n",
       "1.220\n",
       "0.917\n",
       "1.156\n",
       "\n",
       "Table 4: Results on validation and test set. Org. represents original\n",
       "and Ext. represents extended. Base refers to baseline.\n",
       "\n",
       "Apart from data augmentation, our solution relies upon se-\n",
       "mantic similarity learnt from pre-trained embedding models\n",
       "that were learnt on the relevant domain. We observed the\n",
       "clear beneﬁts of domain speciﬁc pretraining during the ex-\n",
       "perimentation.\n",
       "\n",
       "In future, we would like to explore Knowledge Graphs (as\n",
       "described in [Portisch et al., 2021]) to further improve the\n",
       "improve performance of the models. We also want to ex-\n",
       "plore other variants of FinBERT [Araci, 2019] and ﬁne-tune\n",
       "them using the Masked Language Modeling technique (as\n",
       "mentioned by the winner of FinSim-2 [Chersoni and Huang,\n",
       "2021]) and Next Sentence Prediction objective. Moreover,\n",
       "this research can be extended by extracting sentences present\n",
       "in the prospectus (similar to [Goel et al., 2021]) to create\n",
       "more positive and negative samples.\n",
       "\n",
       "References\n",
       "\n",
       "[Anand et al., 2020] Vivek Anand, Yash Agrawal, Aarti Pol,\n",
       "and Vasudeva Varma. FINSIM20 at the FinSim task: Mak-\n",
       "ing sense of text in ﬁnancial domain. In Proceedings of\n",
       "the Second Workshop on Financial Technology and Natu-\n",
       "ral Language Processing, pages 104–107, Kyoto, Japan, 5\n",
       "January 2020.\n",
       "\n",
       "[Auer et al., 2007] S¨oren Auer, Christian Bizer, Georgi Ko-\n",
       "bilarov, Jens Lehmann, Richard Cyganiak, and Zachary\n",
       "Ives. Dbpedia: A nucleus for a web of open data, 2007.\n",
       "\n",
       "[Bernier-Colborne and Barri`ere, 2018] Gabriel\n",
       "\n",
       "Bernier-\n",
       "Colborne and Caroline Barri`ere. CRIM at SemEval-2018\n",
       "task 9: A hybrid approach to hypernym discovery. In Pro-\n",
       "ceedings of The 12th International Workshop on Semantic\n",
       "Evaluation, pages 725–731, New Orleans, Louisiana,\n",
       "June 2018. Association for Computational Linguistics.\n",
       "[Camacho-Collados et al., 2018] Jose Camacho-Collados,\n",
       "Claudio Delli Bovi, Luis Espinosa-Anke, Sergio Oramas,\n",
       "Tommaso Pasini, Enrico Santus, Vered Shwartz, Roberto\n",
       "Navigli, and Horacio Saggion. SemEval-2018 task 9:\n",
       "Hypernym discovery. In Proceedings of The 12th Interna-\n",
       "tional Workshop on Semantic Evaluation, pages 712–724,\n",
       "New Orleans, Louisiana, June 2018. Association for\n",
       "Computational Linguistics.\n",
       "\n",
       "[Cer et al., 2018] Daniel Cer, Yinfei Yang, Sheng yi Kong,\n",
       "Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Con-\n",
       "stant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar,\n",
       "Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil. Uni-\n",
       "versal sentence encoder, 2018.\n",
       "\n",
       "[Chersoni and Huang, 2021] Emmanuele Chersoni and Chu-\n",
       "Ren Huang. PolyU-CBS at the FinSim-2 Task: Combin-\n",
       "ing Distributional, String-Based and Transformers-Based\n",
       "Features for Hypernymy Detection in the Financial Do-\n",
       "main, page 316–319. Association for Computing Machin-\n",
       "ery, New York, NY, USA, 2021.\n",
       "\n",
       "[Devlin et al., 2019] Jacob Devlin, Ming-Wei Chang, Ken-\n",
       "ton Lee, and Kristina Toutanova. BERT: Pre-training of\n",
       "deep bidirectional transformers for language understand-\n",
       "ing. In Proceedings of the 2019 Conference of the North\n",
       "American Chapter of the Association for Computational\n",
       "Linguistics: Human Language Technologies, Volume 1\n",
       "(Long and Short Papers), pages 4171–4186, Minneapo-\n",
       "lis, Minnesota, June 2019. Association for Computational\n",
       "Linguistics.\n",
       "\n",
       "[Araci, 2019] Dogu Araci.\n",
       "\n",
       "Finbert: Financial sentiment\n",
       "\n",
       "analysis with pre-trained language models, 2019.\n",
       "\n",
       "[Goel et al., 2021] Tushar Goel, Vipul Chauhan,\n",
       "\n",
       "Ishan\n",
       "Verma, Tirthankar Dasgupta, and Lipika Dey. TCS WITM\n",
       "\n",
       "\n",
       "[Pei and Zhang, 2021] Yulong Pei and Qian Zhang. Goat at\n",
       "the ﬁnsim-2 task: Learning word representations of ﬁnan-\n",
       "In Companion Pro-\n",
       "cial data with customized corpus.\n",
       "ceedings of the Web Conference 2021, WWW ’21, page\n",
       "307–310, New York, NY, USA, 2021. Association for\n",
       "Computing Machinery.\n",
       "\n",
       "[Portisch et al., 2021] Jan Portisch, Michael Hladik, and\n",
       "Heiko Paulheim. FinMatcher at FinSim-2: Hypernym De-\n",
       "tection in the Financial Services Domain Using Knowl-\n",
       "edge Graphs, page 293–297. Association for Computing\n",
       "Machinery, New York, NY, USA, 2021.\n",
       "\n",
       "[Radford et al., 2019] Alec Radford, Jeff Wu, Rewon Child,\n",
       "David Luan, Dario Amodei, and Ilya Sutskever. Language\n",
       "models are unsupervised multitask learners, 2019.\n",
       "\n",
       "[Reimers et al., 2019] Nils Reimers, Iryna Gurevych, Nils\n",
       "Reimers, Iryna Gurevych, Nandan Thakur, Nils Reimers,\n",
       "Johannes Daxenberger, and Iryna Gurevych. Sentence-\n",
       "bert: Sentence embeddings using siamese bert-networks.\n",
       "In Proceedings of the 2019 Conference on Empirical\n",
       "Methods in Natural Language Processing. Association for\n",
       "Computational Linguistics, 2019.\n",
       "\n",
       "[Saini, 2020] Anuj Saini.\n",
       "\n",
       "Anuj at\n",
       "\n",
       "the FinSim task:\n",
       "Anuj@FINSIM¡VLearning semantic representation of ﬁ-\n",
       "nancial domain with investopedia. In Proceedings of the\n",
       "Second Workshop on Financial Technology and Natural\n",
       "Language Processing, pages 93–97, Kyoto, Japan, 5 Jan-\n",
       "uary 2020.\n",
       "\n",
       "[Stepiˇsnik Perdih et al., 2021] Timen\n",
       "\n",
       "Perdih,\n",
       "Senja Pollak, and Blaˇz ˇSkrlj. JSI at the FinSim-2 Task:\n",
       "Ontology-Augmented Financial Concept Classiﬁcation,\n",
       "page 298–301. Association for Computing Machinery,\n",
       "New York, NY, USA, 2021.\n",
       "\n",
       "Stepiˇsnik\n",
       "\n",
       "[Wolf et al., 2020] Thomas Wolf, Lysandre Debut, Victor\n",
       "Sanh, Julien Chaumond, Clement Delangue, Anthony\n",
       "Moi, Pierric Cistac, Tim Rault, R´emi Louf, Morgan\n",
       "Funtowicz,\n",
       "Joe Davison, Sam Shleifer, Patrick von\n",
       "Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen\n",
       "Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame,\n",
       "Quentin Lhoest, and Alexander M. Rush. Huggingface’s\n",
       "transformers: State-of-the-art natural language processing,\n",
       "2020.\n",
       "\n",
       "2021 @FinSim-2: Transformer Based Models for Auto-\n",
       "matic Classiﬁcation of Financial Terms, page 311–315.\n",
       "Association for Computing Machinery, New York, NY,\n",
       "USA, 2021.\n",
       "\n",
       "[Hahm et al., 2014] Younggyun Hahm,\n",
       "\n",
       "Jungyeul Park,\n",
       "Kyungtae Lim, Youngsik Kim, Dosam Hwang, and\n",
       "Key-Sun Choi. Named entity corpus construction us-\n",
       "In LREC, pages\n",
       "ing wikipedia and dbpedia ontology.\n",
       "2565–2569, 2014.\n",
       "\n",
       "[Honnibal et al., 2020] Matthew Honnibal,\n",
       "\n",
       "Ines Montani,\n",
       "spaCy:\n",
       "Soﬁe Van Landeghem, and Adriane Boyd.\n",
       "Industrial-strength Natural Language Processing in\n",
       "Python, 2020.\n",
       "\n",
       "[Jurgens and Pilehvar, 2016] David Jurgens and Moham-\n",
       "mad Taher Pilehvar. SemEval-2016 task 14: Semantic\n",
       "taxonomy enrichment. In Proceedings of the 10th Interna-\n",
       "tional Workshop on Semantic Evaluation (SemEval-2016),\n",
       "pages 1092–1102, San Diego, California, June 2016. As-\n",
       "sociation for Computational Linguistics.\n",
       "\n",
       "[Keswani et al., 2020] Vishal Keswani, Sakshi Singh, and\n",
       "Ashutosh Modi. IITK at the FinSim task: Hypernym de-\n",
       "tection in ﬁnancial domain via context-free and contextu-\n",
       "In Proceedings of the Second\n",
       "alized word embeddings.\n",
       "Workshop on Financial Technology and Natural Language\n",
       "Processing, pages 87–92, Kyoto, Japan, 5 January 2020.\n",
       "[Kobilarov et al., 2009] Georgi Kobilarov, Tom Scott, Yves\n",
       "Raimond, Silver Oliver, Chris Sizemore, Michael\n",
       "Smethurst, Christian Bizer, and Robert Lee. Media\n",
       "meets semantic web – how the bbc uses dbpedia and\n",
       "linked data to make connections.\n",
       "In Lora Aroyo, Paolo\n",
       "Traverso, Fabio Ciravegna, Philipp Cimiano, Tom Heath,\n",
       "Eero Hyv¨onen, Riichiro Mizoguchi, Eyal Oren, Marta\n",
       "Sabou, and Elena Simperl, editors, The Semantic Web: Re-\n",
       "search and Applications, pages 723–737, Berlin, Heidel-\n",
       "berg, 2009. Springer Berlin Heidelberg.\n",
       "\n",
       "[Maarouf et al., 2020] Ismail El Maarouf, Youness Mansar,\n",
       "Virginie Mouilleron, and Dialekti Valsamou-Stanislawski.\n",
       "The FinSim 2020 shared task: Learning semantic repre-\n",
       "sentations for the ﬁnancial domain. In Proceedings of the\n",
       "Second Workshop on Financial Technology and Natural\n",
       "Language Processing, pages 81–86, Kyoto, Japan, 5 Jan-\n",
       "uary 2020.\n",
       "\n",
       "[Mansar et al., 2021] Youness Mansar, Juyeon Kang, and Is-\n",
       "mail El Maarouf. The FinSim-2 2021 Shared Task: Learn-\n",
       "ing Semantic Similarities for the Financial Domain, page\n",
       "288–292. Association for Computing Machinery, New\n",
       "York, NY, USA, 2021.\n",
       "\n",
       "[Mikolov et al., 2013] Tomas Mikolov, Kai Chen, Greg Cor-\n",
       "rado, and Jeffrey Dean. Efﬁcient estimation of word rep-\n",
       "resentations in vector space, 2013.\n",
       "\n",
       "[Nguyen et al., 2021] Nhu Khoa Nguyen, Emanuela Boros,\n",
       "Gael Lejeune, Antoine Doucet, and Thierry Delahaut. L3i\n",
       "LBPAM at the FinSim-2 Task: Learning Financial Seman-\n",
       "tic Similarities with Siamese Transformers, page 302–306.\n",
       "Association for Computing Machinery, New York, NY,\n",
       "USA, 2021.\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56cab40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Term Expansion and FinBERT ﬁne-tuning for Hypernym and Synonym Ranking\n",
       "of Financial Terms\n",
       "\n",
       "Ankush Chopra∗† , Sohom Ghosh†\n",
       "Fidelity Investments, AI CoE, Bengaluru, India\n",
       "{ankush01729, sohom1ghosh}@gmail.com\n",
       "\n",
       "Abstract\n",
       "\n",
       "Hypernym and synonym matching are one of the\n",
       "mainstream Natural Language Processing (NLP)\n",
       "tasks.\n",
       "In this paper, we present systems that at-\n",
       "tempt to solve this problem. We designed these\n",
       "systems to participate in the FinSim-3, a shared\n",
       "task of FinNLP workshop at IJCAI-2021. The\n",
       "shared task is focused on solving this problem for\n",
       "the ﬁnancial domain. We experimented with var-\n",
       "ious transformer based pre-trained embeddings by\n",
       "ﬁne-tuning these for either classiﬁcation or phrase\n",
       "similarity tasks. We also augmented the provided\n",
       "dataset with abbreviations derived from prospectus\n",
       "provided by the organizers and deﬁnitions of the\n",
       "ﬁnancial terms from DBpedia [Auer et al., 2007],\n",
       "Investopedia, and the Financial Industry Business\n",
       "Ontology (FIBO). Our best performing system uses\n",
       "both FinBERT [Araci, 2019] and data augmenta-\n",
       "tion from the afore-mentioned sources. We ob-\n",
       "served that term expansion using data augmenta-\n",
       "tion in conjunction with semantic similarity is ben-\n",
       "eﬁcial for this task and could be beneﬁcial for\n",
       "the other tasks that deal with short phrases. Our\n",
       "best performing model (Accuracy: 0.917, Rank:\n",
       "1.156) was developed by ﬁne-tuning Sentence-\n",
       "BERT [Reimers et al., 2019] (with FinBERT at the\n",
       "backend) over an extended labelled set created us-\n",
       "ing the hierarchy of labels present in FIBO.\n",
       "\n",
       "Introduction\n",
       "\n",
       "1\n",
       "Ontologies are rich sources of information that provide deep\n",
       "information about the underlying concepts and entities. This\n",
       "information is described for a speciﬁc domain, contains the\n",
       "clearly deﬁned relationship, and organizes in a deﬁned struc-\n",
       "ture mostly as a hierarchy. These properties make ontologies\n",
       "a great source for getting a deeper understanding of the rela-\n",
       "tionship and properties of resources from the domain in con-\n",
       "sideration.\n",
       "\n",
       "Public knowledge graphs and ontologies like DBpedia and\n",
       "Yago have been shown to work on various applications like\n",
       "\n",
       "∗Contact Author\n",
       "†Equal Contribution\n",
       "\n",
       "the ones described in [Kobilarov et al., 2009] and [Hahm et\n",
       "al., 2014]. This has motivated and paved ways for the creation\n",
       "of domain focused ontologies like FIBO1.\n",
       "\n",
       "Effective techniques that enable identifying lexical similar-\n",
       "ity between the terms or concepts increase the effectiveness\n",
       "of the ontologies. These methods not only help in building\n",
       "new ontologies faster or augment the existing ones, but also\n",
       "it helps in the effective querying and concept search.\n",
       "\n",
       "FinSim [Maarouf et al., 2020; Mansar et al., 2021] com-\n",
       "petitions are being held to promote the development of effec-\n",
       "tive similarity measures. In the third edition of the competi-\n",
       "tion FinSim-32 (being held in conjunction with 30th Interna-\n",
       "tional Joint Conference on Artiﬁcial Intelligence (IJCAI-21)),\n",
       "the participants are challenged to develop methods and sys-\n",
       "tems to assign hypernym and synonyms to ﬁnancial terms by\n",
       "mapping them to one of the 17 high-level ﬁnancial concepts\n",
       "present in FIBO.\n",
       "\n",
       "In this paper, we present the systems developed by our\n",
       "team Lipi for hypernym and synonym assignment. We ex-\n",
       "perimented with basic featurization methods like TF-IDF and\n",
       "advanced methods like pre-trained embedding models. Our\n",
       "top 3 systems use pre-trained FinBERT [Araci, 2019] embed-\n",
       "ding model that was ﬁne-tuned on the data speciﬁc to ﬁnan-\n",
       "cial domain . We also augmented the training data by utilizing\n",
       "the knowledge from DBpedia, Investopedia, FIBO and text\n",
       "corpus of prospectus shared with us. We describe the works\n",
       "related to our solution in the next section. Section 3 contains\n",
       "the formal problem statement, followed by data description\n",
       "in section 4. We describe our top three systems in section 5.\n",
       "Section 6 contains the details of the experimentation that we\n",
       "performed and the results from some of them. We draw our\n",
       "conclusions in section 7 while giving a glimpse of things that\n",
       "we would like to try in the future.\n",
       "\n",
       "2 Related Works\n",
       "\n",
       "Hypernym-hyponym extraction and learning text similarity\n",
       "using semantic representations have been very challenging\n",
       "areas of research for the NLP community. SemEval-2018\n",
       "Task 9 [Camacho-Collados et al., 2018] was such an instance.\n",
       "\n",
       "1https://spec.edmcouncil.org/ﬁbo/\n",
       "2https://sites.google.com/nlg.csie.ntu.edu.tw/ﬁnnlp2021/shared-\n",
       "\n",
       "task-ﬁnsim (accessed on 8th July 2021)\n",
       "\n",
       "Proceedings of the Third Workshop on Financial Technology and Natural Language Processing \n",
       "\n",
       "(FinNLP@IJCAI 2021), pages 46-51, Online, August 19, 2021.     \n",
       "\n",
       "46\n",
       "Team CRIM [Bernier-Colborne and Barri`ere, 2018] per-\n",
       "formed the best in this shared task. They combined a super-\n",
       "vised word embedding based approach with an unsupervised\n",
       "pattern discovery based approach. The FinSim shared tasks\n",
       "[Maarouf et al., 2020; Mansar et al., 2021] deal with adopt-\n",
       "ing these challenges speciﬁc to the Financial Domain. Team\n",
       "IIT-K [Keswani et al., 2020] won FinSim-1 using a combi-\n",
       "nation of context-free static embedding Word2Vec [Mikolov\n",
       "et al., 2013] and contextualized dynamic embedding BERT\n",
       "[Devlin et al., 2019]. Anand et al. [Anand et al., 2020] from\n",
       "the team FINSIM20 explored the use of cosine similarity be-\n",
       "tween terms and labels encoded using Universal Sentence En-\n",
       "coder [Cer et al., 2018]. They also tried to extract hypernyms\n",
       "automatically using graph based approaches. Team PolyU-\n",
       "CBS [Chersoni and Huang, 2021] won FinSim-2 shared\n",
       "task using Logistic Regression trained over word embedding\n",
       "and probabilities derived from BERT [Devlin et al., 2019]\n",
       "model. They also experimented with GPT-2 [Radford et al.,\n",
       "2019]. Team L3i-LBPAM [Nguyen et al., 2021] compris-\n",
       "ing Nguyen et al. performed better than the baseline by us-\n",
       "ing Sentence BERT [Reimers et al., 2019] to calculate co-\n",
       "sine similarity between terms and hypernyms. [Saini, 2020;\n",
       "Pei and Zhang, 2021] and [Jurgens and Pilehvar, 2016] dis-\n",
       "cussed various techniques to enrich the data which was avail-\n",
       "able for training. In this edition of FinSim, the number of\n",
       "training samples and labels (ﬁnancial concepts) were more\n",
       "than the previous two editions.\n",
       "\n",
       "3 Problem Statement\n",
       "Given a set F consisting of n tuples of ﬁnancial\n",
       "terms\n",
       "and their hypernyms/top-level concepts/labels i.e. F =\n",
       "{(t1, h1), (t2, h2), ...(tn, hn)} where hi represents the hyper-\n",
       "nym corresponding to the ith term ti and hi(cid:15) set of labels men-\n",
       "tioned in Table 1. For every unseen ﬁnancial term, our task is\n",
       "to generate a ranked list ˆyi consisting of these 17 hypernyms\n",
       "in order of decreasing semantic similarity.\n",
       "Evaluation Metrics The expected output is a raked list of\n",
       "predicted labels for every scored instance. The proposed sys-\n",
       "tems are evaluated based on Accuracy and Mean Rank met-\n",
       "rices as per the shared task rules. Evaluation script was pro-\n",
       "vided by organizers, where accuracy and mean rank were de-\n",
       "ﬁned as:\n",
       "Accuracy = 1\n",
       "n\n",
       "M eanRank = 1\n",
       "i=1( ˆyi.index(yi))\n",
       "n\n",
       "where ˆyi is the ranked list (with index starting from 1) of pre-\n",
       "dicted labels corresponding to the expected label yi. I is an\n",
       "identity matrix.\n",
       "\n",
       "i=1 I(yi = ˆyi[1])\n",
       "(cid:80)n\n",
       "\n",
       "(cid:80)n\n",
       "\n",
       "4 Data\n",
       "4.1 Data Description\n",
       "The training dataset shared for this task has a total of\n",
       "1050 single and multi-word terms tagged to 17 different\n",
       "classes/labels. More than 91% of the terms have 6 words or\n",
       "less and the longest term has 22 words. There were 10 du-\n",
       "plicate entries, and 3 terms were assigned 2 different labels.\n",
       "Along with this, a corpus of prospectuses in English was pro-\n",
       "vided that had 211 documents. Some of the terms mentioned\n",
       "\n",
       "Label\n",
       "Equity Index\n",
       "Regulatory Agency\n",
       "Credit Index\n",
       "Central Securities Depository\n",
       "Debt pricing and yields\n",
       "Bonds\n",
       "Swap\n",
       "Stock Corporation\n",
       "Option\n",
       "Funds\n",
       "Future\n",
       "Credit Events\n",
       "MMIs\n",
       "Stocks\n",
       "Parametric schedules\n",
       "Forward\n",
       "Securities restrictions\n",
       "Total\n",
       "\n",
       "Count\n",
       "280\n",
       "205\n",
       "125\n",
       "107\n",
       "58\n",
       "55\n",
       "36\n",
       "25\n",
       "24\n",
       "22\n",
       "19\n",
       "18\n",
       "17\n",
       "17\n",
       "15\n",
       "9\n",
       "8\n",
       "1040\n",
       "\n",
       "Table 1: Label distribution in the training set\n",
       "\n",
       "in the training data were present in the corpus. Table 1 shows\n",
       "the distribution of these labels in the training set.\n",
       "\n",
       "4.2 Data Augmentation\n",
       "Since the majority of the terms had only a few tokens, we\n",
       "decided to expand the terms wherever possible using various\n",
       "sources. This approach had also been adopted by [Saini,\n",
       "2020] and [Pei and Zhang, 2021] while participating in\n",
       "FinSim-1 and FinSim-2 respectively.\n",
       "\n",
       "Acronym expansion: As mentioned by Keswani et al.\n",
       "[Keswani et al., 2020], the presence of acronyms created a\n",
       "major issue in maintaining consistency. We used the abbre-\n",
       "viation extractor available in spaCy3[Honnibal et al., 2020]\n",
       "package on the corpus of the prospectus to extract all the\n",
       "acronyms and their expansions. Upon manual inspection of\n",
       "a sample output, we identiﬁed that not all the extracted items\n",
       "were valid acronyms and their expansions. We cleaned the\n",
       "extracted list by dropping the records where:\n",
       "\n",
       "• expansion had equal or less length than the acronym.\n",
       "\n",
       "• expansion had parenthesis\n",
       "\n",
       "• extracted acronym was a valid English word such as\n",
       "\n",
       "”fund” or ”Germany”.\n",
       "\n",
       "• the expansion had less than or equal to 5 characters.\n",
       "\n",
       "We managed to extract 635 acronyms from the prospectus\n",
       "corpus after applying the above exclusions. We used this\n",
       "data to expand the matching terms in the given train set and\n",
       "test sets.\n",
       "\n",
       "Deﬁnitions from DBpedia: We used the DBpedia search\n",
       "API4 to extract the description of the terms present in the\n",
       "\n",
       "3https://spacy.io/\n",
       "4https://lookup.dbpedia.org/api/search\n",
       "\n",
       "47\n",
       "train and test sets. We present such an example in Fig-\n",
       "ure 1. In addition to the description, the label was also re-\n",
       "tained from the result payload to identify the right descrip-\n",
       "tion for the input terms. We tried token overlap-based simi-\n",
       "larity of input terms with both matching labels and descrip-\n",
       "tions. We decided to use the label to term match for descrip-\n",
       "tion matching after going through a randomly drawn sam-\n",
       "ple. We cleaned both input terms and labels from DBpedia\n",
       "results by converting them to lower case, replacing punctua-\n",
       "tions by space, removing repetitive spaces, and singularizing\n",
       "the text. We calculated the token overlap ratios for cleaned\n",
       "term and DBpedia labels using the formulas mentioned be-\n",
       "low: Ratio1 = length(s1 ∩ s2)/length(s1) , Ratio2 =\n",
       "length(s2/length(s1 where s1 and s2 represents sets of to-\n",
       "kenized cleaned terms and tokenized and cleaned DBpedia\n",
       "labels respectively. We empirically decided to use all the in-\n",
       "stances with Ratio1 = 1 and Ratio2 <= 1.25 for matching\n",
       "a DBpedia label (and hence description) to the input term.\n",
       "\n",
       "Deﬁnitions from Investopedia and FIBO: Inspired by\n",
       "[Saini, 2020], we obtained deﬁnitions of the terms present\n",
       "in Investopedia’s data dictionary5 by crawling it. We down-\n",
       "loaded a glossary of ﬁnancial terms from the website of\n",
       "FIBO. We cleaned all the terms from the train and test set and\n",
       "also the terms present in Investopedia’s data dictionary using\n",
       "the steps described in the above DBpedia section. We then as-\n",
       "signed the Investopedia or FIBO deﬁnition to the terms from\n",
       "the train and test sets where cleaned terms from train and test\n",
       "data matched to cleaned Investopedia terms perfectly.\n",
       "\n",
       "The test set which was provided to us had 326 terms. We\n",
       "augmented the original train and test set with the records\n",
       "where we could either ﬁnd deﬁnition or expansion using the\n",
       "above sources. The train set size increased to 1801 records\n",
       "and the test set size increased to 607 after the data augmen-\n",
       "tation. We present an example of data augmentation for the\n",
       "term ”callable bond” in Table 2. Table 3 states the number\n",
       "of instances we used from each of the sources to augment the\n",
       "data we had.\n",
       "\n",
       "5 System Description\n",
       "\n",
       "We tried to solve this problem as the term classiﬁcation and\n",
       "term similarity problems. Two of our 3 submissions are mod-\n",
       "elled as the term classiﬁcation problem, whereas the third sys-\n",
       "tem is designed to be a phrase/sentence similarity problem be-\n",
       "tween terms (or expanded terms from the augmented dataset)\n",
       "and the deﬁnitions of 17 class labels that were extracted from\n",
       "FIBO / Internet. All the systems rely on semantic similarity\n",
       "and use FinBERT model to generate the term or token embed-\n",
       "ding representations. We divided the given data into training\n",
       "and validation sets having 841 and 209 terms respectively.\n",
       "\n",
       "5.1 System - 1 (S1)\n",
       "\n",
       "This is the simplest of our proposed systems, where we did\n",
       "not use the augmented dataset and stuck to the original set that\n",
       "was shared by organizers. We loaded FinBERT pre-trained\n",
       "\n",
       "5https://www.investopedia.com/ﬁnancial-term-dictionary-\n",
       "\n",
       "4769738\n",
       "\n",
       "model and ﬁne-tuned it by trying to classify the representa-\n",
       "tion of [CLS] token into one of the 17 labels mentioned pre-\n",
       "viously. Since the original data did not have longer terms,\n",
       "we kept the maximum length to 32, and train and validation\n",
       "batch sizes of 64. We used Adam optimizer with a learning\n",
       "rate of 0.00002. We ran the model for 40 epochs and picked\n",
       "the model saved after 18th epoch based on the performance on\n",
       "the validation set. Finally, we ranked the predictions based on\n",
       "the predicted probability of each class.\n",
       "\n",
       "5.2 System - 2 (S2)\n",
       "\n",
       "This system is similar to System-1 with the only difference\n",
       "that data being the augmented set and not the original dataset.\n",
       "Since the augmented dataset has the descriptions of the terms,\n",
       "the input is considerably longer. Hence, we increased the\n",
       "maximum length to 256 while keeping all the other hyper-\n",
       "parameters the same. After, training the model for 40 epochs\n",
       "we selected the model saved after the 17th epoch as the best\n",
       "model based on validation set performance.\n",
       "\n",
       "5.3 System -3 (S3)\n",
       "\n",
       "We explored the FIBO ontology to understand the hierarchy\n",
       "[Stepiˇsnik Perdih et al., 2021] of the 17 labels as depicted\n",
       "in Figure 2. We used the augmented data described in sec-\n",
       "tion 4.2 to create a labelled dataset having similarity scores.\n",
       "For every term deﬁnition (T) to label deﬁnition (L) mapping\n",
       "which existed in the extended training set, we assigned a sim-\n",
       "ilarity score of 1.0 to the (T,L) pair and picked up 10 train-\n",
       "ing instances randomly ensuring none of their label deﬁnition\n",
       "was same as L. For each of the label deﬁnitions (LL) present\n",
       "in this sample, we extracted its root node and ﬁrst child node.\n",
       "We did the same for the original label deﬁnition (L). Then, we\n",
       "compared these nodes. If the root node and ﬁrst child node of\n",
       "L were different from that of LL then we assigned a similar-\n",
       "ity score of 0 to the (T, LL) pair. If the root nodes were the\n",
       "same, we assigned a similarity score of ’k’ when the ﬁrst child\n",
       "nodes differed and a similarity score of ’2k’ when they were\n",
       "the same (where 0 < k < 1). We empirically ﬁgured out that\n",
       "k=0.4 works the best. As expected, the number of instances\n",
       "with a similarity score equal to 0 increased substantially. We\n",
       "under-sampled such instances and the new training set had\n",
       "30% instances with similarity score 1.0, 12% instances with\n",
       "similarity score ’k’, 28% instances with similarity score ’2k’\n",
       "and 30% instances with similarity score 0. After that, we ﬁne-\n",
       "tuned a FinBERT [Araci, 2019] model using Sentence BERT\n",
       "[Reimers et al., 2019] framework with this newly generated\n",
       "labelled data for 25 epochs with a batch size of 20. Our ob-\n",
       "jective was to minimize the multiple negatives ranking loss\n",
       "and online contrastive loss. We used a margin of 0.5 and co-\n",
       "sine distance as a distance metric while training this model.\n",
       "Finally, we converted all of the 17 labels’ deﬁnitions and term\n",
       "deﬁnitions from the validation set to vectors using this ﬁne-\n",
       "tuned model. For every such term deﬁnition, we performed\n",
       "a semantic search over the label vectors and ranked them in\n",
       "decreasing order of similarity.\n",
       "System 2 and 3 take advantage of term expansion during both\n",
       "model training and scoring phases, which causes certain ob-\n",
       "servations to appear more than once (reference: Table 3). We\n",
       "\n",
       "48\n",
       "Figure 1: Sample output from DBpedia search API\n",
       "\n",
       "Expanded Term/Term Deﬁnition\n",
       "\n",
       "Callable bond\n",
       "\n",
       "bond that includes a stipulation allowing the issuer\n",
       "the right to repurchase and retire the bond at the call price after the call protection period\n",
       "A callable bond (also called redeemable bond) is a type of bond (debt security) that allows\n",
       "the issuer of the bond to retain the privilege of redeeming the bond at some point before\n",
       "the bond reaches its date of maturity.\n",
       "\n",
       "Table 2: Result of Data Augmentation of the term ”Callable bond”\n",
       "\n",
       "Label\n",
       "\n",
       "Bonds\n",
       "\n",
       "Source\n",
       "original and\n",
       "acronym expansion\n",
       "\n",
       "Bonds\n",
       "\n",
       "FIBO\n",
       "\n",
       "Bonds DBpedia\n",
       "\n",
       "Data Source\n",
       "Original modelling data\n",
       "DBpedia\n",
       "FIBO\n",
       "Investopedia\n",
       "Acronym expansion\n",
       "\n",
       "Count\n",
       "1040\n",
       "257\n",
       "236\n",
       "85\n",
       "218\n",
       "\n",
       "Table 3: Details of various data sources\n",
       "\n",
       "derive the ﬁnal prediction by averaging the output probabili-\n",
       "ties for all the 17 classes for all the occurrences of the term.\n",
       "\n",
       "6 Experimentation and Results\n",
       "We had 1040 observations after removing the duplicates. We\n",
       "did an 80:20 split to create a training and validation set from\n",
       "this. We augmented the given modelling set by incorporating\n",
       "deﬁnitions from DBpedia, FIBO and Investopedia. We used\n",
       "the list of acronyms extracted from the prospectus corpus to\n",
       "create a copy with acronym expansion. This helped us to in-\n",
       "crease the original data to 1836 records (mentioned in Table\n",
       "1). It should be noted that we could not ﬁnd the expansions\n",
       "for all the terms given in the modelling set. Train and valida-\n",
       "tion set sizes for the original modelling set and expanded data\n",
       "were (832 & 208) and (1469 & 366) respectively.\n",
       "\n",
       "We established a baseline by running the scripts provided\n",
       "by the organizers. Then, we considered original modelling\n",
       "data and ﬁne-tuned base BERT-cased model [Devlin et al.,\n",
       "2019] to predict the class label by taking the representa-\n",
       "tion of [CLS] token while passing it through few layers of\n",
       "a feed-forward network. This performed better than base-\n",
       "line. We then tried the same BERT-base model on the ex-\n",
       "panded dataset, which gave us further performance improve-\n",
       "ment. Since the only change between these runs was the data,\n",
       "\n",
       "the improvement can be attributed to the expanded data.\n",
       "\n",
       "We experimented with a few of the other pre-trained mod-\n",
       "els that are available on the Huggingface model repository\n",
       "[Wolf et al., 2020]. We observed clear improvement when\n",
       "we used the FinBERT model which was trained on data spe-\n",
       "ciﬁc to the ﬁnancial domain. The model performance succes-\n",
       "sively increased when we used a combination of data expan-\n",
       "sion with FinBERT. Furthermore, we tried to ﬁne-tune Fin-\n",
       "BERT using Sentence Transformers [Reimers et al., 2019] to\n",
       "capture semantic textual similarity. For this, we used several\n",
       "combinations of term and term deﬁnitions with label and la-\n",
       "bel deﬁnitions.\n",
       "\n",
       "All the hyperparameters for the ﬁnal 3 models are already\n",
       "given in the system description. After rigorous experimenta-\n",
       "tion, these hyperparameters were selected empirically based\n",
       "on validation set performance. The results are presented in\n",
       "Table 4. Since the number of submissions was restricted to\n",
       "3 for each team, we do not have the performance numbers of\n",
       "the BERT models in the test set. Analysing the results we see\n",
       "that SentenceBERT trained with FinBERT at the backed as\n",
       "mentioned in section-5.3 performed the best.\n",
       "\n",
       "7 Conclusion and Future Works\n",
       "In this work, we attempted to solve the hypernym and syn-\n",
       "onym discovery hosted at FinSim-3. This challenge aimed\n",
       "to enable the better use of ontologies like FIBO using hy-\n",
       "pernyms and synonyms, and we used these ontologies them-\n",
       "selves to develop our systems which perform signiﬁcantly\n",
       "better than the provided baseline systems. This proves the\n",
       "present use of these ontologies. The presented solution is\n",
       "recursive in a sense as it uses knowledge from ontologies\n",
       "to further increase the effectiveness and use of the same.\n",
       "Apart from data augmentation, our solution relies upon se-\n",
       "mantic similarity learnt from pre-trained embedding models\n",
       "\n",
       "49\n",
       "Figure 2: Label Hierarchy from FIBO. Bold (leaf nodes) denotes the labels.\n",
       "\n",
       "Validation set Test set\n",
       "\n",
       "Data Rank Acc.\n",
       "Model\n",
       "0.498\n",
       "2.158\n",
       "Org.\n",
       "Base-1\n",
       "0.876\n",
       "1.201\n",
       "Org.\n",
       "Base-2\n",
       "0.899\n",
       "1.177\n",
       "Org.\n",
       "BERT\n",
       "0.928\n",
       "1.153\n",
       "BERT\n",
       "Ext.\n",
       "0.928\n",
       "1.117\n",
       "FinBERT(S1) Org.\n",
       "0.942\n",
       "1.110\n",
       "FinBERT(S2) Ext.\n",
       "0.947\n",
       "1.086\n",
       "Ext.\n",
       "SBERT(S3)\n",
       "\n",
       "Rank Acc.\n",
       "0.564\n",
       "1.941\n",
       "0.669\n",
       "1.75\n",
       "-\n",
       "-\n",
       "-\n",
       "-\n",
       "0.886\n",
       "1.257\n",
       "0.895\n",
       "1.220\n",
       "0.917\n",
       "1.156\n",
       "\n",
       "Table 4: Results on validation and test set. Org. represents original\n",
       "and Ext. represents extended. Base refers to baseline.\n",
       "\n",
       "that were learnt on the relevant domain. We observed the\n",
       "clear beneﬁts of domain speciﬁc pretraining during the ex-\n",
       "perimentation.\n",
       "\n",
       "In future, we would like to explore Knowledge Graphs (as\n",
       "described in [Portisch et al., 2021]) to further improve the\n",
       "improve performance of the models. We also want to ex-\n",
       "plore other variants of FinBERT [Araci, 2019] and ﬁne-tune\n",
       "them using the Masked Language Modeling technique (as\n",
       "mentioned by the winner of FinSim-2 [Chersoni and Huang,\n",
       "2021]) and Next Sentence Prediction objective. Moreover,\n",
       "this research can be extended by extracting sentences present\n",
       "in the prospectus (similar to [Goel et al., 2021]) to create pos-\n",
       "itive and negative samples.\n",
       "\n",
       "References\n",
       "[Anand et al., 2020] Vivek Anand, Yash Agrawal, Aarti Pol,\n",
       "and Vasudeva Varma. FINSIM20 at the FinSim task: Mak-\n",
       "ing sense of text in ﬁnancial domain. In Proceedings of\n",
       "the Second Workshop on Financial Technology and Natu-\n",
       "ral Language Processing, pages 104–107, Kyoto, Japan, 5\n",
       "January 2020.\n",
       "\n",
       "[Araci, 2019] Dogu Araci.\n",
       "\n",
       "Finbert: Financial sentiment\n",
       "\n",
       "analysis with pre-trained language models, 2019.\n",
       "\n",
       "[Auer et al., 2007] S¨oren Auer, Christian Bizer, Georgi Ko-\n",
       "bilarov, Jens Lehmann, Richard Cyganiak, and Zachary\n",
       "Ives. Dbpedia: A nucleus for a web of open data, 2007.\n",
       "\n",
       "[Bernier-Colborne and Barri`ere, 2018] Gabriel\n",
       "\n",
       "Bernier-\n",
       "Colborne and Caroline Barri`ere. CRIM at SemEval-2018\n",
       "task 9: A hybrid approach to hypernym discovery. In Pro-\n",
       "ceedings of The 12th International Workshop on Semantic\n",
       "Evaluation, pages 725–731, New Orleans, Louisiana,\n",
       "June 2018. Association for Computational Linguistics.\n",
       "\n",
       "[Camacho-Collados et al., 2018] Jose Camacho-Collados,\n",
       "Claudio Delli Bovi, Luis Espinosa-Anke, Sergio Oramas,\n",
       "Tommaso Pasini, Enrico Santus, Vered Shwartz, Roberto\n",
       "Navigli, and Horacio Saggion. SemEval-2018 task 9:\n",
       "Hypernym discovery. In Proceedings of The 12th Interna-\n",
       "tional Workshop on Semantic Evaluation, pages 712–724,\n",
       "New Orleans, Louisiana, June 2018. Association for\n",
       "Computational Linguistics.\n",
       "\n",
       "[Cer et al., 2018] Daniel Cer, Yinfei Yang, Sheng yi Kong,\n",
       "Nan Hua, Nicole Limtiaco, Rhomni St. John, Noah Con-\n",
       "stant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar,\n",
       "Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil. Uni-\n",
       "versal sentence encoder, 2018.\n",
       "\n",
       "[Chersoni and Huang, 2021] Emmanuele Chersoni and Chu-\n",
       "Ren Huang. PolyU-CBS at the FinSim-2 Task: Combin-\n",
       "ing Distributional, String-Based and Transformers-Based\n",
       "Features for Hypernymy Detection in the Financial Do-\n",
       "main, page 316–319. Association for Computing Machin-\n",
       "ery, New York, NY, USA, 2021.\n",
       "\n",
       "[Devlin et al., 2019] Jacob Devlin, Ming-Wei Chang, Ken-\n",
       "ton Lee, and Kristina Toutanova. BERT: Pre-training of\n",
       "deep bidirectional transformers for language understand-\n",
       "ing. In Proceedings of the 2019 Conference of the North\n",
       "American Chapter of the Association for Computational\n",
       "Linguistics: Human Language Technologies, Volume 1\n",
       "(Long and Short Papers), pages 4171–4186, Minneapo-\n",
       "lis, Minnesota, June 2019. Association for Computational\n",
       "Linguistics.\n",
       "\n",
       "[Goel et al., 2021] Tushar Goel, Vipul Chauhan,\n",
       "\n",
       "Ishan\n",
       "Verma, Tirthankar Dasgupta, and Lipika Dey. TCS WITM\n",
       "2021 @FinSim-2: Transformer Based Models for Auto-\n",
       "matic Classiﬁcation of Financial Terms, page 311–315.\n",
       "\n",
       "50\n",
       "In Companion Pro-\n",
       "cial data with customized corpus.\n",
       "ceedings of the Web Conference 2021, WWW ’21, page\n",
       "307–310, New York, NY, USA, 2021. Association for\n",
       "Computing Machinery.\n",
       "\n",
       "[Portisch et al., 2021] Jan Portisch, Michael Hladik, and\n",
       "Heiko Paulheim. FinMatcher at FinSim-2: Hypernym De-\n",
       "tection in the Financial Services Domain Using Knowl-\n",
       "edge Graphs, page 293–297. Association for Computing\n",
       "Machinery, New York, NY, USA, 2021.\n",
       "\n",
       "[Radford et al., 2019] Alec Radford, Jeff Wu, Rewon Child,\n",
       "David Luan, Dario Amodei, and Ilya Sutskever. Language\n",
       "models are unsupervised multitask learners, 2019.\n",
       "\n",
       "[Reimers et al., 2019] Nils Reimers, Iryna Gurevych, Nils\n",
       "Reimers, Iryna Gurevych, Nandan Thakur, Nils Reimers,\n",
       "Johannes Daxenberger, and Iryna Gurevych. Sentence-\n",
       "bert: Sentence embeddings using siamese bert-networks.\n",
       "In Proceedings of the 2019 Conference on Empirical\n",
       "Methods in Natural Language Processing. Association for\n",
       "Computational Linguistics, 2019.\n",
       "\n",
       "[Saini, 2020] Anuj Saini.\n",
       "\n",
       "Anuj at\n",
       "\n",
       "the FinSim task:\n",
       "Anuj@FINSIM¡VLearning semantic representation of ﬁ-\n",
       "nancial domain with investopedia. In Proceedings of the\n",
       "Second Workshop on Financial Technology and Natural\n",
       "Language Processing, pages 93–97, Kyoto, Japan, 5 Jan-\n",
       "uary 2020.\n",
       "\n",
       "[Stepiˇsnik Perdih et al., 2021] Timen\n",
       "\n",
       "Perdih,\n",
       "Senja Pollak, and Blaˇz ˇSkrlj. JSI at the FinSim-2 Task:\n",
       "Ontology-Augmented Financial Concept Classiﬁcation,\n",
       "page 298–301. Association for Computing Machinery,\n",
       "New York, NY, USA, 2021.\n",
       "\n",
       "Stepiˇsnik\n",
       "\n",
       "[Wolf et al., 2020] Thomas Wolf, Lysandre Debut, Victor\n",
       "Sanh, Julien Chaumond, Clement Delangue, Anthony\n",
       "Moi, Pierric Cistac, Tim Rault, R´emi Louf, Morgan\n",
       "Funtowicz,\n",
       "Joe Davison, Sam Shleifer, Patrick von\n",
       "Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen\n",
       "Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame,\n",
       "Quentin Lhoest, and Alexander M. Rush. Huggingface’s\n",
       "transformers: State-of-the-art natural language processing,\n",
       "2020.\n",
       "\n",
       "Association for Computing Machinery, New York, NY,\n",
       "USA, 2021.\n",
       "\n",
       "[Hahm et al., 2014] Younggyun Hahm,\n",
       "\n",
       "Jungyeul Park,\n",
       "Kyungtae Lim, Youngsik Kim, Dosam Hwang, and\n",
       "Key-Sun Choi. Named entity corpus construction us-\n",
       "In LREC, pages\n",
       "ing wikipedia and dbpedia ontology.\n",
       "2565–2569, 2014.\n",
       "\n",
       "[Honnibal et al., 2020] Matthew Honnibal,\n",
       "\n",
       "Ines Montani,\n",
       "Soﬁe Van Landeghem, and Adriane Boyd.\n",
       "spaCy:\n",
       "Industrial-strength Natural Language Processing in\n",
       "Python, 2020.\n",
       "\n",
       "[Jurgens and Pilehvar, 2016] David Jurgens and Moham-\n",
       "mad Taher Pilehvar. SemEval-2016 task 14: Semantic\n",
       "taxonomy enrichment. In Proceedings of the 10th Interna-\n",
       "tional Workshop on Semantic Evaluation (SemEval-2016),\n",
       "pages 1092–1102, San Diego, California, June 2016. As-\n",
       "sociation for Computational Linguistics.\n",
       "\n",
       "[Keswani et al., 2020] Vishal Keswani, Sakshi Singh, and\n",
       "Ashutosh Modi. IITK at the FinSim task: Hypernym de-\n",
       "tection in ﬁnancial domain via context-free and contextu-\n",
       "In Proceedings of the Second\n",
       "alized word embeddings.\n",
       "Workshop on Financial Technology and Natural Language\n",
       "Processing, pages 87–92, Kyoto, Japan, 5 January 2020.\n",
       "[Kobilarov et al., 2009] Georgi Kobilarov, Tom Scott, Yves\n",
       "Raimond, Silver Oliver, Chris Sizemore, Michael\n",
       "Smethurst, Christian Bizer, and Robert Lee. Media\n",
       "meets semantic web – how the bbc uses dbpedia and\n",
       "linked data to make connections.\n",
       "In Lora Aroyo, Paolo\n",
       "Traverso, Fabio Ciravegna, Philipp Cimiano, Tom Heath,\n",
       "Eero Hyv¨onen, Riichiro Mizoguchi, Eyal Oren, Marta\n",
       "Sabou, and Elena Simperl, editors, The Semantic Web: Re-\n",
       "search and Applications, pages 723–737, Berlin, Heidel-\n",
       "berg, 2009. Springer Berlin Heidelberg.\n",
       "\n",
       "[Maarouf et al., 2020] Ismail El Maarouf, Youness Mansar,\n",
       "Virginie Mouilleron, and Dialekti Valsamou-Stanislawski.\n",
       "The FinSim 2020 shared task: Learning semantic repre-\n",
       "sentations for the ﬁnancial domain. In Proceedings of the\n",
       "Second Workshop on Financial Technology and Natural\n",
       "Language Processing, pages 81–86, Kyoto, Japan, 5 Jan-\n",
       "uary 2020.\n",
       "\n",
       "[Mansar et al., 2021] Youness Mansar, Juyeon Kang, and Is-\n",
       "mail El Maarouf. The FinSim-2 2021 Shared Task: Learn-\n",
       "ing Semantic Similarities for the Financial Domain, page\n",
       "288–292. Association for Computing Machinery, New\n",
       "York, NY, USA, 2021.\n",
       "\n",
       "[Mikolov et al., 2013] Tomas Mikolov, Kai Chen, Greg Cor-\n",
       "rado, and Jeffrey Dean. Efﬁcient estimation of word rep-\n",
       "resentations in vector space, 2013.\n",
       "\n",
       "[Nguyen et al., 2021] Nhu Khoa Nguyen, Emanuela Boros,\n",
       "Gael Lejeune, Antoine Doucet, and Thierry Delahaut. L3i\n",
       "LBPAM at the FinSim-2 Task: Learning Financial Seman-\n",
       "tic Similarities with Siamese Transformers, page 302–306.\n",
       "Association for Computing Machinery, New York, NY,\n",
       "USA, 2021.\n",
       "\n",
       "[Pei and Zhang, 2021] Yulong Pei and Qian Zhang. Goat at\n",
       "the ﬁnsim-2 task: Learning word representations of ﬁnan-\n",
       "\n",
       "51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_Anth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1ba780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(doc_Arxiv == doc_Anth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32fb130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_13936/292443956.py:1: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  doc_Arxiv.similarity(doc_Anth)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_Arxiv.similarity(doc_Anth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e5469",
   "metadata": {},
   "source": [
    "# Removing cleaning\n",
    "https://betterprogramming.pub/the-beginners-guide-to-similarity-matching-using-spacy-782fc2922f7c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9705edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad40d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the default stopwords list to a variable\n",
    "STOP_WORDS = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97e26f6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thru', 'around', 'fifty', 'should', 'seemed', 'sometimes', 'there', 'then', 'always', 'often', 'up', 'until', '‘s', 'thence', 'or', 'not', 'eight', 'nothing', 'even', 'whence', 'almost', 'am', 'serious', 'many', 'here', 'anyone', 'same', 'front', 'two', 'using', 'because', 'whose', 'before', 'and', 'below', 'does', 'everything', 'my', 'moreover', \"'re\", 'see', 'nobody', 'while', 'have', 'made', 'wherever', 'each', 'ten', 'whether', 'was', 'latterly', 'next', 'on', 'part', '‘d', 'neither', 'already', 'has', 'toward', 'per', 'another', 'ours', 'formerly', \"'ll\", 'full', 'first', 'used', 'eleven', \"n't\", 'cannot', 'regarding', 'become', 'again', 'your', 'if', 'an', 'seem', 'him', \"'m\", 'whatever', 'keep', 'twenty', 'thereupon', 'but', 'once', 'beside', 'former', 'behind', 'could', 'it', 'therein', 'that', 'becoming', 'whereafter', 'unless', 'whereas', 'whereupon', 'within', 'with', 'against', 'are', 'over', 'whereby', 'these', 'themselves', 'really', 'therefore', \"'s\", 'amongst', 'third', 'thereby', 'thus', 'at', 'only', 'yourself', 'one', 'three', 'four', 'twelve', 'thereafter', 'anyway', 'upon', 'enough', 'show', 'he', 'about', 'via', 'afterwards', 'been', 'i', 'very', 'may', 'meanwhile', 'of', 'done', 'hundred', 'their', 'due', 'its', 'herein', 'few', 'down', 'elsewhere', 'well', 'between', '‘ll', 'our', 'noone', 'indeed', 'take', 'more', 'anyhow', 'being', 'somewhere', 'off', 'last', 'call', 'hereafter', 'his', 'all', 'still', 'doing', 'own', 'several', 'although', 'name', \"'d\", 're', 'to', 'others', 'further', \"'ve\", 'any', 'will', 'anything', 'perhaps', 'who', 'among', 'now', 'nor', 'so', '’ll', 'were', '’d', 'none', 'yourselves', 'quite', 'in', 'some', 'alone', 'whither', 'beforehand', 'either', 'hers', 'n’t', 'most', 'after', 'also', 'besides', 'her', '‘re', 'something', 'by', 'mostly', 'else', 'can', 'than', 'for', 'please', 'hence', 'had', 'beyond', 'least', '’ve', 'from', 'just', 'throughout', 'five', 'together', '’s', 'ever', 'whom', 'less', 'onto', 'as', 'towards', 'other', '’m', 'nevertheless', 'much', 'go', 'sixty', 'whoever', 'what', 'whenever', 'which', 'the', 'is', 'along', 'top', 'move', 'fifteen', 'would', 'no', '’re', 'do', 'somehow', 'everywhere', 'bottom', 'anywhere', 'though', 'ca', 'hereby', 'herself', 'without', 'six', 'might', 'through', 'did', 'yours', 'why', 'this', 'never', 'they', 'wherein', 'since', 'rather', 'amount', 'those', 'everyone', 'put', 'nine', 'nowhere', 'someone', 'otherwise', 'seems', 'however', 'get', '‘m', 'them', 'various', 'itself', 'both', 'give', 'where', 'hereupon', 'became', 'myself', 'say', 'latter', 'out', 'namely', 'side', 'n‘t', 'whole', 'except', 'you', 'be', 'she', 'sometime', 'make', 'must', 'becomes', 'forty', 'seeming', 'across', 'such', 'we', 'how', 'during', 'every', 'a', 'us', 'above', '‘ve', 'ourselves', 'me', 'under', 'mine', 'yet', 'when', 'into', 'himself', 'back', 'too', 'empty'}\n"
     ]
    }
   ],
   "source": [
    "#nlp refers to the name of the model loaded, change the name accordingly\n",
    "#nlp = en_core_web_lg.load() or nlp = spacy.load(\"en_core_web_lg\")\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f3697db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    doc = nlp(text.lower()) #1\n",
    "    result = [] #2\n",
    "    for token in doc: #3\n",
    "        if token.text in nlp.Defaults.stop_words: #4\n",
    "            continue\n",
    "        result.append(token.text)#5\n",
    "    return \" \".join(result) #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3955d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_fast(text):\n",
    "    doc = nlp(text.lower())\n",
    "    result = [token.text for token in doc if token.text not in nlp.Defaults.stop_words]\n",
    "#     result = [token.text for token in doc if token.text not in ['\\n', '\\n\\n']]\n",
    "#     return \" \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f586c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"Thanks for the cool story bro!\"\n",
    "# %timeit remove_stopwords(sample)\n",
    "# %timeit remove_stopwords_fast(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102c363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = %timeit remove_stopwords_fast(str(doc_Anth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cc583af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks cool story bro !'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98f9c1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thanks', 'for', 'the', 'cool', 'story', 'bro', '!']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords_fast(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02c76909",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anth_lst = remove_stopwords_fast(str(doc_Anth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b29857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arx_lst = remove_stopwords_fast(str(doc_Arxiv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "894f2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = []\n",
    "diff = []\n",
    "for x in range(len(Anth_lst)):\n",
    "    if Anth_lst[-x] == Arx_lst[-x]:\n",
    "        i.append(Anth_lst[x])\n",
    "    else:\n",
    "        diff.append((Anth_lst[-x], Arx_lst[-x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "835692b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8733a6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\x0c', '\\n\\n\\x0c'),\n",
       " ('51', '.'),\n",
       " ('ﬁnan-', '2021'),\n",
       " ('of', ','),\n",
       " ('representations', 'usa'),\n",
       " ('word', ','),\n",
       " ('learning', 'ny'),\n",
       " (':', ','),\n",
       " ('task', 'york'),\n",
       " ('ﬁnsim-2', 'new'),\n",
       " ('the', ','),\n",
       " ('at', 'machinery'),\n",
       " ('goat', 'computing'),\n",
       " ('.', 'for'),\n",
       " ('zhang', 'association'),\n",
       " ('qian', '.'),\n",
       " ('and', '302–306'),\n",
       " ('pei', 'page'),\n",
       " ('yulong', ','),\n",
       " (']', 'transformers'),\n",
       " ('2021', 'siamese'),\n",
       " (',', 'with'),\n",
       " ('zhang', 'similarities'),\n",
       " ('and', 'tic'),\n",
       " ('pei', 'seman-'),\n",
       " ('[', 'financial'),\n",
       " ('.', 'learning'),\n",
       " ('2021', ':'),\n",
       " (',', 'task'),\n",
       " ('usa', 'finsim-2'),\n",
       " (',', 'the'),\n",
       " ('ny', 'at'),\n",
       " (',', 'lbpam'),\n",
       " ('york', 'l3i'),\n",
       " ('new', '.'),\n",
       " (',', 'delahaut'),\n",
       " ('machinery', 'thierry'),\n",
       " ('computing', 'and'),\n",
       " ('for', ','),\n",
       " ('association', 'doucet'),\n",
       " ('.', 'antoine'),\n",
       " ('302–306', ','),\n",
       " ('page', 'lejeune'),\n",
       " (',', 'gael'),\n",
       " ('transformers', ','),\n",
       " ('siamese', 'boros'),\n",
       " ('with', 'emanuela'),\n",
       " ('similarities', ','),\n",
       " ('tic', 'nguyen'),\n",
       " ('seman-', 'khoa'),\n",
       " ('financial', 'nhu'),\n",
       " ('learning', ']'),\n",
       " (':', '2021'),\n",
       " ('task', ','),\n",
       " ('finsim-2', '.'),\n",
       " ('the', 'al'),\n",
       " ('at', 'et'),\n",
       " ('lbpam', 'nguyen'),\n",
       " ('l3i', '['),\n",
       " ('delahaut', '2013'),\n",
       " ('thierry', ','),\n",
       " ('and', 'space'),\n",
       " (',', 'vector'),\n",
       " ('doucet', 'in'),\n",
       " ('antoine', 'resentations'),\n",
       " (',', 'rep-'),\n",
       " ('lejeune', 'word'),\n",
       " ('gael', 'of'),\n",
       " (',', 'estimation'),\n",
       " ('boros', 'efﬁcient'),\n",
       " ('emanuela', '.'),\n",
       " (',', 'dean'),\n",
       " ('nguyen', 'jeffrey'),\n",
       " ('khoa', 'and'),\n",
       " ('nhu', ','),\n",
       " (']', 'rado'),\n",
       " ('2021', 'cor-'),\n",
       " (',', 'greg'),\n",
       " ('.', ','),\n",
       " ('al', 'chen'),\n",
       " ('et', 'kai'),\n",
       " ('nguyen', ','),\n",
       " ('[', 'mikolov'),\n",
       " ('.', 'tomas'),\n",
       " ('2013', ']'),\n",
       " (',', '2013'),\n",
       " ('space', ','),\n",
       " ('vector', '.'),\n",
       " ('in', 'al'),\n",
       " ('resentations', 'et'),\n",
       " ('rep-', 'mikolov'),\n",
       " ('word', '['),\n",
       " ('of', '.'),\n",
       " ('estimation', '2021'),\n",
       " ('efﬁcient', ','),\n",
       " ('.', 'usa'),\n",
       " ('dean', ','),\n",
       " ('jeffrey', 'ny'),\n",
       " ('and', ','),\n",
       " (',', 'york'),\n",
       " ('rado', 'new'),\n",
       " ('cor-', ','),\n",
       " ('greg', 'machinery'),\n",
       " (',', 'computing'),\n",
       " ('chen', 'for'),\n",
       " ('kai', 'association'),\n",
       " (',', '.'),\n",
       " ('mikolov', '288–292'),\n",
       " ('tomas', 'page'),\n",
       " (']', ','),\n",
       " ('2013', 'domain'),\n",
       " (',', 'financial'),\n",
       " ('.', 'the'),\n",
       " ('al', 'for'),\n",
       " ('et', 'similarities'),\n",
       " ('mikolov', 'semantic'),\n",
       " ('[', 'ing'),\n",
       " ('.', 'learn-'),\n",
       " ('2021', ':'),\n",
       " (',', 'task'),\n",
       " ('usa', 'shared'),\n",
       " (',', '2021'),\n",
       " ('ny', 'finsim-2'),\n",
       " (',', 'the'),\n",
       " ('york', '.'),\n",
       " ('new', 'maarouf'),\n",
       " (',', 'el'),\n",
       " ('machinery', 'mail'),\n",
       " ('computing', 'is-'),\n",
       " ('for', 'and'),\n",
       " ('association', ','),\n",
       " ('.', 'kang'),\n",
       " ('288–292', 'juyeon'),\n",
       " ('page', ','),\n",
       " (',', 'mansar'),\n",
       " ('domain', 'youness'),\n",
       " ('financial', ']'),\n",
       " ('the', '2021'),\n",
       " ('for', ','),\n",
       " ('similarities', '.'),\n",
       " ('semantic', 'al'),\n",
       " ('ing', 'et'),\n",
       " ('learn-', 'mansar'),\n",
       " (':', '['),\n",
       " ('task', '.'),\n",
       " ('shared', '2020'),\n",
       " ('2021', 'uary'),\n",
       " ('finsim-2', 'jan-'),\n",
       " ('the', '5'),\n",
       " ('.', ','),\n",
       " ('maarouf', 'japan'),\n",
       " ('el', ','),\n",
       " ('mail', 'kyoto'),\n",
       " ('is-', ','),\n",
       " ('and', '81–86'),\n",
       " (',', 'pages'),\n",
       " ('kang', ','),\n",
       " ('juyeon', 'processing'),\n",
       " (',', 'language'),\n",
       " ('mansar', 'natural'),\n",
       " ('youness', 'and'),\n",
       " (']', 'technology'),\n",
       " ('2021', 'financial'),\n",
       " (',', 'on'),\n",
       " ('.', 'workshop'),\n",
       " ('al', 'second'),\n",
       " ('et', 'the'),\n",
       " ('mansar', 'of'),\n",
       " ('[', 'proceedings'),\n",
       " ('.', 'in'),\n",
       " ('2020', '.'),\n",
       " ('uary', 'domain'),\n",
       " ('jan-', 'ﬁnancial'),\n",
       " ('5', 'the'),\n",
       " (',', 'for'),\n",
       " ('japan', 'sentations'),\n",
       " (',', 'repre-'),\n",
       " ('kyoto', 'semantic'),\n",
       " (',', 'learning'),\n",
       " ('81–86', ':'),\n",
       " ('pages', 'task'),\n",
       " (',', 'shared'),\n",
       " ('processing', '2020'),\n",
       " ('language', 'finsim'),\n",
       " ('natural', 'the'),\n",
       " ('and', '.'),\n",
       " ('technology', 'stanislawski'),\n",
       " ('financial', '-'),\n",
       " ('on', 'valsamou'),\n",
       " ('workshop', 'dialekti'),\n",
       " ('second', 'and'),\n",
       " ('the', ','),\n",
       " ('of', 'mouilleron'),\n",
       " ('proceedings', 'virginie'),\n",
       " ('in', ','),\n",
       " ('.', 'mansar'),\n",
       " ('domain', 'youness'),\n",
       " ('ﬁnancial', ','),\n",
       " ('the', 'maarouf'),\n",
       " ('for', 'el'),\n",
       " ('sentations', 'ismail'),\n",
       " ('repre-', ']'),\n",
       " ('semantic', '2020'),\n",
       " ('learning', ','),\n",
       " (':', '.'),\n",
       " ('task', 'al'),\n",
       " ('shared', 'et'),\n",
       " ('2020', 'maarouf'),\n",
       " ('finsim', '['),\n",
       " ('the', '.'),\n",
       " ('.', 'heidelberg'),\n",
       " ('stanislawski', 'berlin'),\n",
       " ('-', 'springer'),\n",
       " ('valsamou', '.'),\n",
       " ('dialekti', '2009'),\n",
       " ('and', ','),\n",
       " (',', 'berg'),\n",
       " ('mouilleron', 'heidel-'),\n",
       " ('virginie', ','),\n",
       " (',', 'berlin'),\n",
       " ('mansar', ','),\n",
       " ('youness', '723–737'),\n",
       " (',', 'pages'),\n",
       " ('maarouf', ','),\n",
       " ('el', 'applications'),\n",
       " ('ismail', 'and'),\n",
       " (']', 'search'),\n",
       " ('2020', 're-'),\n",
       " (',', ':'),\n",
       " ('.', 'web'),\n",
       " ('al', 'semantic'),\n",
       " ('et', 'the'),\n",
       " ('maarouf', ','),\n",
       " ('[', 'editors'),\n",
       " ('.', ','),\n",
       " ('heidelberg', 'simperl'),\n",
       " ('berlin', 'elena'),\n",
       " ('springer', 'and'),\n",
       " ('.', ','),\n",
       " ('2009', 'sabou'),\n",
       " (',', 'marta'),\n",
       " ('berg', ','),\n",
       " ('heidel-', 'oren'),\n",
       " (',', 'eyal'),\n",
       " ('berlin', ','),\n",
       " (',', 'mizoguchi'),\n",
       " ('723–737', 'riichiro'),\n",
       " ('pages', ','),\n",
       " (',', 'hyv¨onen'),\n",
       " ('applications', 'eero'),\n",
       " ('and', ','),\n",
       " ('search', 'heath'),\n",
       " ('re-', 'tom'),\n",
       " (':', ','),\n",
       " ('web', 'cimiano'),\n",
       " ('semantic', 'philipp'),\n",
       " ('the', ','),\n",
       " (',', 'ciravegna'),\n",
       " ('editors', 'fabio'),\n",
       " ('simperl', 'traverso'),\n",
       " ('elena', 'paolo'),\n",
       " ('and', ','),\n",
       " (',', 'aroyo'),\n",
       " ('sabou', 'lora'),\n",
       " ('marta', 'in'),\n",
       " (',', '.'),\n",
       " ('oren', 'connections'),\n",
       " ('eyal', 'make'),\n",
       " (',', 'to'),\n",
       " ('mizoguchi', 'data'),\n",
       " ('riichiro', 'linked'),\n",
       " (',', 'and'),\n",
       " ('hyv¨onen', 'dbpedia'),\n",
       " ('eero', 'uses'),\n",
       " (',', 'bbc'),\n",
       " ('heath', 'the'),\n",
       " ('tom', 'how'),\n",
       " (',', '–'),\n",
       " ('cimiano', 'web'),\n",
       " ('philipp', 'semantic'),\n",
       " (',', 'meets'),\n",
       " ('ciravegna', 'media'),\n",
       " ('fabio', '.'),\n",
       " (',', 'lee'),\n",
       " ('traverso', 'robert'),\n",
       " ('paolo', 'and'),\n",
       " ('aroyo', 'bizer'),\n",
       " ('lora', 'christian'),\n",
       " ('in', ','),\n",
       " ('.', 'smethurst'),\n",
       " ('connections', 'michael'),\n",
       " ('make', ','),\n",
       " ('to', 'sizemore'),\n",
       " ('data', 'chris'),\n",
       " ('linked', ','),\n",
       " ('and', 'oliver'),\n",
       " ('dbpedia', 'silver'),\n",
       " ('uses', ','),\n",
       " ('bbc', 'raimond'),\n",
       " ('the', 'yves'),\n",
       " ('how', ','),\n",
       " ('–', 'scott'),\n",
       " ('web', 'tom'),\n",
       " ('semantic', ','),\n",
       " ('meets', 'kobilarov'),\n",
       " ('media', 'georgi'),\n",
       " ('.', ']'),\n",
       " ('lee', '2009'),\n",
       " ('robert', ','),\n",
       " ('and', '.'),\n",
       " (',', 'al'),\n",
       " ('bizer', 'et'),\n",
       " ('christian', 'kobilarov'),\n",
       " (',', '['),\n",
       " ('smethurst', '.'),\n",
       " ('michael', '2020'),\n",
       " (',', 'january'),\n",
       " ('sizemore', '5'),\n",
       " ('chris', ','),\n",
       " (',', 'japan'),\n",
       " ('oliver', ','),\n",
       " ('silver', 'kyoto'),\n",
       " ('raimond', '87–92'),\n",
       " ('yves', 'pages'),\n",
       " ('scott', 'processing'),\n",
       " ('tom', 'language'),\n",
       " (',', 'natural'),\n",
       " ('kobilarov', 'and'),\n",
       " ('georgi', 'technology'),\n",
       " (']', 'financial'),\n",
       " ('2009', 'on'),\n",
       " (',', 'workshop'),\n",
       " ('al', 'embeddings'),\n",
       " ('et', 'word'),\n",
       " ('kobilarov', 'alized'),\n",
       " ('[', 'second'),\n",
       " ('.', 'the'),\n",
       " ('2020', 'of'),\n",
       " ('january', 'proceedings'),\n",
       " ('5', 'in'),\n",
       " (',', 'contextu-'),\n",
       " ('japan', 'and'),\n",
       " (',', 'free'),\n",
       " ('kyoto', '-'),\n",
       " (',', 'context'),\n",
       " ('87–92', 'via'),\n",
       " ('pages', 'domain'),\n",
       " (',', 'ﬁnancial'),\n",
       " ('processing', 'in'),\n",
       " ('language', 'tection'),\n",
       " ('natural', 'de-'),\n",
       " ('and', 'hypernym'),\n",
       " ('technology', ':'),\n",
       " ('financial', 'task'),\n",
       " ('on', 'finsim'),\n",
       " ('workshop', 'the'),\n",
       " ('.', 'at'),\n",
       " ('embeddings', 'iitk'),\n",
       " ('word', '.'),\n",
       " ('alized', 'modi'),\n",
       " ('second', 'ashutosh'),\n",
       " ('the', 'and'),\n",
       " ('of', ','),\n",
       " ('proceedings', 'singh'),\n",
       " ('in', 'sakshi'),\n",
       " ('contextu-', ','),\n",
       " ('and', 'keswani'),\n",
       " ('free', 'vishal'),\n",
       " ('-', ']'),\n",
       " ('context', '2020'),\n",
       " ('via', ','),\n",
       " ('domain', '.'),\n",
       " ('ﬁnancial', 'al'),\n",
       " ('in', 'et'),\n",
       " ('tection', 'keswani'),\n",
       " ('de-', '['),\n",
       " ('hypernym', '.'),\n",
       " (':', 'linguistics'),\n",
       " ('task', 'computational'),\n",
       " ('finsim', 'for'),\n",
       " ('the', 'sociation'),\n",
       " ('at', 'as-'),\n",
       " ('iitk', '.'),\n",
       " ('.', '2016'),\n",
       " ('modi', 'june'),\n",
       " ('ashutosh', ','),\n",
       " ('and', 'california'),\n",
       " ('singh', 'diego'),\n",
       " ('sakshi', 'san'),\n",
       " ('keswani', '1092–1102'),\n",
       " ('vishal', 'pages'),\n",
       " (']', ','),\n",
       " ('2020', ')'),\n",
       " (',', 'semeval-2016'),\n",
       " ('.', '('),\n",
       " ('al', 'evaluation'),\n",
       " ('et', 'semantic'),\n",
       " ('keswani', 'on'),\n",
       " ('[', 'workshop'),\n",
       " ('.', 'tional'),\n",
       " ('linguistics', 'interna-'),\n",
       " ('computational', '10th'),\n",
       " ('for', 'the'),\n",
       " ('sociation', 'of'),\n",
       " ('as-', 'proceedings'),\n",
       " ('.', 'in'),\n",
       " ('2016', '.'),\n",
       " ('june', 'enrichment'),\n",
       " (',', 'taxonomy'),\n",
       " ('california', 'semantic'),\n",
       " (',', ':'),\n",
       " ('diego', '14'),\n",
       " ('san', 'task'),\n",
       " (',', 'semeval-2016'),\n",
       " ('1092–1102', '.'),\n",
       " ('pages', 'pilehvar'),\n",
       " (',', 'taher'),\n",
       " (')', 'mad'),\n",
       " ('semeval-2016', 'moham-'),\n",
       " ('(', 'and'),\n",
       " ('evaluation', 'jurgens'),\n",
       " ('semantic', 'david'),\n",
       " ('on', ']'),\n",
       " ('workshop', '2016'),\n",
       " ('tional', ','),\n",
       " ('interna-', 'pilehvar'),\n",
       " ('10th', 'and'),\n",
       " ('the', 'jurgens'),\n",
       " ('of', '['),\n",
       " ('proceedings', '.'),\n",
       " ('in', '2020'),\n",
       " ('.', ','),\n",
       " ('enrichment', 'python'),\n",
       " ('taxonomy', 'in'),\n",
       " ('semantic', 'processing'),\n",
       " (':', 'language'),\n",
       " ('14', 'natural'),\n",
       " ('task', 'strength'),\n",
       " ('semeval-2016', '-'),\n",
       " ('.', 'industrial'),\n",
       " ('pilehvar', '.'),\n",
       " ('taher', 'boyd'),\n",
       " ('mad', 'adriane'),\n",
       " ('moham-', 'and'),\n",
       " ('and', ','),\n",
       " ('jurgens', 'landeghem'),\n",
       " ('david', 'van'),\n",
       " (']', 'soﬁe'),\n",
       " ('2016', ':'),\n",
       " (',', 'spacy'),\n",
       " ('pilehvar', ','),\n",
       " ('and', 'montani'),\n",
       " ('jurgens', 'ines'),\n",
       " ('[', ','),\n",
       " ('.', 'honnibal'),\n",
       " ('2020', 'matthew'),\n",
       " (',', ']'),\n",
       " ('python', '2020'),\n",
       " ('in', ','),\n",
       " ('processing', '.'),\n",
       " ('language', 'al'),\n",
       " ('natural', 'et'),\n",
       " ('strength', 'honnibal'),\n",
       " ('-', '['),\n",
       " ('industrial', '.'),\n",
       " (':', '2014'),\n",
       " ('spacy', ','),\n",
       " ('.', '2565–2569'),\n",
       " ('boyd', '.'),\n",
       " ('adriane', 'ontology'),\n",
       " ('and', 'dbpedia'),\n",
       " (',', 'and'),\n",
       " ('landeghem', 'wikipedia'),\n",
       " ('van', 'ing'),\n",
       " ('soﬁe', 'pages'),\n",
       " ('montani', 'lrec'),\n",
       " ('ines', 'in'),\n",
       " (',', 'us-'),\n",
       " ('honnibal', 'construction'),\n",
       " ('matthew', 'corpus'),\n",
       " (']', 'entity'),\n",
       " ('2020', 'named'),\n",
       " (',', '.'),\n",
       " ('.', 'choi'),\n",
       " ('al', 'sun'),\n",
       " ('et', '-'),\n",
       " ('honnibal', 'key'),\n",
       " ('[', 'and'),\n",
       " ('.', ','),\n",
       " ('2014', 'hwang'),\n",
       " (',', 'dosam'),\n",
       " ('2565–2569', ','),\n",
       " ('.', 'kim'),\n",
       " ('ontology', 'youngsik'),\n",
       " ('dbpedia', ','),\n",
       " ('and', 'lim'),\n",
       " ('wikipedia', 'kyungtae'),\n",
       " ('ing', ','),\n",
       " ('pages', 'park'),\n",
       " (',', 'jungyeul'),\n",
       " ('lrec', ','),\n",
       " ('in', 'hahm'),\n",
       " ('us-', 'younggyun'),\n",
       " ('construction', ']'),\n",
       " ('corpus', '2014'),\n",
       " ('entity', ','),\n",
       " ('named', '.'),\n",
       " ('.', 'al'),\n",
       " ('choi', 'et'),\n",
       " ('sun', 'hahm'),\n",
       " ('-', '['),\n",
       " ('key', '.'),\n",
       " ('and', '2021'),\n",
       " ('hwang', 'usa'),\n",
       " ('dosam', ','),\n",
       " (',', 'ny'),\n",
       " ('kim', ','),\n",
       " ('youngsik', 'york'),\n",
       " (',', 'new'),\n",
       " ('lim', ','),\n",
       " ('kyungtae', 'machinery'),\n",
       " (',', 'computing'),\n",
       " ('park', 'for'),\n",
       " ('jungyeul', 'association'),\n",
       " (',', '.'),\n",
       " ('hahm', '311–315'),\n",
       " ('younggyun', 'page'),\n",
       " (']', ','),\n",
       " ('2014', 'terms'),\n",
       " (',', 'financial'),\n",
       " ('.', 'of'),\n",
       " ('al', 'classiﬁcation'),\n",
       " ('et', 'matic'),\n",
       " ('hahm', 'auto-'),\n",
       " ('[', 'for'),\n",
       " ('.', 'models'),\n",
       " ('2021', 'based'),\n",
       " (',', 'transformer'),\n",
       " ('usa', ':'),\n",
       " (',', '@finsim-2'),\n",
       " ('ny', '2021'),\n",
       " (',', '.'),\n",
       " ('york', '2020'),\n",
       " ('new', ','),\n",
       " (',', 'processing'),\n",
       " ('machinery', 'language'),\n",
       " ('computing', 'natural'),\n",
       " ('for', 'art'),\n",
       " ('association', '-'),\n",
       " ('.', 'the'),\n",
       " ('2020', '-'),\n",
       " (',', 'of'),\n",
       " ('processing', '-'),\n",
       " ('language', 'state'),\n",
       " ('natural', ':'),\n",
       " ('art', 'transformers'),\n",
       " ('-', '’s'),\n",
       " ('the', 'huggingface'),\n",
       " ('-', '.'),\n",
       " ('of', 'rush'),\n",
       " ('-', 'm.'),\n",
       " ('state', 'alexander'),\n",
       " (':', 'and'),\n",
       " ('transformers', ','),\n",
       " ('’s', 'lhoest'),\n",
       " ('huggingface', 'quentin'),\n",
       " ('.', ','),\n",
       " ('rush', 'drame'),\n",
       " ('m.', 'mariama'),\n",
       " ('alexander', ','),\n",
       " ('and', 'gugger'),\n",
       " (',', 'sylvain'),\n",
       " ('lhoest', ','),\n",
       " ('quentin', 'scao'),\n",
       " (',', 'le'),\n",
       " ('drame', 'teven'),\n",
       " ('mariama', ','),\n",
       " (',', 'xu'),\n",
       " ('gugger', 'canwen'),\n",
       " ('sylvain', ','),\n",
       " (',', 'plu'),\n",
       " ('scao', 'julien'),\n",
       " ('le', ','),\n",
       " ('teven', 'jernite'),\n",
       " (',', 'yacine'),\n",
       " ('xu', ','),\n",
       " ('canwen', 'ma'),\n",
       " (',', 'clara'),\n",
       " ('plu', ','),\n",
       " ('julien', 'platen'),\n",
       " (',', 'von'),\n",
       " ('jernite', 'patrick'),\n",
       " ('yacine', ','),\n",
       " (',', 'shleifer'),\n",
       " ('ma', 'sam'),\n",
       " ('clara', ','),\n",
       " (',', 'davison'),\n",
       " ('platen', 'joe'),\n",
       " ('von', ','),\n",
       " ('patrick', 'funtowicz'),\n",
       " (',', 'morgan'),\n",
       " ('shleifer', ','),\n",
       " ('sam', 'louf'),\n",
       " (',', 'r´emi'),\n",
       " ('davison', ','),\n",
       " ('joe', 'rault'),\n",
       " (',', 'tim'),\n",
       " ('funtowicz', ','),\n",
       " ('morgan', 'cistac'),\n",
       " (',', 'pierric'),\n",
       " ('louf', ','),\n",
       " ('r´emi', 'moi'),\n",
       " (',', 'anthony'),\n",
       " ('rault', ','),\n",
       " ('tim', 'delangue'),\n",
       " (',', 'clement'),\n",
       " ('cistac', ','),\n",
       " ('pierric', 'chaumond'),\n",
       " (',', 'julien'),\n",
       " ('moi', ','),\n",
       " ('anthony', 'sanh'),\n",
       " (',', 'victor'),\n",
       " ('delangue', ','),\n",
       " ('clement', 'debut'),\n",
       " (',', 'lysandre'),\n",
       " ('chaumond', ','),\n",
       " ('julien', 'wolf'),\n",
       " (',', 'thomas'),\n",
       " ('sanh', ']'),\n",
       " ('victor', '2020'),\n",
       " ('debut', '.'),\n",
       " ('lysandre', 'al'),\n",
       " (',', 'et'),\n",
       " ('thomas', '['),\n",
       " (']', 'stepiˇsnik'),\n",
       " ('2020', '.'),\n",
       " (',', '2021'),\n",
       " ('.', ','),\n",
       " ('al', 'usa'),\n",
       " ('et', ','),\n",
       " ('wolf', 'ny'),\n",
       " ('[', ','),\n",
       " ('stepiˇsnik', 'york'),\n",
       " ('.', 'new'),\n",
       " ('2021', ','),\n",
       " (',', 'machinery'),\n",
       " ('usa', 'computing'),\n",
       " (',', 'for'),\n",
       " ('ny', 'association'),\n",
       " (',', '.'),\n",
       " ('york', '298–301'),\n",
       " ('new', 'page'),\n",
       " ('machinery', 'classiﬁcation'),\n",
       " ('computing', 'concept'),\n",
       " ('for', 'financial'),\n",
       " ('association', 'augmented'),\n",
       " ('.', '-'),\n",
       " ('298–301', 'ontology'),\n",
       " ('page', ':'),\n",
       " (',', 'task'),\n",
       " ('classiﬁcation', 'finsim-2'),\n",
       " ('concept', 'the'),\n",
       " ('financial', 'at'),\n",
       " ('augmented', 'jsi'),\n",
       " ('-', '.'),\n",
       " ('ontology', 'ˇskrlj'),\n",
       " (':', 'blaˇz'),\n",
       " ('task', 'and'),\n",
       " ('finsim-2', ','),\n",
       " ('the', 'pollak'),\n",
       " ('at', 'senja'),\n",
       " ('jsi', ','),\n",
       " ('.', 'perdih'),\n",
       " ('ˇskrlj', 'timen'),\n",
       " ('blaˇz', ']'),\n",
       " ('and', '2021'),\n",
       " ('pollak', '.'),\n",
       " ('senja', 'al'),\n",
       " (',', 'et'),\n",
       " ('timen', 'stepiˇsnik'),\n",
       " (']', '['),\n",
       " ('2021', '.'),\n",
       " (',', '2020'),\n",
       " ('.', 'uary'),\n",
       " ('al', 'jan-'),\n",
       " ('et', '5'),\n",
       " ('perdih', ','),\n",
       " ('stepiˇsnik', 'japan'),\n",
       " ('[', ','),\n",
       " ('.', 'kyoto'),\n",
       " ('2020', ','),\n",
       " ('uary', '93–97'),\n",
       " ('jan-', 'pages'),\n",
       " ('5', ','),\n",
       " (',', 'processing'),\n",
       " ('japan', 'language'),\n",
       " (',', 'natural'),\n",
       " ('kyoto', 'and'),\n",
       " (',', 'technology'),\n",
       " ('93–97', 'financial'),\n",
       " ('pages', 'on'),\n",
       " (',', 'workshop'),\n",
       " ('processing', 'second'),\n",
       " ('language', 'the'),\n",
       " ('natural', 'of'),\n",
       " ('and', 'proceedings'),\n",
       " ('technology', 'in'),\n",
       " ('financial', '.'),\n",
       " ('on', 'investopedia'),\n",
       " ('workshop', 'with'),\n",
       " ('second', 'domain'),\n",
       " ('the', 'nancial'),\n",
       " ('of', 'ﬁ-'),\n",
       " ('proceedings', 'of'),\n",
       " ('in', 'representation'),\n",
       " ('.', 'semantic'),\n",
       " ('investopedia', 'anuj@finsim¡vlearning'),\n",
       " ('with', ':'),\n",
       " ('domain', 'task'),\n",
       " ('nancial', 'finsim'),\n",
       " ('ﬁ-', 'the'),\n",
       " ('of', 'at'),\n",
       " ('representation', 'anuj'),\n",
       " ('semantic', '.'),\n",
       " ('anuj@finsim¡vlearning', 'saini'),\n",
       " (':', 'anuj'),\n",
       " ('task', ']'),\n",
       " ('finsim', '2020'),\n",
       " ('the', ','),\n",
       " ('at', 'saini'),\n",
       " ('anuj', '['),\n",
       " ('saini', '2019'),\n",
       " ('anuj', ','),\n",
       " (']', 'linguistics'),\n",
       " ('2020', 'computational'),\n",
       " (',', 'for'),\n",
       " ('saini', 'association'),\n",
       " ('[', '.'),\n",
       " ('.', 'processing'),\n",
       " ('2019', 'language'),\n",
       " (',', 'natural'),\n",
       " ('linguistics', 'in'),\n",
       " ('computational', 'methods'),\n",
       " ('for', 'empirical'),\n",
       " ('association', 'on'),\n",
       " ('.', 'conference'),\n",
       " ('processing', '2019'),\n",
       " ('language', 'the'),\n",
       " ('natural', 'of'),\n",
       " ('in', 'proceedings'),\n",
       " ('methods', 'in'),\n",
       " ('empirical', '.'),\n",
       " ('on', 'networks'),\n",
       " ('conference', '-'),\n",
       " ('2019', 'bert'),\n",
       " ('the', 'siamese'),\n",
       " ('of', 'using'),\n",
       " ('proceedings', 'embeddings'),\n",
       " ('in', 'sentence'),\n",
       " ('.', ':'),\n",
       " ('networks', 'bert'),\n",
       " ('-', 'sentence-'),\n",
       " ('bert', '.'),\n",
       " ('siamese', 'gurevych'),\n",
       " ('using', 'iryna'),\n",
       " ('embeddings', 'and'),\n",
       " ('sentence', ','),\n",
       " (':', 'daxenberger'),\n",
       " ('bert', 'johannes'),\n",
       " ('sentence-', ','),\n",
       " ('.', 'reimers'),\n",
       " ('gurevych', 'nils'),\n",
       " ('iryna', ','),\n",
       " ('and', 'thakur'),\n",
       " (',', 'nandan'),\n",
       " ('daxenberger', ','),\n",
       " ('johannes', 'gurevych'),\n",
       " (',', 'iryna'),\n",
       " ('reimers', ','),\n",
       " ('nils', 'reimers'),\n",
       " (',', 'nils'),\n",
       " ('thakur', ','),\n",
       " ('nandan', 'gurevych'),\n",
       " (',', 'iryna'),\n",
       " ('gurevych', ','),\n",
       " ('iryna', 'reimers'),\n",
       " (',', 'nils'),\n",
       " ('reimers', ']'),\n",
       " ('nils', '2019'),\n",
       " ('gurevych', '.'),\n",
       " ('iryna', 'al'),\n",
       " (',', 'et'),\n",
       " ('nils', '['),\n",
       " (']', '.'),\n",
       " ('.', 'learners'),\n",
       " ('al', 'multitask'),\n",
       " ('et', 'unsupervised'),\n",
       " ('reimers', 'are'),\n",
       " ('[', 'models'),\n",
       " ('.', 'language'),\n",
       " ('2019', '.'),\n",
       " (',', 'sutskever'),\n",
       " ('learners', 'ilya'),\n",
       " ('multitask', 'and'),\n",
       " ('unsupervised', ','),\n",
       " ('are', 'amodei'),\n",
       " ('models', 'dario'),\n",
       " ('language', ','),\n",
       " ('.', 'luan'),\n",
       " ('sutskever', 'david'),\n",
       " ('ilya', ','),\n",
       " ('and', 'child'),\n",
       " (',', 'rewon'),\n",
       " ('amodei', ','),\n",
       " ('dario', 'wu'),\n",
       " (',', 'jeff'),\n",
       " ('luan', ','),\n",
       " ('david', 'radford'),\n",
       " (',', 'alec'),\n",
       " ('child', ']'),\n",
       " ('rewon', '2019'),\n",
       " ('wu', '.'),\n",
       " ('jeff', 'al'),\n",
       " (',', 'et'),\n",
       " ('alec', '['),\n",
       " (']', '.'),\n",
       " ('2019', '2021'),\n",
       " ('.', 'usa'),\n",
       " ('al', ','),\n",
       " ('et', 'ny'),\n",
       " ('radford', ','),\n",
       " ('[', 'york'),\n",
       " ('.', 'new'),\n",
       " ('2021', ','),\n",
       " (',', 'machinery'),\n",
       " ('usa', 'computing'),\n",
       " (',', 'for'),\n",
       " ('ny', 'association'),\n",
       " (',', '.'),\n",
       " ('york', '293–297'),\n",
       " ('new', 'page'),\n",
       " ('machinery', 'graphs'),\n",
       " ('computing', 'edge'),\n",
       " ('for', 'knowl-'),\n",
       " ('association', 'using'),\n",
       " ('.', 'domain'),\n",
       " ('293–297', 'services'),\n",
       " ('page', 'financial'),\n",
       " (',', 'the'),\n",
       " ('graphs', 'in'),\n",
       " ('edge', 'tection'),\n",
       " ('knowl-', 'de-'),\n",
       " ('using', 'hypernym'),\n",
       " ('domain', ':'),\n",
       " ('services', 'finsim-2'),\n",
       " ('financial', 'at'),\n",
       " ('the', 'finmatcher'),\n",
       " ('in', '.'),\n",
       " ('tection', 'paulheim'),\n",
       " ('de-', 'heiko'),\n",
       " ('hypernym', 'and'),\n",
       " (':', ','),\n",
       " ('finsim-2', 'hladik'),\n",
       " ('at', 'michael'),\n",
       " ('finmatcher', ','),\n",
       " ('.', 'portisch'),\n",
       " ('paulheim', 'jan'),\n",
       " ('heiko', ']'),\n",
       " ('and', '2021'),\n",
       " ('hladik', '.'),\n",
       " ('michael', 'al'),\n",
       " (',', 'et'),\n",
       " ('jan', '['),\n",
       " (']', '.'),\n",
       " ('2021', 'machinery'),\n",
       " (',', 'computing'),\n",
       " ('.', 'for'),\n",
       " ('al', 'association'),\n",
       " ('et', '.'),\n",
       " ('portisch', '2021'),\n",
       " ('[', ','),\n",
       " ('.', 'usa'),\n",
       " ('machinery', ','),\n",
       " ('computing', 'ny'),\n",
       " ('for', ','),\n",
       " ('association', 'york'),\n",
       " ('.', 'new'),\n",
       " ('2021', ','),\n",
       " (',', '307–310'),\n",
       " ('usa', 'page'),\n",
       " ('ny', '21'),\n",
       " (',', '’'),\n",
       " ('york', 'www'),\n",
       " ('new', ','),\n",
       " (',', '2021'),\n",
       " ('307–310', 'conference'),\n",
       " ('page', 'web'),\n",
       " (',', 'the'),\n",
       " ('21', 'of'),\n",
       " ('’', 'ceedings'),\n",
       " ('www', '.'),\n",
       " (',', 'corpus'),\n",
       " ('2021', 'customized'),\n",
       " ('conference', 'with'),\n",
       " ('web', 'data'),\n",
       " ('the', 'cial'),\n",
       " ('of', 'pro-'),\n",
       " ('ceedings', 'companion'),\n",
       " ('.', 'in'),\n",
       " ('corpus', 'ﬁnan-'),\n",
       " ('customized', 'of'),\n",
       " ('with', 'representations'),\n",
       " ('data', 'word'),\n",
       " ('cial', 'learning'),\n",
       " ('pro-', ':'),\n",
       " ('companion', 'task'),\n",
       " ('in', 'ﬁnsim-2'),\n",
       " ('\\x0c', 'the'),\n",
       " ('50', 'at'),\n",
       " ('.', 'goat'),\n",
       " ('311–315', '.'),\n",
       " ('page', 'zhang'),\n",
       " (',', 'qian'),\n",
       " ('terms', 'and'),\n",
       " ('financial', 'pei'),\n",
       " ('of', 'yulong'),\n",
       " ('classiﬁcation', ']'),\n",
       " ('matic', '2021'),\n",
       " ('auto-', ','),\n",
       " ('for', 'zhang'),\n",
       " ('models', 'and'),\n",
       " ('based', 'pei'),\n",
       " ('transformer', '['),\n",
       " (':', '\\n\\n\\x0c'),\n",
       " ('@finsim-2', 'witm'),\n",
       " ('2021', 'tcs'),\n",
       " ('witm', '.'),\n",
       " ('tcs', 'dey'),\n",
       " ('.', 'lipika'),\n",
       " ('dey', 'and'),\n",
       " ('lipika', ','),\n",
       " ('and', 'dasgupta'),\n",
       " (',', 'tirthankar'),\n",
       " ('dasgupta', ','),\n",
       " ('tirthankar', 'verma'),\n",
       " (',', 'ishan'),\n",
       " ('verma', ','),\n",
       " ('ishan', 'chauhan'),\n",
       " (',', 'vipul'),\n",
       " ('chauhan', ','),\n",
       " ('vipul', 'goel'),\n",
       " (',', 'tushar'),\n",
       " ('goel', ']'),\n",
       " ('tushar', '2021'),\n",
       " (']', ','),\n",
       " ('2021', '.'),\n",
       " (',', 'al'),\n",
       " ('.', 'et'),\n",
       " ('al', 'goel'),\n",
       " ('et', '['),\n",
       " ('goel', '.'),\n",
       " ('[', '2019'),\n",
       " ('.', ','),\n",
       " ('linguistics', 'models'),\n",
       " ('computational', 'language'),\n",
       " ('for', 'trained'),\n",
       " ('association', '-'),\n",
       " ('.', 'pre'),\n",
       " ('2019', 'with'),\n",
       " ('june', 'analysis'),\n",
       " (',', 'sentiment'),\n",
       " ('minnesota', 'financial'),\n",
       " (',', ':'),\n",
       " ('lis', 'finbert'),\n",
       " ('minneapo-', '.'),\n",
       " (',', 'araci'),\n",
       " ('4171–4186', 'dogu'),\n",
       " ('pages', ']'),\n",
       " (',', '2019'),\n",
       " (')', ','),\n",
       " ('papers', 'araci'),\n",
       " ('short', '['),\n",
       " ('and', '.'),\n",
       " ('long', 'linguistics'),\n",
       " ('(', 'computational'),\n",
       " ('1', 'for'),\n",
       " ('volume', 'association'),\n",
       " (',', '.'),\n",
       " ('technologies', '2019'),\n",
       " ('language', 'june'),\n",
       " ('human', ','),\n",
       " (':', 'minnesota'),\n",
       " ('linguistics', ','),\n",
       " ('computational', 'lis'),\n",
       " ('for', 'minneapo-'),\n",
       " ('association', ','),\n",
       " ('the', '4171–4186'),\n",
       " ('of', 'pages'),\n",
       " ('chapter', ','),\n",
       " ('american', ')'),\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9f6113b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term',\n",
       " 'tempt',\n",
       " 'over',\n",
       " 'about',\n",
       " 'ontologies',\n",
       " 'source',\n",
       " 'tionship',\n",
       " 'this',\n",
       " 'and',\n",
       " 'effec-',\n",
       " 'methods',\n",
       " 'corpus',\n",
       " 'with',\n",
       " 'formal',\n",
       " 'the',\n",
       " 'experimentation',\n",
       " 'areas',\n",
       " ',',\n",
       " '2021',\n",
       " '46',\n",
       " '\\x0c',\n",
       " 'based',\n",
       " 'unsupervised',\n",
       " 'approach',\n",
       " 'et',\n",
       " ']',\n",
       " 'a',\n",
       " 'contextualized',\n",
       " ']',\n",
       " '.',\n",
       " ';',\n",
       " ']',\n",
       " 'of',\n",
       " 'labels',\n",
       " 'consisting',\n",
       " '-',\n",
       " 'h1',\n",
       " ',',\n",
       " ',',\n",
       " 'tn',\n",
       " 'are',\n",
       " '.',\n",
       " 'du-',\n",
       " 'entries',\n",
       " 'approach',\n",
       " 'where',\n",
       " ':',\n",
       " '”',\n",
       " 'we',\n",
       " 'length(s1',\n",
       " 'on',\n",
       " 'semantic',\n",
       " '.',\n",
       " ',',\n",
       " '(',\n",
       " 'as',\n",
       " 'of',\n",
       " 'workshop',\n",
       " 'pre',\n",
       " ',',\n",
       " 'nicole',\n",
       " ',',\n",
       " 'st',\n",
       " 'for',\n",
       " 'second',\n",
       " ',',\n",
       " '.',\n",
       " 'contextu-',\n",
       " ',',\n",
       " ',']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acc816e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term',\n",
       " 'expansion',\n",
       " 'and',\n",
       " 'finbert',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuning',\n",
       " 'for',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonym',\n",
       " 'ranking',\n",
       " 'of',\n",
       " 'financial',\n",
       " 'terms',\n",
       " 'ankush',\n",
       " 'chopra∗†',\n",
       " ',',\n",
       " 'sohom',\n",
       " 'ghosh†',\n",
       " 'fidelity',\n",
       " 'investments',\n",
       " ',',\n",
       " 'ai',\n",
       " 'coe',\n",
       " ',',\n",
       " 'bengaluru',\n",
       " ',',\n",
       " 'india',\n",
       " '{',\n",
       " 'ankush01729',\n",
       " ',',\n",
       " 'sohom1ghosh}@gmail.com',\n",
       " 'abstract',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonym',\n",
       " 'matching',\n",
       " 'are',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mainstream',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'nlp',\n",
       " ')',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'in',\n",
       " 'this',\n",
       " 'paper',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'systems',\n",
       " 'that',\n",
       " 'at-',\n",
       " 'tempt',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'this',\n",
       " 'problem',\n",
       " '.',\n",
       " 'we',\n",
       " 'designed',\n",
       " 'these',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'participate',\n",
       " 'in',\n",
       " 'the',\n",
       " 'finsim-3',\n",
       " ',',\n",
       " 'a',\n",
       " 'shared',\n",
       " 'task',\n",
       " 'of',\n",
       " 'finnlp',\n",
       " 'workshop',\n",
       " 'at',\n",
       " 'ijcai-2021',\n",
       " '.',\n",
       " 'the',\n",
       " 'shared',\n",
       " 'task',\n",
       " 'is',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'solving',\n",
       " 'this',\n",
       " 'problem',\n",
       " 'for',\n",
       " 'the',\n",
       " 'ﬁnancial',\n",
       " 'domain',\n",
       " '.',\n",
       " 'we',\n",
       " 'experimented',\n",
       " 'with',\n",
       " 'var-',\n",
       " 'ious',\n",
       " 'transformer',\n",
       " 'based',\n",
       " 'pre',\n",
       " '-',\n",
       " 'trained',\n",
       " 'embeddings',\n",
       " 'by',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuning',\n",
       " 'these',\n",
       " 'for',\n",
       " 'either',\n",
       " 'classiﬁcation',\n",
       " 'or',\n",
       " 'phrase',\n",
       " 'similarity',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'we',\n",
       " 'also',\n",
       " 'augmented',\n",
       " 'the',\n",
       " 'provided',\n",
       " 'dataset',\n",
       " 'with',\n",
       " 'abbreviations',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'prospectus',\n",
       " 'provided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'organizers',\n",
       " 'and',\n",
       " 'deﬁnitions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ﬁnancial',\n",
       " 'terms',\n",
       " 'from',\n",
       " 'dbpedia',\n",
       " '[',\n",
       " 'auer',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2007',\n",
       " ']',\n",
       " ',',\n",
       " 'investopedia',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'financial',\n",
       " 'industry',\n",
       " 'business',\n",
       " 'ontology',\n",
       " '(',\n",
       " 'fibo',\n",
       " ')',\n",
       " '.',\n",
       " 'our',\n",
       " 'best',\n",
       " 'performing',\n",
       " 'system',\n",
       " 'uses',\n",
       " 'both',\n",
       " 'finbert',\n",
       " '[',\n",
       " 'araci',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " 'and',\n",
       " 'data',\n",
       " 'augmenta-',\n",
       " 'tion',\n",
       " 'from',\n",
       " 'the',\n",
       " 'afore',\n",
       " '-',\n",
       " 'mentioned',\n",
       " 'sources',\n",
       " '.',\n",
       " 'we',\n",
       " 'ob-',\n",
       " 'served',\n",
       " 'that',\n",
       " 'term',\n",
       " 'expansion',\n",
       " 'using',\n",
       " 'data',\n",
       " 'augmenta-',\n",
       " 'tion',\n",
       " 'in',\n",
       " 'conjunction',\n",
       " 'with',\n",
       " 'semantic',\n",
       " 'similarity',\n",
       " 'is',\n",
       " 'ben-',\n",
       " 'eﬁcial',\n",
       " 'for',\n",
       " 'this',\n",
       " 'task',\n",
       " 'and',\n",
       " 'could',\n",
       " 'be',\n",
       " 'beneﬁcial',\n",
       " 'for',\n",
       " 'the',\n",
       " 'other',\n",
       " 'tasks',\n",
       " 'that',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'short',\n",
       " 'phrases',\n",
       " '.',\n",
       " 'our',\n",
       " 'best',\n",
       " 'performing',\n",
       " 'model',\n",
       " '(',\n",
       " 'accuracy',\n",
       " ':',\n",
       " '0.917',\n",
       " ',',\n",
       " 'rank',\n",
       " ':',\n",
       " '1.156',\n",
       " ')',\n",
       " 'was',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuning',\n",
       " 'sentence-',\n",
       " 'bert',\n",
       " '[',\n",
       " 'reimers',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " '(',\n",
       " 'with',\n",
       " 'finbert',\n",
       " 'at',\n",
       " 'the',\n",
       " 'backend',\n",
       " ')',\n",
       " 'over',\n",
       " 'an',\n",
       " 'extended',\n",
       " 'labelled',\n",
       " 'set',\n",
       " 'created',\n",
       " 'us-',\n",
       " 'ing',\n",
       " 'the',\n",
       " 'hierarchy',\n",
       " 'of',\n",
       " 'labels',\n",
       " 'present',\n",
       " 'in',\n",
       " 'fibo',\n",
       " '.',\n",
       " 'introduction',\n",
       " '1',\n",
       " 'ontologies',\n",
       " 'are',\n",
       " 'rich',\n",
       " 'sources',\n",
       " 'of',\n",
       " 'information',\n",
       " 'that',\n",
       " 'provide',\n",
       " 'deep',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'underlying',\n",
       " 'concepts',\n",
       " 'and',\n",
       " 'entities',\n",
       " '.',\n",
       " 'this',\n",
       " 'information',\n",
       " 'is',\n",
       " 'described',\n",
       " 'for',\n",
       " 'a',\n",
       " 'speciﬁc',\n",
       " 'domain',\n",
       " ',',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'clearly',\n",
       " 'deﬁned',\n",
       " 'relationship',\n",
       " ',',\n",
       " 'and',\n",
       " 'organizes',\n",
       " 'in',\n",
       " 'a',\n",
       " 'deﬁned',\n",
       " 'struc-',\n",
       " 'ture',\n",
       " 'mostly',\n",
       " 'as',\n",
       " 'a',\n",
       " 'hierarchy',\n",
       " '.',\n",
       " 'these',\n",
       " 'properties',\n",
       " 'make',\n",
       " 'ontologies',\n",
       " 'a',\n",
       " 'great',\n",
       " 'source',\n",
       " 'for',\n",
       " 'getting',\n",
       " 'a',\n",
       " 'deeper',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rela-',\n",
       " 'tionship',\n",
       " 'and',\n",
       " 'properties',\n",
       " 'of',\n",
       " 'resources',\n",
       " 'from',\n",
       " 'the',\n",
       " 'domain',\n",
       " 'in',\n",
       " 'con-',\n",
       " 'sideration',\n",
       " '.',\n",
       " 'public',\n",
       " 'knowledge',\n",
       " 'graphs',\n",
       " 'and',\n",
       " 'ontologies',\n",
       " 'like',\n",
       " 'dbpedia',\n",
       " 'and',\n",
       " 'yago',\n",
       " 'have',\n",
       " 'been',\n",
       " 'shown',\n",
       " 'to',\n",
       " 'work',\n",
       " 'on',\n",
       " 'various',\n",
       " 'applications',\n",
       " 'like',\n",
       " '∗contact',\n",
       " 'author',\n",
       " '†equal',\n",
       " 'contribution',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'described',\n",
       " 'in',\n",
       " '[',\n",
       " 'kobilarov',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2009',\n",
       " ']',\n",
       " 'and',\n",
       " '[',\n",
       " 'hahm',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2014',\n",
       " ']',\n",
       " '.',\n",
       " 'this',\n",
       " 'has',\n",
       " 'motivated',\n",
       " 'and',\n",
       " 'paved',\n",
       " 'ways',\n",
       " 'for',\n",
       " 'the',\n",
       " 'creation',\n",
       " 'of',\n",
       " 'domain',\n",
       " 'focused',\n",
       " 'ontologies',\n",
       " 'like',\n",
       " 'fibo1',\n",
       " '.',\n",
       " 'effective',\n",
       " 'techniques',\n",
       " 'that',\n",
       " 'enable',\n",
       " 'identifying',\n",
       " 'lexical',\n",
       " 'similar-',\n",
       " 'ity',\n",
       " 'between',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'or',\n",
       " 'concepts',\n",
       " 'increase',\n",
       " 'the',\n",
       " 'effectiveness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ontologies',\n",
       " '.',\n",
       " 'these',\n",
       " 'methods',\n",
       " 'not',\n",
       " 'only',\n",
       " 'help',\n",
       " 'in',\n",
       " 'building',\n",
       " 'new',\n",
       " 'ontologies',\n",
       " 'faster',\n",
       " 'or',\n",
       " 'augment',\n",
       " 'the',\n",
       " 'existing',\n",
       " 'ones',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'it',\n",
       " 'helps',\n",
       " 'in',\n",
       " 'the',\n",
       " 'effective',\n",
       " 'querying',\n",
       " 'and',\n",
       " 'concept',\n",
       " 'search',\n",
       " '.',\n",
       " 'finsim',\n",
       " '[',\n",
       " 'maarouf',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ';',\n",
       " 'mansar',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2021',\n",
       " ']',\n",
       " 'com-',\n",
       " 'petitions',\n",
       " 'are',\n",
       " 'being',\n",
       " 'held',\n",
       " 'to',\n",
       " 'promote',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'effec-',\n",
       " 'tive',\n",
       " 'similarity',\n",
       " 'measures',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'third',\n",
       " 'edition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'competi-',\n",
       " 'tion',\n",
       " 'finsim-32',\n",
       " '(',\n",
       " 'being',\n",
       " 'held',\n",
       " 'in',\n",
       " 'conjunction',\n",
       " 'with',\n",
       " '30th',\n",
       " 'interna-',\n",
       " 'tional',\n",
       " 'joint',\n",
       " 'conference',\n",
       " 'on',\n",
       " 'artiﬁcial',\n",
       " 'intelligence',\n",
       " '(',\n",
       " 'ijcai-21',\n",
       " ')',\n",
       " ')',\n",
       " ',',\n",
       " 'the',\n",
       " 'participants',\n",
       " 'are',\n",
       " 'challenged',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'sys-',\n",
       " 'tems',\n",
       " 'to',\n",
       " 'assign',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonyms',\n",
       " 'to',\n",
       " 'ﬁnancial',\n",
       " 'terms',\n",
       " 'by',\n",
       " 'mapping',\n",
       " 'them',\n",
       " 'to',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " '17',\n",
       " 'high',\n",
       " '-',\n",
       " 'level',\n",
       " 'ﬁnancial',\n",
       " 'concepts',\n",
       " 'present',\n",
       " 'in',\n",
       " 'fibo',\n",
       " '.',\n",
       " 'in',\n",
       " 'this',\n",
       " 'paper',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'the',\n",
       " 'systems',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'our',\n",
       " 'team',\n",
       " 'lipi',\n",
       " 'for',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonym',\n",
       " 'assignment',\n",
       " '.',\n",
       " 'we',\n",
       " 'ex-',\n",
       " 'perimented',\n",
       " 'with',\n",
       " 'basic',\n",
       " 'featurization',\n",
       " 'methods',\n",
       " 'like',\n",
       " 'tf',\n",
       " '-',\n",
       " 'idf',\n",
       " 'and',\n",
       " 'advanced',\n",
       " 'methods',\n",
       " 'like',\n",
       " 'pre',\n",
       " '-',\n",
       " 'trained',\n",
       " 'embedding',\n",
       " 'models',\n",
       " '.',\n",
       " 'our',\n",
       " 'top',\n",
       " '3',\n",
       " 'systems',\n",
       " 'use',\n",
       " 'pre',\n",
       " '-',\n",
       " 'trained',\n",
       " 'finbert',\n",
       " '[',\n",
       " 'araci',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " 'embed-',\n",
       " 'ding',\n",
       " 'model',\n",
       " 'that',\n",
       " 'was',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuned',\n",
       " 'on',\n",
       " 'the',\n",
       " 'data',\n",
       " 'speciﬁc',\n",
       " 'to',\n",
       " 'ﬁnan-',\n",
       " 'cial',\n",
       " 'domain',\n",
       " '.',\n",
       " 'we',\n",
       " 'also',\n",
       " 'augmented',\n",
       " 'the',\n",
       " 'training',\n",
       " 'data',\n",
       " 'by',\n",
       " 'utilizing',\n",
       " 'the',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'dbpedia',\n",
       " ',',\n",
       " 'investopedia',\n",
       " ',',\n",
       " 'fibo',\n",
       " 'and',\n",
       " 'text',\n",
       " 'corpus',\n",
       " 'of',\n",
       " 'prospectus',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " '.',\n",
       " 'we',\n",
       " 'describe',\n",
       " 'the',\n",
       " 'works',\n",
       " 'related',\n",
       " 'to',\n",
       " 'our',\n",
       " 'solution',\n",
       " 'in',\n",
       " 'the',\n",
       " 'next',\n",
       " 'section',\n",
       " '.',\n",
       " 'section',\n",
       " '3',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'formal',\n",
       " 'problem',\n",
       " 'statement',\n",
       " ',',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'data',\n",
       " 'description',\n",
       " 'in',\n",
       " 'section',\n",
       " '4',\n",
       " '.',\n",
       " 'we',\n",
       " 'describe',\n",
       " 'our',\n",
       " 'top',\n",
       " 'three',\n",
       " 'systems',\n",
       " 'in',\n",
       " 'section',\n",
       " '5',\n",
       " '.',\n",
       " 'section',\n",
       " '6',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'details',\n",
       " 'of',\n",
       " 'the',\n",
       " 'experimentation',\n",
       " 'that',\n",
       " 'we',\n",
       " 'performed',\n",
       " 'and',\n",
       " 'the',\n",
       " 'results',\n",
       " 'from',\n",
       " 'some',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'we',\n",
       " 'draw',\n",
       " 'our',\n",
       " 'conclusions',\n",
       " 'in',\n",
       " 'section',\n",
       " '7',\n",
       " 'while',\n",
       " 'giving',\n",
       " 'a',\n",
       " 'glimpse',\n",
       " 'of',\n",
       " 'things',\n",
       " 'that',\n",
       " 'we',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'try',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " '2',\n",
       " 'related',\n",
       " 'works',\n",
       " 'hypernym',\n",
       " '-',\n",
       " 'hyponym',\n",
       " 'extraction',\n",
       " 'and',\n",
       " 'learning',\n",
       " 'text',\n",
       " 'similarity',\n",
       " 'using',\n",
       " 'semantic',\n",
       " 'representations',\n",
       " 'have',\n",
       " 'been',\n",
       " 'very',\n",
       " 'challenging',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'research',\n",
       " 'for',\n",
       " 'the',\n",
       " 'nlp',\n",
       " 'community',\n",
       " '.',\n",
       " 'semeval-2018',\n",
       " 'task',\n",
       " '9',\n",
       " '[',\n",
       " 'camacho',\n",
       " '-',\n",
       " 'collados',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2018',\n",
       " ']',\n",
       " 'was',\n",
       " 'such',\n",
       " 'an',\n",
       " 'instance',\n",
       " '.',\n",
       " '1https://spec.edmcouncil.org/ﬁbo/',\n",
       " '2https://sites.google.com/nlg.csie.ntu.edu.tw/ﬁnnlp2021/shared-',\n",
       " 'task-ﬁnsim',\n",
       " '(',\n",
       " 'accessed',\n",
       " 'on',\n",
       " '8th',\n",
       " 'july',\n",
       " '2021',\n",
       " ')',\n",
       " 'proceedings',\n",
       " 'of',\n",
       " 'the',\n",
       " 'third',\n",
       " 'workshop',\n",
       " 'on',\n",
       " 'financial',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'finnlp@ijcai',\n",
       " '2021',\n",
       " ')',\n",
       " ',',\n",
       " 'pages',\n",
       " '46',\n",
       " '-',\n",
       " '51',\n",
       " ',',\n",
       " 'online',\n",
       " ',',\n",
       " 'august',\n",
       " '19',\n",
       " ',',\n",
       " '2021',\n",
       " '.',\n",
       " '    \\n\\n',\n",
       " '46',\n",
       " '\\x0c',\n",
       " 'team',\n",
       " 'crim',\n",
       " '[',\n",
       " 'bernier',\n",
       " '-',\n",
       " 'colborne',\n",
       " 'and',\n",
       " 'barri`ere',\n",
       " ',',\n",
       " '2018',\n",
       " ']',\n",
       " 'per-',\n",
       " 'formed',\n",
       " 'the',\n",
       " 'best',\n",
       " 'in',\n",
       " 'this',\n",
       " 'shared',\n",
       " 'task',\n",
       " '.',\n",
       " 'they',\n",
       " 'combined',\n",
       " 'a',\n",
       " 'super-',\n",
       " 'vised',\n",
       " 'word',\n",
       " 'embedding',\n",
       " 'based',\n",
       " 'approach',\n",
       " 'with',\n",
       " 'an',\n",
       " 'unsupervised',\n",
       " 'pattern',\n",
       " 'discovery',\n",
       " 'based',\n",
       " 'approach',\n",
       " '.',\n",
       " 'the',\n",
       " 'finsim',\n",
       " 'shared',\n",
       " 'tasks',\n",
       " '[',\n",
       " 'maarouf',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ';',\n",
       " 'mansar',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2021',\n",
       " ']',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'adopt-',\n",
       " 'ing',\n",
       " 'these',\n",
       " 'challenges',\n",
       " 'speciﬁc',\n",
       " 'to',\n",
       " 'the',\n",
       " 'financial',\n",
       " 'domain',\n",
       " '.',\n",
       " 'team',\n",
       " 'iit',\n",
       " '-',\n",
       " 'k',\n",
       " '[',\n",
       " 'keswani',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ']',\n",
       " 'won',\n",
       " 'finsim-1',\n",
       " 'using',\n",
       " 'a',\n",
       " 'combi-',\n",
       " 'nation',\n",
       " 'of',\n",
       " 'context',\n",
       " '-',\n",
       " 'free',\n",
       " 'static',\n",
       " 'embedding',\n",
       " 'word2vec',\n",
       " '[',\n",
       " 'mikolov',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2013',\n",
       " ']',\n",
       " 'and',\n",
       " 'contextualized',\n",
       " 'dynamic',\n",
       " 'embedding',\n",
       " 'bert',\n",
       " '[',\n",
       " 'devlin',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " '.',\n",
       " 'anand',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " '[',\n",
       " 'anand',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ']',\n",
       " 'from',\n",
       " 'the',\n",
       " 'team',\n",
       " 'finsim20',\n",
       " 'explored',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'cosine',\n",
       " 'similarity',\n",
       " 'be-',\n",
       " 'tween',\n",
       " 'terms',\n",
       " 'and',\n",
       " 'labels',\n",
       " 'encoded',\n",
       " 'using',\n",
       " 'universal',\n",
       " 'sentence',\n",
       " 'en-',\n",
       " 'coder',\n",
       " '[',\n",
       " 'cer',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2018',\n",
       " ']',\n",
       " '.',\n",
       " 'they',\n",
       " 'also',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'hypernyms',\n",
       " 'automatically',\n",
       " 'using',\n",
       " 'graph',\n",
       " 'based',\n",
       " 'approaches',\n",
       " '.',\n",
       " 'team',\n",
       " 'polyu-',\n",
       " 'cbs',\n",
       " '[',\n",
       " 'chersoni',\n",
       " 'and',\n",
       " 'huang',\n",
       " ',',\n",
       " '2021',\n",
       " ']',\n",
       " 'won',\n",
       " 'finsim-2',\n",
       " 'shared',\n",
       " 'task',\n",
       " 'using',\n",
       " 'logistic',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Anth_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e972513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term',\n",
       " 'expansion',\n",
       " 'and',\n",
       " 'finbert',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuning',\n",
       " 'for',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonym',\n",
       " 'ranking',\n",
       " 'of',\n",
       " 'financial',\n",
       " 'terms',\n",
       " 'ankush',\n",
       " 'chopra∗†',\n",
       " ',',\n",
       " 'sohom',\n",
       " 'ghosh†',\n",
       " 'fidelity',\n",
       " 'investments',\n",
       " ',',\n",
       " 'ai',\n",
       " 'coe',\n",
       " ',',\n",
       " 'bengaluru',\n",
       " ',',\n",
       " 'india',\n",
       " '{',\n",
       " 'ankush01729',\n",
       " ',',\n",
       " 'sohom1ghosh}@gmail.com',\n",
       " '1',\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '\\n \\n',\n",
       " 'l',\n",
       " 'u',\n",
       " 'j',\n",
       " '\\n \\n',\n",
       " '9',\n",
       " '2',\n",
       " '\\n \\n \\n',\n",
       " ']',\n",
       " 'l',\n",
       " 'c',\n",
       " '.',\n",
       " 's',\n",
       " 'c',\n",
       " '[',\n",
       " '\\n \\n \\n',\n",
       " '1',\n",
       " 'v',\n",
       " '4',\n",
       " '6',\n",
       " '7',\n",
       " '3',\n",
       " '1',\n",
       " '.',\n",
       " '7',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " ':',\n",
       " 'v',\n",
       " 'i',\n",
       " 'x',\n",
       " 'r',\n",
       " 'a',\n",
       " 'abstract',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonym',\n",
       " 'matching',\n",
       " 'are',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mainstream',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'nlp',\n",
       " ')',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'in',\n",
       " 'this',\n",
       " 'paper',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'systems',\n",
       " 'that',\n",
       " 'at-',\n",
       " 'tempt',\n",
       " 'to',\n",
       " 'solve',\n",
       " 'this',\n",
       " 'problem',\n",
       " '.',\n",
       " 'we',\n",
       " 'designed',\n",
       " 'these',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'participate',\n",
       " 'in',\n",
       " 'the',\n",
       " 'finsim-3',\n",
       " ',',\n",
       " 'a',\n",
       " 'shared',\n",
       " 'task',\n",
       " 'of',\n",
       " 'finnlp',\n",
       " 'workshop',\n",
       " 'at',\n",
       " 'ijcai-2021',\n",
       " '.',\n",
       " 'the',\n",
       " 'shared',\n",
       " 'task',\n",
       " 'is',\n",
       " 'focused',\n",
       " 'on',\n",
       " 'solving',\n",
       " 'this',\n",
       " 'problem',\n",
       " 'for',\n",
       " 'the',\n",
       " 'ﬁnancial',\n",
       " 'domain',\n",
       " '.',\n",
       " 'we',\n",
       " 'experimented',\n",
       " 'with',\n",
       " 'var-',\n",
       " 'ious',\n",
       " 'transformer',\n",
       " 'based',\n",
       " 'pre',\n",
       " '-',\n",
       " 'trained',\n",
       " 'embeddings',\n",
       " 'by',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuning',\n",
       " 'these',\n",
       " 'for',\n",
       " 'either',\n",
       " 'classiﬁcation',\n",
       " 'or',\n",
       " 'phrase',\n",
       " 'similarity',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'we',\n",
       " 'also',\n",
       " 'augmented',\n",
       " 'the',\n",
       " 'provided',\n",
       " 'dataset',\n",
       " 'with',\n",
       " 'abbreviations',\n",
       " 'derived',\n",
       " 'from',\n",
       " 'prospectus',\n",
       " 'provided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'organizers',\n",
       " 'and',\n",
       " 'deﬁnitions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ﬁnancial',\n",
       " 'terms',\n",
       " 'from',\n",
       " 'dbpedia',\n",
       " '[',\n",
       " 'auer',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2007',\n",
       " ']',\n",
       " ',',\n",
       " 'investopedia',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'financial',\n",
       " 'industry',\n",
       " 'business',\n",
       " 'ontology',\n",
       " '(',\n",
       " 'fibo',\n",
       " ')',\n",
       " '.',\n",
       " 'our',\n",
       " 'best',\n",
       " 'performing',\n",
       " 'system',\n",
       " 'uses',\n",
       " 'both',\n",
       " 'finbert',\n",
       " '[',\n",
       " 'araci',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " 'and',\n",
       " 'data',\n",
       " 'augmenta-',\n",
       " 'tion',\n",
       " 'from',\n",
       " 'the',\n",
       " 'afore',\n",
       " '-',\n",
       " 'mentioned',\n",
       " 'sources',\n",
       " '.',\n",
       " 'we',\n",
       " 'ob-',\n",
       " 'served',\n",
       " 'that',\n",
       " 'term',\n",
       " 'expansion',\n",
       " 'using',\n",
       " 'data',\n",
       " 'augmentation',\n",
       " 'in',\n",
       " 'conjunction',\n",
       " 'with',\n",
       " 'semantic',\n",
       " 'similarity',\n",
       " 'is',\n",
       " 'beneﬁcial',\n",
       " 'for',\n",
       " 'this',\n",
       " 'task',\n",
       " 'and',\n",
       " 'could',\n",
       " 'be',\n",
       " 'useful',\n",
       " 'for',\n",
       " 'the',\n",
       " 'other',\n",
       " 'tasks',\n",
       " 'that',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'short',\n",
       " 'phrases',\n",
       " '.',\n",
       " 'our',\n",
       " 'best',\n",
       " 'performing',\n",
       " 'model',\n",
       " '(',\n",
       " 'accuracy',\n",
       " ':',\n",
       " '0.917',\n",
       " ',',\n",
       " 'rank',\n",
       " ':',\n",
       " '1.156',\n",
       " ')',\n",
       " 'was',\n",
       " 'devel-',\n",
       " 'oped',\n",
       " 'by',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuning',\n",
       " 'sentencebert',\n",
       " '[',\n",
       " 'reimers',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " '(',\n",
       " 'with',\n",
       " 'finbert',\n",
       " 'at',\n",
       " 'the',\n",
       " 'backend',\n",
       " ')',\n",
       " 'over',\n",
       " 'an',\n",
       " 'ex-',\n",
       " 'tended',\n",
       " 'labelled',\n",
       " 'set',\n",
       " 'created',\n",
       " 'using',\n",
       " 'the',\n",
       " 'hierarchy',\n",
       " 'of',\n",
       " 'labels',\n",
       " 'present',\n",
       " 'in',\n",
       " 'fibo',\n",
       " '.',\n",
       " '1',\n",
       " 'introduction',\n",
       " 'ontologies',\n",
       " 'are',\n",
       " 'rich',\n",
       " 'sources',\n",
       " 'of',\n",
       " 'information',\n",
       " 'that',\n",
       " 'provide',\n",
       " 'deep',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'underlying',\n",
       " 'concepts',\n",
       " 'and',\n",
       " 'entities',\n",
       " '.',\n",
       " 'this',\n",
       " 'information',\n",
       " 'is',\n",
       " 'described',\n",
       " 'for',\n",
       " 'a',\n",
       " 'speciﬁc',\n",
       " 'domain',\n",
       " '.',\n",
       " 'it',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'clearly',\n",
       " 'deﬁned',\n",
       " 'relationships',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'organized',\n",
       " 'in',\n",
       " 'a',\n",
       " 'deﬁned',\n",
       " 'structure',\n",
       " 'mostly',\n",
       " 'as',\n",
       " 'a',\n",
       " 'hierarchy',\n",
       " '.',\n",
       " 'these',\n",
       " 'properties',\n",
       " 'make',\n",
       " 'on-',\n",
       " 'tologies',\n",
       " 'a',\n",
       " 'great',\n",
       " 'source',\n",
       " 'for',\n",
       " 'getting',\n",
       " 'a',\n",
       " 'deeper',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'relationship',\n",
       " 'and',\n",
       " 'properties',\n",
       " 'of',\n",
       " 'resources',\n",
       " 'of',\n",
       " 'the',\n",
       " 'domain',\n",
       " 'in',\n",
       " 'consideration',\n",
       " '.',\n",
       " 'public',\n",
       " 'knowledge',\n",
       " 'graphs',\n",
       " 'and',\n",
       " 'ontologies',\n",
       " 'like',\n",
       " 'dbpedia',\n",
       " 'and',\n",
       " 'yago',\n",
       " 'have',\n",
       " 'been',\n",
       " 'shown',\n",
       " 'to',\n",
       " 'work',\n",
       " 'on',\n",
       " 'various',\n",
       " 'applications',\n",
       " 'like',\n",
       " '∗contact',\n",
       " 'author',\n",
       " '†equal',\n",
       " 'contribution',\n",
       " 'the',\n",
       " 'ones',\n",
       " 'described',\n",
       " 'in',\n",
       " '[',\n",
       " 'kobilarov',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2009',\n",
       " ']',\n",
       " 'and',\n",
       " '[',\n",
       " 'hahm',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2014',\n",
       " ']',\n",
       " '.',\n",
       " 'this',\n",
       " 'has',\n",
       " 'motivated',\n",
       " 'and',\n",
       " 'paved',\n",
       " 'ways',\n",
       " 'for',\n",
       " 'the',\n",
       " 'creation',\n",
       " 'of',\n",
       " 'domain',\n",
       " 'focused',\n",
       " 'ontologies',\n",
       " 'like',\n",
       " 'fibo1',\n",
       " '.',\n",
       " 'effective',\n",
       " 'techniques',\n",
       " 'that',\n",
       " 'enable',\n",
       " 'identifying',\n",
       " 'lexical',\n",
       " 'similar-',\n",
       " 'ity',\n",
       " 'between',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'or',\n",
       " 'concepts',\n",
       " 'increase',\n",
       " 'the',\n",
       " 'effectiveness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'ontologies',\n",
       " '.',\n",
       " 'these',\n",
       " 'methods',\n",
       " 'not',\n",
       " 'only',\n",
       " 'help',\n",
       " 'in',\n",
       " 'building',\n",
       " 'new',\n",
       " 'ontologies',\n",
       " 'faster',\n",
       " 'or',\n",
       " 'augment',\n",
       " 'the',\n",
       " 'existing',\n",
       " 'ones',\n",
       " ',',\n",
       " 'but',\n",
       " 'also',\n",
       " 'it',\n",
       " 'helps',\n",
       " 'in',\n",
       " 'the',\n",
       " 'effective',\n",
       " 'querying',\n",
       " 'and',\n",
       " 'searching',\n",
       " 'of',\n",
       " 'concepts',\n",
       " '.',\n",
       " 'finsim',\n",
       " '[',\n",
       " 'maarouf',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ';',\n",
       " 'mansar',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2021',\n",
       " ']',\n",
       " 'compe-',\n",
       " 'titions',\n",
       " 'are',\n",
       " 'being',\n",
       " 'held',\n",
       " 'to',\n",
       " 'promote',\n",
       " 'the',\n",
       " 'development',\n",
       " 'of',\n",
       " 'effective',\n",
       " 'similarity',\n",
       " 'measures',\n",
       " '.',\n",
       " 'in',\n",
       " 'the',\n",
       " 'third',\n",
       " 'edition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'competition',\n",
       " 'finsim-32',\n",
       " '(',\n",
       " 'being',\n",
       " 'held',\n",
       " 'in',\n",
       " 'conjunction',\n",
       " 'with',\n",
       " 'the',\n",
       " '30th',\n",
       " 'interna-',\n",
       " 'tional',\n",
       " 'joint',\n",
       " 'conference',\n",
       " 'on',\n",
       " 'artiﬁcial',\n",
       " 'intelligence',\n",
       " '(',\n",
       " 'ijcai-21',\n",
       " ')',\n",
       " ')',\n",
       " ',',\n",
       " 'the',\n",
       " 'participants',\n",
       " 'are',\n",
       " 'challenged',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'methods',\n",
       " 'and',\n",
       " 'sys-',\n",
       " 'tems',\n",
       " 'to',\n",
       " 'rank',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonyms',\n",
       " 'to',\n",
       " 'ﬁnancial',\n",
       " 'terms',\n",
       " 'by',\n",
       " 'mapping',\n",
       " 'them',\n",
       " 'to',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " '17',\n",
       " 'high',\n",
       " '-',\n",
       " 'level',\n",
       " 'ﬁnancial',\n",
       " 'concepts',\n",
       " 'present',\n",
       " 'in',\n",
       " 'fibo',\n",
       " '.',\n",
       " 'in',\n",
       " 'this',\n",
       " 'paper',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'the',\n",
       " 'systems',\n",
       " 'developed',\n",
       " 'by',\n",
       " 'our',\n",
       " 'team',\n",
       " 'lipi',\n",
       " 'for',\n",
       " 'hypernym',\n",
       " 'and',\n",
       " 'synonym',\n",
       " 'ranking',\n",
       " '.',\n",
       " 'we',\n",
       " 'experi-',\n",
       " 'mented',\n",
       " 'with',\n",
       " 'basic',\n",
       " 'featurization',\n",
       " 'methods',\n",
       " 'like',\n",
       " 'tf',\n",
       " '-',\n",
       " 'idf',\n",
       " 'and',\n",
       " 'ad-',\n",
       " 'vanced',\n",
       " 'methods',\n",
       " 'like',\n",
       " 'pre',\n",
       " '-',\n",
       " 'trained',\n",
       " 'embedding',\n",
       " 'models',\n",
       " '.',\n",
       " 'our',\n",
       " 'top',\n",
       " '3',\n",
       " 'systems',\n",
       " 'use',\n",
       " 'pre',\n",
       " '-',\n",
       " 'trained',\n",
       " 'finbert',\n",
       " '[',\n",
       " 'araci',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " 'embedding',\n",
       " 'model',\n",
       " 'that',\n",
       " 'was',\n",
       " 'ﬁne',\n",
       " '-',\n",
       " 'tuned',\n",
       " 'on',\n",
       " 'the',\n",
       " 'data',\n",
       " 'speciﬁc',\n",
       " 'to',\n",
       " 'ﬁnancial',\n",
       " 'do-',\n",
       " 'main',\n",
       " '.',\n",
       " 'we',\n",
       " 'also',\n",
       " 'augmented',\n",
       " 'the',\n",
       " 'training',\n",
       " 'data',\n",
       " 'by',\n",
       " 'utilizing',\n",
       " 'the',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'dbpedia',\n",
       " ',',\n",
       " 'investopedia',\n",
       " ',',\n",
       " 'fibo',\n",
       " 'and',\n",
       " 'text',\n",
       " 'cor-',\n",
       " 'pus',\n",
       " 'of',\n",
       " 'prospectus',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " '.',\n",
       " 'we',\n",
       " 'describe',\n",
       " 'the',\n",
       " 'works',\n",
       " 're-',\n",
       " 'lated',\n",
       " 'to',\n",
       " 'our',\n",
       " 'solution',\n",
       " 'in',\n",
       " 'the',\n",
       " 'next',\n",
       " 'section',\n",
       " '.',\n",
       " 'section',\n",
       " '3',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'formal',\n",
       " 'problem',\n",
       " 'statement',\n",
       " ',',\n",
       " 'followed',\n",
       " 'by',\n",
       " 'data',\n",
       " 'description',\n",
       " 'in',\n",
       " 'section',\n",
       " '4',\n",
       " '.',\n",
       " 'we',\n",
       " 'describe',\n",
       " 'our',\n",
       " 'top',\n",
       " 'three',\n",
       " 'systems',\n",
       " 'in',\n",
       " 'section',\n",
       " '5',\n",
       " '.',\n",
       " 'section',\n",
       " '6',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'details',\n",
       " 'of',\n",
       " 'the',\n",
       " 'experimentation',\n",
       " 'that',\n",
       " 'we',\n",
       " 'performed',\n",
       " 'and',\n",
       " 'the',\n",
       " 'results',\n",
       " 'obtained',\n",
       " 'from',\n",
       " 'some',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'we',\n",
       " 'draw',\n",
       " 'our',\n",
       " 'conclusions',\n",
       " 'in',\n",
       " 'section',\n",
       " '7',\n",
       " 'while',\n",
       " 'giving',\n",
       " 'a',\n",
       " 'glimpse',\n",
       " 'of',\n",
       " 'things',\n",
       " 'that',\n",
       " 'we',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'try',\n",
       " 'in',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " '2',\n",
       " 'related',\n",
       " 'works',\n",
       " 'hypernym',\n",
       " '-',\n",
       " 'hyponym',\n",
       " 'extraction',\n",
       " 'and',\n",
       " 'learning',\n",
       " 'text',\n",
       " 'similarity',\n",
       " 'using',\n",
       " 'semantic',\n",
       " 'representations',\n",
       " 'have',\n",
       " 'been',\n",
       " 'very',\n",
       " 'challenging',\n",
       " 'areas',\n",
       " 'of',\n",
       " 'research',\n",
       " 'for',\n",
       " 'the',\n",
       " 'nlp',\n",
       " 'community',\n",
       " '.',\n",
       " 'semeval-2018',\n",
       " 'task',\n",
       " '9',\n",
       " '[',\n",
       " 'camacho',\n",
       " '-',\n",
       " 'collados',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2018',\n",
       " ']',\n",
       " 'was',\n",
       " 'such',\n",
       " 'an',\n",
       " 'instance',\n",
       " '.',\n",
       " '1https://spec.edmcouncil.org/ﬁbo/',\n",
       " '2https://sites.google.com/nlg.csie.ntu.edu.tw/ﬁnnlp2021/shared-',\n",
       " 'task-ﬁnsim',\n",
       " '(',\n",
       " 'accessed',\n",
       " 'on',\n",
       " '8th',\n",
       " 'july',\n",
       " '2021',\n",
       " ')',\n",
       " '\\n\\n\\x0c',\n",
       " 'team',\n",
       " 'crim',\n",
       " '[',\n",
       " 'bernier',\n",
       " '-',\n",
       " 'colborne',\n",
       " 'and',\n",
       " 'barri`ere',\n",
       " ',',\n",
       " '2018',\n",
       " ']',\n",
       " 'per-',\n",
       " 'formed',\n",
       " 'the',\n",
       " 'best',\n",
       " 'in',\n",
       " 'this',\n",
       " 'shared',\n",
       " 'task',\n",
       " '.',\n",
       " 'they',\n",
       " 'combined',\n",
       " 'a',\n",
       " 'super-',\n",
       " 'vised',\n",
       " 'word',\n",
       " 'embedding',\n",
       " 'based',\n",
       " 'approach',\n",
       " 'with',\n",
       " 'an',\n",
       " 'unsupervised',\n",
       " 'pattern',\n",
       " 'discovery',\n",
       " 'based',\n",
       " 'approach',\n",
       " '.',\n",
       " 'the',\n",
       " 'finsim',\n",
       " 'shared',\n",
       " 'tasks',\n",
       " '[',\n",
       " 'maarouf',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ';',\n",
       " 'mansar',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2021',\n",
       " ']',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'adopt-',\n",
       " 'ing',\n",
       " 'these',\n",
       " 'challenges',\n",
       " 'speciﬁc',\n",
       " 'to',\n",
       " 'the',\n",
       " 'financial',\n",
       " 'domain',\n",
       " '.',\n",
       " 'team',\n",
       " 'iit',\n",
       " '-',\n",
       " 'k',\n",
       " '[',\n",
       " 'keswani',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ']',\n",
       " 'won',\n",
       " 'finsim-1',\n",
       " 'using',\n",
       " 'a',\n",
       " 'combi-',\n",
       " 'nation',\n",
       " 'of',\n",
       " 'context',\n",
       " '-',\n",
       " 'free',\n",
       " 'static',\n",
       " 'embedding',\n",
       " 'word2vec',\n",
       " '[',\n",
       " 'mikolov',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2013',\n",
       " ']',\n",
       " 'and',\n",
       " 'contextualized',\n",
       " 'dynamic',\n",
       " 'embedding',\n",
       " 'bert',\n",
       " '[',\n",
       " 'devlin',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2019',\n",
       " ']',\n",
       " '.',\n",
       " 'anand',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " '[',\n",
       " 'anand',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2020',\n",
       " ']',\n",
       " 'from',\n",
       " 'the',\n",
       " 'team',\n",
       " 'finsim20',\n",
       " 'explored',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'cosine',\n",
       " 'similarity',\n",
       " 'be-',\n",
       " 'tween',\n",
       " 'terms',\n",
       " 'and',\n",
       " 'labels',\n",
       " 'encoded',\n",
       " 'using',\n",
       " 'universal',\n",
       " 'sentence',\n",
       " 'en-',\n",
       " 'coder',\n",
       " '[',\n",
       " 'cer',\n",
       " 'et',\n",
       " 'al',\n",
       " '.',\n",
       " ',',\n",
       " '2018',\n",
       " ']',\n",
       " '.',\n",
       " 'they',\n",
       " 'also',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'hypernyms',\n",
       " 'automatically',\n",
       " 'using',\n",
       " 'graph',\n",
       " 'based',\n",
       " 'approaches',\n",
       " '.',\n",
       " 'team',\n",
       " 'polyu-',\n",
       " 'cbs',\n",
       " '[',\n",
       " 'chersoni',\n",
       " 'and',\n",
       " 'huang',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Arx_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5330f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b63b568",
   "metadata": {},
   "source": [
    "# Cosin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2776785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50a45f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "    return np.dot(vector1, vector2) / (np.sqrt(np.sum(vector1**2)) * np.sqrt(np.sum(vector2**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73c4baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7df32e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.Series(doc_Anth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "236fb732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5430x1401 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4374 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix = vectorizer.fit_transform(Anth_lst)\n",
    "bow_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3bf9d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193635\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_count = vectorizer.get_feature_names()\n",
    "feature_names_count\n",
    "features_array_count = bow_matrix.toarray()\n",
    "features_array_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06c55d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193635\\AppData\\Local\\Temp/ipykernel_13936/1179820790.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.dot(vector1, vector2) / (np.sqrt(np.sum(vector1**2)) * np.sqrt(np.sum(vector2**2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5 is:  nan\n",
      "The cosine similarity between the documents  0 and 6 is:  0.0\n",
      "The cosine similarity between the documents  0 and 7 is:  0.0\n",
      "The cosine similarity between the documents  0 and 8 is:  0.0\n",
      "The cosine similarity between the documents  0 and 9 is:  0.0\n",
      "The cosine similarity between the documents  0 and 10 is:  0.0\n",
      "The cosine similarity between the documents  0 and 11 is:  0.0\n",
      "The cosine similarity between the documents  0 and 12 is:  0.0\n",
      "The cosine similarity between the documents  0 and 13 is:  0.0\n",
      "The cosine similarity between the documents  0 and 14 is:  0.0\n",
      "The cosine similarity between the documents  0 and 15 is:  0.0\n",
      "The cosine similarity between the documents  0 and 16 is:  0.0\n",
      "The cosine similarity between the documents  0 and 17 is:  nan\n",
      "The cosine similarity between the documents  0 and 18 is:  0.0\n",
      "The cosine similarity between the documents  0 and 19 is:  0.0\n",
      "The cosine similarity between the documents  0 and 20 is:  0.0\n",
      "The cosine similarity between the documents  0 and 21 is:  0.0\n",
      "The cosine similarity between the documents  0 and 22 is:  nan\n",
      "The cosine similarity between the documents  0 and 23 is:  0.0\n",
      "The cosine similarity between the documents  0 and 24 is:  0.0\n",
      "The cosine similarity between the documents  0 and 25 is:  nan\n",
      "The cosine similarity between the documents  0 and 26 is:  0.0\n",
      "The cosine similarity between the documents  0 and 27 is:  nan\n",
      "The cosine similarity between the documents  0 and 28 is:  0.0\n",
      "The cosine similarity between the documents  0 and 29 is:  nan\n",
      "The cosine similarity between the documents  0 and 30 is:  0.0\n",
      "The cosine similarity between the documents  0 and 31 is:  nan\n",
      "The cosine similarity between the documents  0 and 32 is:  0.0\n",
      "The cosine similarity between the documents  0 and 33 is:  0.0\n",
      "The cosine similarity between the documents  0 and 34 is:  0.0\n",
      "The cosine similarity between the documents  0 and 35 is:  0.0\n",
      "The cosine similarity between the documents  0 and 36 is:  0.0\n",
      "The cosine similarity between the documents  0 and 37 is:  0.0\n",
      "The cosine similarity between the documents  0 and 38 is:  0.0\n",
      "The cosine similarity between the documents  0 and 39 is:  0.0\n",
      "The cosine similarity between the documents  0 and 40 is:  0.0\n",
      "The cosine similarity between the documents  0 and 41 is:  0.0\n",
      "The cosine similarity between the documents  0 and 42 is:  0.0\n",
      "The cosine similarity between the documents  0 and 43 is:  0.0\n",
      "The cosine similarity between the documents  0 and 44 is:  0.0\n",
      "The cosine similarity between the documents  0 and 45 is:  0.0\n",
      "The cosine similarity between the documents  0 and 46 is:  nan\n",
      "The cosine similarity between the documents  0 and 47 is:  0.0\n",
      "The cosine similarity between the documents  0 and 48 is:  nan\n",
      "The cosine similarity between the documents  0 and 49 is:  0.0\n",
      "The cosine similarity between the documents  0 and 50 is:  nan\n",
      "The cosine similarity between the documents  0 and 51 is:  0.0\n",
      "The cosine similarity between the documents  0 and 52 is:  0.0\n",
      "The cosine similarity between the documents  0 and 53 is:  0.0\n",
      "The cosine similarity between the documents  0 and 54 is:  nan\n",
      "The cosine similarity between the documents  0 and 55 is:  0.0\n",
      "The cosine similarity between the documents  0 and 56 is:  0.0\n",
      "The cosine similarity between the documents  0 and 57 is:  0.0\n",
      "The cosine similarity between the documents  0 and 58 is:  0.0\n",
      "The cosine similarity between the documents  0 and 59 is:  0.0\n",
      "The cosine similarity between the documents  0 and 60 is:  0.0\n",
      "The cosine similarity between the documents  0 and 61 is:  0.0\n",
      "The cosine similarity between the documents  0 and 62 is:  0.0\n",
      "The cosine similarity between the documents  0 and 63 is:  0.0\n",
      "The cosine similarity between the documents  0 and 64 is:  0.0\n",
      "The cosine similarity between the documents  0 and 65 is:  nan\n",
      "The cosine similarity between the documents  0 and 66 is:  0.0\n",
      "The cosine similarity between the documents  0 and 67 is:  0.0\n",
      "The cosine similarity between the documents  0 and 68 is:  0.0\n",
      "The cosine similarity between the documents  0 and 69 is:  0.0\n",
      "The cosine similarity between the documents  0 and 70 is:  0.0\n",
      "The cosine similarity between the documents  0 and 71 is:  0.0\n",
      "The cosine similarity between the documents  0 and 72 is:  0.0\n",
      "The cosine similarity between the documents  0 and 73 is:  0.0\n",
      "The cosine similarity between the documents  0 and 74 is:  0.0\n",
      "The cosine similarity between the documents  0 and 75 is:  nan\n",
      "The cosine similarity between the documents  0 and 76 is:  nan\n",
      "The cosine similarity between the documents  0 and 77 is:  0.0\n",
      "The cosine similarity between the documents  0 and 78 is:  0.0\n",
      "The cosine similarity between the documents  0 and 79 is:  0.0\n",
      "The cosine similarity between the documents  0 and 80 is:  0.0\n",
      "The cosine similarity between the documents  0 and 81 is:  0.0\n",
      "The cosine similarity between the documents  0 and 82 is:  0.0\n",
      "The cosine similarity between the documents  0 and 83 is:  0.0\n",
      "The cosine similarity between the documents  0 and 84 is:  nan\n",
      "The cosine similarity between the documents  0 and 85 is:  0.0\n",
      "The cosine similarity between the documents  0 and 86 is:  0.0\n",
      "The cosine similarity between the documents  0 and 87 is:  0.0\n",
      "The cosine similarity between the documents  0 and 88 is:  0.0\n",
      "The cosine similarity between the documents  0 and 89 is:  0.0\n",
      "The cosine similarity between the documents  0 and 90 is:  0.0\n",
      "The cosine similarity between the documents  0 and 91 is:  0.0\n",
      "The cosine similarity between the documents  0 and 92 is:  0.0\n",
      "The cosine similarity between the documents  0 and 93 is:  0.0\n",
      "The cosine similarity between the documents  0 and 94 is:  0.0\n",
      "The cosine similarity between the documents  0 and 95 is:  0.0\n",
      "The cosine similarity between the documents  0 and 96 is:  0.0\n",
      "The cosine similarity between the documents  0 and 97 is:  0.0\n",
      "The cosine similarity between the documents  0 and 98 is:  nan\n",
      "The cosine similarity between the documents  0 and 99 is:  0.0\n",
      "The cosine similarity between the documents  0 and 100 is:  0.0\n",
      "The cosine similarity between the documents  0 and 101 is:  0.0\n",
      "The cosine similarity between the documents  0 and 102 is:  0.0\n",
      "The cosine similarity between the documents  0 and 103 is:  0.0\n",
      "The cosine similarity between the documents  0 and 104 is:  0.0\n",
      "The cosine similarity between the documents  0 and 105 is:  0.0\n",
      "The cosine similarity between the documents  0 and 106 is:  0.0\n",
      "The cosine similarity between the documents  0 and 107 is:  nan\n",
      "The cosine similarity between the documents  0 and 108 is:  0.0\n",
      "The cosine similarity between the documents  0 and 109 is:  0.0\n",
      "The cosine similarity between the documents  0 and 110 is:  0.0\n",
      "The cosine similarity between the documents  0 and 111 is:  0.0\n",
      "The cosine similarity between the documents  0 and 112 is:  nan\n",
      "The cosine similarity between the documents  0 and 113 is:  0.0\n",
      "The cosine similarity between the documents  0 and 114 is:  0.0\n",
      "The cosine similarity between the documents  0 and 115 is:  0.0\n",
      "The cosine similarity between the documents  0 and 116 is:  0.0\n",
      "The cosine similarity between the documents  0 and 117 is:  0.0\n",
      "The cosine similarity between the documents  0 and 118 is:  0.0\n",
      "The cosine similarity between the documents  0 and 119 is:  0.0\n",
      "The cosine similarity between the documents  0 and 120 is:  0.0\n",
      "The cosine similarity between the documents  0 and 121 is:  0.0\n",
      "The cosine similarity between the documents  0 and 122 is:  nan\n",
      "The cosine similarity between the documents  0 and 123 is:  0.0\n",
      "The cosine similarity between the documents  0 and 124 is:  0.0\n",
      "The cosine similarity between the documents  0 and 125 is:  0.0\n",
      "The cosine similarity between the documents  0 and 126 is:  0.0\n",
      "The cosine similarity between the documents  0 and 127 is:  0.0\n",
      "The cosine similarity between the documents  0 and 128 is:  0.0\n",
      "The cosine similarity between the documents  0 and 129 is:  0.0\n",
      "The cosine similarity between the documents  0 and 130 is:  0.0\n",
      "The cosine similarity between the documents  0 and 131 is:  0.0\n",
      "The cosine similarity between the documents  0 and 132 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 133 is:  0.0\n",
      "The cosine similarity between the documents  0 and 134 is:  0.0\n",
      "The cosine similarity between the documents  0 and 135 is:  0.0\n",
      "The cosine similarity between the documents  0 and 136 is:  0.0\n",
      "The cosine similarity between the documents  0 and 137 is:  0.0\n",
      "The cosine similarity between the documents  0 and 138 is:  0.0\n",
      "The cosine similarity between the documents  0 and 139 is:  0.0\n",
      "The cosine similarity between the documents  0 and 140 is:  0.0\n",
      "The cosine similarity between the documents  0 and 141 is:  0.0\n",
      "The cosine similarity between the documents  0 and 142 is:  0.0\n",
      "The cosine similarity between the documents  0 and 143 is:  0.0\n",
      "The cosine similarity between the documents  0 and 144 is:  0.0\n",
      "The cosine similarity between the documents  0 and 145 is:  0.0\n",
      "The cosine similarity between the documents  0 and 146 is:  nan\n",
      "The cosine similarity between the documents  0 and 147 is:  0.0\n",
      "The cosine similarity between the documents  0 and 148 is:  0.0\n",
      "The cosine similarity between the documents  0 and 149 is:  0.0\n",
      "The cosine similarity between the documents  0 and 150 is:  nan\n",
      "The cosine similarity between the documents  0 and 151 is:  nan\n",
      "The cosine similarity between the documents  0 and 152 is:  0.0\n",
      "The cosine similarity between the documents  0 and 153 is:  nan\n",
      "The cosine similarity between the documents  0 and 154 is:  nan\n",
      "The cosine similarity between the documents  0 and 155 is:  0.0\n",
      "The cosine similarity between the documents  0 and 156 is:  nan\n",
      "The cosine similarity between the documents  0 and 157 is:  0.0\n",
      "The cosine similarity between the documents  0 and 158 is:  0.0\n",
      "The cosine similarity between the documents  0 and 159 is:  0.0\n",
      "The cosine similarity between the documents  0 and 160 is:  0.0\n",
      "The cosine similarity between the documents  0 and 161 is:  0.0\n",
      "The cosine similarity between the documents  0 and 162 is:  0.0\n",
      "The cosine similarity between the documents  0 and 163 is:  nan\n",
      "The cosine similarity between the documents  0 and 164 is:  0.0\n",
      "The cosine similarity between the documents  0 and 165 is:  nan\n",
      "The cosine similarity between the documents  0 and 166 is:  nan\n",
      "The cosine similarity between the documents  0 and 167 is:  0.0\n",
      "The cosine similarity between the documents  0 and 168 is:  0.0\n",
      "The cosine similarity between the documents  0 and 169 is:  0.0\n",
      "The cosine similarity between the documents  0 and 170 is:  0.0\n",
      "The cosine similarity between the documents  0 and 171 is:  0.0\n",
      "The cosine similarity between the documents  0 and 172 is:  0.0\n",
      "The cosine similarity between the documents  0 and 173 is:  0.0\n",
      "The cosine similarity between the documents  0 and 174 is:  nan\n",
      "The cosine similarity between the documents  0 and 175 is:  0.0\n",
      "The cosine similarity between the documents  0 and 176 is:  nan\n",
      "The cosine similarity between the documents  0 and 177 is:  0.0\n",
      "The cosine similarity between the documents  0 and 178 is:  nan\n",
      "The cosine similarity between the documents  0 and 179 is:  0.0\n",
      "The cosine similarity between the documents  0 and 180 is:  0.0\n",
      "The cosine similarity between the documents  0 and 181 is:  0.0\n",
      "The cosine similarity between the documents  0 and 182 is:  0.0\n",
      "The cosine similarity between the documents  0 and 183 is:  0.0\n",
      "The cosine similarity between the documents  0 and 184 is:  0.0\n",
      "The cosine similarity between the documents  0 and 185 is:  0.0\n",
      "The cosine similarity between the documents  0 and 186 is:  nan\n",
      "The cosine similarity between the documents  0 and 187 is:  0.0\n",
      "The cosine similarity between the documents  0 and 188 is:  0.0\n",
      "The cosine similarity between the documents  0 and 189 is:  nan\n",
      "The cosine similarity between the documents  0 and 190 is:  0.0\n",
      "The cosine similarity between the documents  0 and 191 is:  0.0\n",
      "The cosine similarity between the documents  0 and 192 is:  0.0\n",
      "The cosine similarity between the documents  0 and 193 is:  0.0\n",
      "The cosine similarity between the documents  0 and 194 is:  1.0\n",
      "The cosine similarity between the documents  0 and 195 is:  0.0\n",
      "The cosine similarity between the documents  0 and 196 is:  0.0\n",
      "The cosine similarity between the documents  0 and 197 is:  0.0\n",
      "The cosine similarity between the documents  0 and 198 is:  0.0\n",
      "The cosine similarity between the documents  0 and 199 is:  0.0\n",
      "The cosine similarity between the documents  0 and 200 is:  0.0\n",
      "The cosine similarity between the documents  0 and 201 is:  0.0\n",
      "The cosine similarity between the documents  0 and 202 is:  0.0\n",
      "The cosine similarity between the documents  0 and 203 is:  0.0\n",
      "The cosine similarity between the documents  0 and 204 is:  0.0\n",
      "The cosine similarity between the documents  0 and 205 is:  0.0\n",
      "The cosine similarity between the documents  0 and 206 is:  0.0\n",
      "The cosine similarity between the documents  0 and 207 is:  0.0\n",
      "The cosine similarity between the documents  0 and 208 is:  0.0\n",
      "The cosine similarity between the documents  0 and 209 is:  0.0\n",
      "The cosine similarity between the documents  0 and 210 is:  0.0\n",
      "The cosine similarity between the documents  0 and 211 is:  0.0\n",
      "The cosine similarity between the documents  0 and 212 is:  0.0\n",
      "The cosine similarity between the documents  0 and 213 is:  0.0\n",
      "The cosine similarity between the documents  0 and 214 is:  0.0\n",
      "The cosine similarity between the documents  0 and 215 is:  0.0\n",
      "The cosine similarity between the documents  0 and 216 is:  0.0\n",
      "The cosine similarity between the documents  0 and 217 is:  0.0\n",
      "The cosine similarity between the documents  0 and 218 is:  0.0\n",
      "The cosine similarity between the documents  0 and 219 is:  0.0\n",
      "The cosine similarity between the documents  0 and 220 is:  0.0\n",
      "The cosine similarity between the documents  0 and 221 is:  0.0\n",
      "The cosine similarity between the documents  0 and 222 is:  0.0\n",
      "The cosine similarity between the documents  0 and 223 is:  0.0\n",
      "The cosine similarity between the documents  0 and 224 is:  nan\n",
      "The cosine similarity between the documents  0 and 225 is:  0.0\n",
      "The cosine similarity between the documents  0 and 226 is:  0.0\n",
      "The cosine similarity between the documents  0 and 227 is:  0.0\n",
      "The cosine similarity between the documents  0 and 228 is:  0.0\n",
      "The cosine similarity between the documents  0 and 229 is:  nan\n",
      "The cosine similarity between the documents  0 and 230 is:  0.0\n",
      "The cosine similarity between the documents  0 and 231 is:  nan\n",
      "The cosine similarity between the documents  0 and 232 is:  0.0\n",
      "The cosine similarity between the documents  0 and 233 is:  nan\n",
      "The cosine similarity between the documents  0 and 234 is:  0.0\n",
      "The cosine similarity between the documents  0 and 235 is:  nan\n",
      "The cosine similarity between the documents  0 and 236 is:  0.0\n",
      "The cosine similarity between the documents  0 and 237 is:  nan\n",
      "The cosine similarity between the documents  0 and 238 is:  0.0\n",
      "The cosine similarity between the documents  0 and 239 is:  0.0\n",
      "The cosine similarity between the documents  0 and 240 is:  0.0\n",
      "The cosine similarity between the documents  0 and 241 is:  0.0\n",
      "The cosine similarity between the documents  0 and 242 is:  nan\n",
      "The cosine similarity between the documents  0 and 243 is:  0.0\n",
      "The cosine similarity between the documents  0 and 244 is:  0.0\n",
      "The cosine similarity between the documents  0 and 245 is:  0.0\n",
      "The cosine similarity between the documents  0 and 246 is:  nan\n",
      "The cosine similarity between the documents  0 and 247 is:  0.0\n",
      "The cosine similarity between the documents  0 and 248 is:  0.0\n",
      "The cosine similarity between the documents  0 and 249 is:  0.0\n",
      "The cosine similarity between the documents  0 and 250 is:  nan\n",
      "The cosine similarity between the documents  0 and 251 is:  nan\n",
      "The cosine similarity between the documents  0 and 252 is:  0.0\n",
      "The cosine similarity between the documents  0 and 253 is:  nan\n",
      "The cosine similarity between the documents  0 and 254 is:  nan\n",
      "The cosine similarity between the documents  0 and 255 is:  0.0\n",
      "The cosine similarity between the documents  0 and 256 is:  0.0\n",
      "The cosine similarity between the documents  0 and 257 is:  0.0\n",
      "The cosine similarity between the documents  0 and 258 is:  0.0\n",
      "The cosine similarity between the documents  0 and 259 is:  0.0\n",
      "The cosine similarity between the documents  0 and 260 is:  nan\n",
      "The cosine similarity between the documents  0 and 261 is:  0.0\n",
      "The cosine similarity between the documents  0 and 262 is:  0.0\n",
      "The cosine similarity between the documents  0 and 263 is:  0.0\n",
      "The cosine similarity between the documents  0 and 264 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 265 is:  0.0\n",
      "The cosine similarity between the documents  0 and 266 is:  0.0\n",
      "The cosine similarity between the documents  0 and 267 is:  0.0\n",
      "The cosine similarity between the documents  0 and 268 is:  0.0\n",
      "The cosine similarity between the documents  0 and 269 is:  0.0\n",
      "The cosine similarity between the documents  0 and 270 is:  0.0\n",
      "The cosine similarity between the documents  0 and 271 is:  0.0\n",
      "The cosine similarity between the documents  0 and 272 is:  0.0\n",
      "The cosine similarity between the documents  0 and 273 is:  0.0\n",
      "The cosine similarity between the documents  0 and 274 is:  0.0\n",
      "The cosine similarity between the documents  0 and 275 is:  0.0\n",
      "The cosine similarity between the documents  0 and 276 is:  nan\n",
      "The cosine similarity between the documents  0 and 277 is:  0.0\n",
      "The cosine similarity between the documents  0 and 278 is:  nan\n",
      "The cosine similarity between the documents  0 and 279 is:  0.0\n",
      "The cosine similarity between the documents  0 and 280 is:  0.0\n",
      "The cosine similarity between the documents  0 and 281 is:  0.0\n",
      "The cosine similarity between the documents  0 and 282 is:  0.0\n",
      "The cosine similarity between the documents  0 and 283 is:  0.0\n",
      "The cosine similarity between the documents  0 and 284 is:  0.0\n",
      "The cosine similarity between the documents  0 and 285 is:  0.0\n",
      "The cosine similarity between the documents  0 and 286 is:  0.0\n",
      "The cosine similarity between the documents  0 and 287 is:  0.0\n",
      "The cosine similarity between the documents  0 and 288 is:  0.0\n",
      "The cosine similarity between the documents  0 and 289 is:  0.0\n",
      "The cosine similarity between the documents  0 and 290 is:  0.0\n",
      "The cosine similarity between the documents  0 and 291 is:  0.0\n",
      "The cosine similarity between the documents  0 and 292 is:  0.0\n",
      "The cosine similarity between the documents  0 and 293 is:  0.0\n",
      "The cosine similarity between the documents  0 and 294 is:  0.0\n",
      "The cosine similarity between the documents  0 and 295 is:  nan\n",
      "The cosine similarity between the documents  0 and 296 is:  0.0\n",
      "The cosine similarity between the documents  0 and 297 is:  0.0\n",
      "The cosine similarity between the documents  0 and 298 is:  0.0\n",
      "The cosine similarity between the documents  0 and 299 is:  0.0\n",
      "The cosine similarity between the documents  0 and 300 is:  0.0\n",
      "The cosine similarity between the documents  0 and 301 is:  nan\n",
      "The cosine similarity between the documents  0 and 302 is:  0.0\n",
      "The cosine similarity between the documents  0 and 303 is:  0.0\n",
      "The cosine similarity between the documents  0 and 304 is:  nan\n",
      "The cosine similarity between the documents  0 and 305 is:  0.0\n",
      "The cosine similarity between the documents  0 and 306 is:  0.0\n",
      "The cosine similarity between the documents  0 and 307 is:  0.0\n",
      "The cosine similarity between the documents  0 and 308 is:  0.0\n",
      "The cosine similarity between the documents  0 and 309 is:  0.0\n",
      "The cosine similarity between the documents  0 and 310 is:  nan\n",
      "The cosine similarity between the documents  0 and 311 is:  0.0\n",
      "The cosine similarity between the documents  0 and 312 is:  0.0\n",
      "The cosine similarity between the documents  0 and 313 is:  0.0\n",
      "The cosine similarity between the documents  0 and 314 is:  nan\n",
      "The cosine similarity between the documents  0 and 315 is:  0.0\n",
      "The cosine similarity between the documents  0 and 316 is:  0.0\n",
      "The cosine similarity between the documents  0 and 317 is:  0.0\n",
      "The cosine similarity between the documents  0 and 318 is:  0.0\n",
      "The cosine similarity between the documents  0 and 319 is:  0.0\n",
      "The cosine similarity between the documents  0 and 320 is:  nan\n",
      "The cosine similarity between the documents  0 and 321 is:  0.0\n",
      "The cosine similarity between the documents  0 and 322 is:  nan\n",
      "The cosine similarity between the documents  0 and 323 is:  0.0\n",
      "The cosine similarity between the documents  0 and 324 is:  0.0\n",
      "The cosine similarity between the documents  0 and 325 is:  0.0\n",
      "The cosine similarity between the documents  0 and 326 is:  0.0\n",
      "The cosine similarity between the documents  0 and 327 is:  nan\n",
      "The cosine similarity between the documents  0 and 328 is:  0.0\n",
      "The cosine similarity between the documents  0 and 329 is:  0.0\n",
      "The cosine similarity between the documents  0 and 330 is:  0.0\n",
      "The cosine similarity between the documents  0 and 331 is:  0.0\n",
      "The cosine similarity between the documents  0 and 332 is:  nan\n",
      "The cosine similarity between the documents  0 and 333 is:  0.0\n",
      "The cosine similarity between the documents  0 and 334 is:  0.0\n",
      "The cosine similarity between the documents  0 and 335 is:  0.0\n",
      "The cosine similarity between the documents  0 and 336 is:  0.0\n",
      "The cosine similarity between the documents  0 and 337 is:  0.0\n",
      "The cosine similarity between the documents  0 and 338 is:  0.0\n",
      "The cosine similarity between the documents  0 and 339 is:  0.0\n",
      "The cosine similarity between the documents  0 and 340 is:  0.0\n",
      "The cosine similarity between the documents  0 and 341 is:  0.0\n",
      "The cosine similarity between the documents  0 and 342 is:  0.0\n",
      "The cosine similarity between the documents  0 and 343 is:  0.0\n",
      "The cosine similarity between the documents  0 and 344 is:  0.0\n",
      "The cosine similarity between the documents  0 and 345 is:  0.0\n",
      "The cosine similarity between the documents  0 and 346 is:  0.0\n",
      "The cosine similarity between the documents  0 and 347 is:  0.0\n",
      "The cosine similarity between the documents  0 and 348 is:  0.0\n",
      "The cosine similarity between the documents  0 and 349 is:  nan\n",
      "The cosine similarity between the documents  0 and 350 is:  0.0\n",
      "The cosine similarity between the documents  0 and 351 is:  0.0\n",
      "The cosine similarity between the documents  0 and 352 is:  0.0\n",
      "The cosine similarity between the documents  0 and 353 is:  0.0\n",
      "The cosine similarity between the documents  0 and 354 is:  0.0\n",
      "The cosine similarity between the documents  0 and 355 is:  0.0\n",
      "The cosine similarity between the documents  0 and 356 is:  0.0\n",
      "The cosine similarity between the documents  0 and 357 is:  0.0\n",
      "The cosine similarity between the documents  0 and 358 is:  0.0\n",
      "The cosine similarity between the documents  0 and 359 is:  0.0\n",
      "The cosine similarity between the documents  0 and 360 is:  0.0\n",
      "The cosine similarity between the documents  0 and 361 is:  0.0\n",
      "The cosine similarity between the documents  0 and 362 is:  0.0\n",
      "The cosine similarity between the documents  0 and 363 is:  0.0\n",
      "The cosine similarity between the documents  0 and 364 is:  0.0\n",
      "The cosine similarity between the documents  0 and 365 is:  0.0\n",
      "The cosine similarity between the documents  0 and 366 is:  0.0\n",
      "The cosine similarity between the documents  0 and 367 is:  0.0\n",
      "The cosine similarity between the documents  0 and 368 is:  0.0\n",
      "The cosine similarity between the documents  0 and 369 is:  0.0\n",
      "The cosine similarity between the documents  0 and 370 is:  0.0\n",
      "The cosine similarity between the documents  0 and 371 is:  0.0\n",
      "The cosine similarity between the documents  0 and 372 is:  0.0\n",
      "The cosine similarity between the documents  0 and 373 is:  0.0\n",
      "The cosine similarity between the documents  0 and 374 is:  0.0\n",
      "The cosine similarity between the documents  0 and 375 is:  0.0\n",
      "The cosine similarity between the documents  0 and 376 is:  nan\n",
      "The cosine similarity between the documents  0 and 377 is:  0.0\n",
      "The cosine similarity between the documents  0 and 378 is:  0.0\n",
      "The cosine similarity between the documents  0 and 379 is:  0.0\n",
      "The cosine similarity between the documents  0 and 380 is:  nan\n",
      "The cosine similarity between the documents  0 and 381 is:  nan\n",
      "The cosine similarity between the documents  0 and 382 is:  0.0\n",
      "The cosine similarity between the documents  0 and 383 is:  nan\n",
      "The cosine similarity between the documents  0 and 384 is:  0.0\n",
      "The cosine similarity between the documents  0 and 385 is:  nan\n",
      "The cosine similarity between the documents  0 and 386 is:  0.0\n",
      "The cosine similarity between the documents  0 and 387 is:  0.0\n",
      "The cosine similarity between the documents  0 and 388 is:  0.0\n",
      "The cosine similarity between the documents  0 and 389 is:  nan\n",
      "The cosine similarity between the documents  0 and 390 is:  nan\n",
      "The cosine similarity between the documents  0 and 391 is:  0.0\n",
      "The cosine similarity between the documents  0 and 392 is:  nan\n",
      "The cosine similarity between the documents  0 and 393 is:  nan\n",
      "The cosine similarity between the documents  0 and 394 is:  0.0\n",
      "The cosine similarity between the documents  0 and 395 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 396 is:  0.0\n",
      "The cosine similarity between the documents  0 and 397 is:  0.0\n",
      "The cosine similarity between the documents  0 and 398 is:  0.0\n",
      "The cosine similarity between the documents  0 and 399 is:  0.0\n",
      "The cosine similarity between the documents  0 and 400 is:  0.0\n",
      "The cosine similarity between the documents  0 and 401 is:  0.0\n",
      "The cosine similarity between the documents  0 and 402 is:  0.0\n",
      "The cosine similarity between the documents  0 and 403 is:  0.0\n",
      "The cosine similarity between the documents  0 and 404 is:  0.0\n",
      "The cosine similarity between the documents  0 and 405 is:  0.0\n",
      "The cosine similarity between the documents  0 and 406 is:  0.0\n",
      "The cosine similarity between the documents  0 and 407 is:  0.0\n",
      "The cosine similarity between the documents  0 and 408 is:  0.0\n",
      "The cosine similarity between the documents  0 and 409 is:  nan\n",
      "The cosine similarity between the documents  0 and 410 is:  0.0\n",
      "The cosine similarity between the documents  0 and 411 is:  0.0\n",
      "The cosine similarity between the documents  0 and 412 is:  0.0\n",
      "The cosine similarity between the documents  0 and 413 is:  0.0\n",
      "The cosine similarity between the documents  0 and 414 is:  0.0\n",
      "The cosine similarity between the documents  0 and 415 is:  0.0\n",
      "The cosine similarity between the documents  0 and 416 is:  0.0\n",
      "The cosine similarity between the documents  0 and 417 is:  0.0\n",
      "The cosine similarity between the documents  0 and 418 is:  0.0\n",
      "The cosine similarity between the documents  0 and 419 is:  0.0\n",
      "The cosine similarity between the documents  0 and 420 is:  0.0\n",
      "The cosine similarity between the documents  0 and 421 is:  0.0\n",
      "The cosine similarity between the documents  0 and 422 is:  0.0\n",
      "The cosine similarity between the documents  0 and 423 is:  0.0\n",
      "The cosine similarity between the documents  0 and 424 is:  0.0\n",
      "The cosine similarity between the documents  0 and 425 is:  0.0\n",
      "The cosine similarity between the documents  0 and 426 is:  0.0\n",
      "The cosine similarity between the documents  0 and 427 is:  0.0\n",
      "The cosine similarity between the documents  0 and 428 is:  0.0\n",
      "The cosine similarity between the documents  0 and 429 is:  nan\n",
      "The cosine similarity between the documents  0 and 430 is:  0.0\n",
      "The cosine similarity between the documents  0 and 431 is:  0.0\n",
      "The cosine similarity between the documents  0 and 432 is:  0.0\n",
      "The cosine similarity between the documents  0 and 433 is:  0.0\n",
      "The cosine similarity between the documents  0 and 434 is:  0.0\n",
      "The cosine similarity between the documents  0 and 435 is:  0.0\n",
      "The cosine similarity between the documents  0 and 436 is:  0.0\n",
      "The cosine similarity between the documents  0 and 437 is:  0.0\n",
      "The cosine similarity between the documents  0 and 438 is:  0.0\n",
      "The cosine similarity between the documents  0 and 439 is:  0.0\n",
      "The cosine similarity between the documents  0 and 440 is:  0.0\n",
      "The cosine similarity between the documents  0 and 441 is:  0.0\n",
      "The cosine similarity between the documents  0 and 442 is:  0.0\n",
      "The cosine similarity between the documents  0 and 443 is:  0.0\n",
      "The cosine similarity between the documents  0 and 444 is:  0.0\n",
      "The cosine similarity between the documents  0 and 445 is:  nan\n",
      "The cosine similarity between the documents  0 and 446 is:  0.0\n",
      "The cosine similarity between the documents  0 and 447 is:  0.0\n",
      "The cosine similarity between the documents  0 and 448 is:  0.0\n",
      "The cosine similarity between the documents  0 and 449 is:  0.0\n",
      "The cosine similarity between the documents  0 and 450 is:  0.0\n",
      "The cosine similarity between the documents  0 and 451 is:  0.0\n",
      "The cosine similarity between the documents  0 and 452 is:  0.0\n",
      "The cosine similarity between the documents  0 and 453 is:  0.0\n",
      "The cosine similarity between the documents  0 and 454 is:  0.0\n",
      "The cosine similarity between the documents  0 and 455 is:  0.0\n",
      "The cosine similarity between the documents  0 and 456 is:  0.0\n",
      "The cosine similarity between the documents  0 and 457 is:  nan\n",
      "The cosine similarity between the documents  0 and 458 is:  0.0\n",
      "The cosine similarity between the documents  0 and 459 is:  nan\n",
      "The cosine similarity between the documents  0 and 460 is:  0.0\n",
      "The cosine similarity between the documents  0 and 461 is:  0.0\n",
      "The cosine similarity between the documents  0 and 462 is:  0.0\n",
      "The cosine similarity between the documents  0 and 463 is:  nan\n",
      "The cosine similarity between the documents  0 and 464 is:  nan\n",
      "The cosine similarity between the documents  0 and 465 is:  0.0\n",
      "The cosine similarity between the documents  0 and 466 is:  nan\n",
      "The cosine similarity between the documents  0 and 467 is:  0.0\n",
      "The cosine similarity between the documents  0 and 468 is:  0.0\n",
      "The cosine similarity between the documents  0 and 469 is:  0.0\n",
      "The cosine similarity between the documents  0 and 470 is:  nan\n",
      "The cosine similarity between the documents  0 and 471 is:  nan\n",
      "The cosine similarity between the documents  0 and 472 is:  0.0\n",
      "The cosine similarity between the documents  0 and 473 is:  nan\n",
      "The cosine similarity between the documents  0 and 474 is:  0.0\n",
      "The cosine similarity between the documents  0 and 475 is:  0.0\n",
      "The cosine similarity between the documents  0 and 476 is:  0.0\n",
      "The cosine similarity between the documents  0 and 477 is:  0.0\n",
      "The cosine similarity between the documents  0 and 478 is:  0.0\n",
      "The cosine similarity between the documents  0 and 479 is:  0.0\n",
      "The cosine similarity between the documents  0 and 480 is:  0.0\n",
      "The cosine similarity between the documents  0 and 481 is:  0.0\n",
      "The cosine similarity between the documents  0 and 482 is:  0.0\n",
      "The cosine similarity between the documents  0 and 483 is:  0.0\n",
      "The cosine similarity between the documents  0 and 484 is:  0.0\n",
      "The cosine similarity between the documents  0 and 485 is:  0.0\n",
      "The cosine similarity between the documents  0 and 486 is:  0.0\n",
      "The cosine similarity between the documents  0 and 487 is:  0.0\n",
      "The cosine similarity between the documents  0 and 488 is:  nan\n",
      "The cosine similarity between the documents  0 and 489 is:  0.0\n",
      "The cosine similarity between the documents  0 and 490 is:  0.0\n",
      "The cosine similarity between the documents  0 and 491 is:  0.0\n",
      "The cosine similarity between the documents  0 and 492 is:  0.0\n",
      "The cosine similarity between the documents  0 and 493 is:  0.0\n",
      "The cosine similarity between the documents  0 and 494 is:  0.0\n",
      "The cosine similarity between the documents  0 and 495 is:  0.0\n",
      "The cosine similarity between the documents  0 and 496 is:  0.0\n",
      "The cosine similarity between the documents  0 and 497 is:  0.0\n",
      "The cosine similarity between the documents  0 and 498 is:  nan\n",
      "The cosine similarity between the documents  0 and 499 is:  0.0\n",
      "The cosine similarity between the documents  0 and 500 is:  0.0\n",
      "The cosine similarity between the documents  0 and 501 is:  0.0\n",
      "The cosine similarity between the documents  0 and 502 is:  0.0\n",
      "The cosine similarity between the documents  0 and 503 is:  0.0\n",
      "The cosine similarity between the documents  0 and 504 is:  0.0\n",
      "The cosine similarity between the documents  0 and 505 is:  0.0\n",
      "The cosine similarity between the documents  0 and 506 is:  0.0\n",
      "The cosine similarity between the documents  0 and 507 is:  0.0\n",
      "The cosine similarity between the documents  0 and 508 is:  0.0\n",
      "The cosine similarity between the documents  0 and 509 is:  0.0\n",
      "The cosine similarity between the documents  0 and 510 is:  0.0\n",
      "The cosine similarity between the documents  0 and 511 is:  0.0\n",
      "The cosine similarity between the documents  0 and 512 is:  nan\n",
      "The cosine similarity between the documents  0 and 513 is:  0.0\n",
      "The cosine similarity between the documents  0 and 514 is:  nan\n",
      "The cosine similarity between the documents  0 and 515 is:  nan\n",
      "The cosine similarity between the documents  0 and 516 is:  nan\n",
      "The cosine similarity between the documents  0 and 517 is:  0.0\n",
      "The cosine similarity between the documents  0 and 518 is:  0.0\n",
      "The cosine similarity between the documents  0 and 519 is:  0.0\n",
      "The cosine similarity between the documents  0 and 520 is:  0.0\n",
      "The cosine similarity between the documents  0 and 521 is:  0.0\n",
      "The cosine similarity between the documents  0 and 522 is:  0.0\n",
      "The cosine similarity between the documents  0 and 523 is:  0.0\n",
      "The cosine similarity between the documents  0 and 524 is:  0.0\n",
      "The cosine similarity between the documents  0 and 525 is:  0.0\n",
      "The cosine similarity between the documents  0 and 526 is:  0.0\n",
      "The cosine similarity between the documents  0 and 527 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 528 is:  0.0\n",
      "The cosine similarity between the documents  0 and 529 is:  0.0\n",
      "The cosine similarity between the documents  0 and 530 is:  0.0\n",
      "The cosine similarity between the documents  0 and 531 is:  0.0\n",
      "The cosine similarity between the documents  0 and 532 is:  0.0\n",
      "The cosine similarity between the documents  0 and 533 is:  0.0\n",
      "The cosine similarity between the documents  0 and 534 is:  0.0\n",
      "The cosine similarity between the documents  0 and 535 is:  0.0\n",
      "The cosine similarity between the documents  0 and 536 is:  0.0\n",
      "The cosine similarity between the documents  0 and 537 is:  0.0\n",
      "The cosine similarity between the documents  0 and 538 is:  0.0\n",
      "The cosine similarity between the documents  0 and 539 is:  0.0\n",
      "The cosine similarity between the documents  0 and 540 is:  0.0\n",
      "The cosine similarity between the documents  0 and 541 is:  0.0\n",
      "The cosine similarity between the documents  0 and 542 is:  0.0\n",
      "The cosine similarity between the documents  0 and 543 is:  0.0\n",
      "The cosine similarity between the documents  0 and 544 is:  nan\n",
      "The cosine similarity between the documents  0 and 545 is:  0.0\n",
      "The cosine similarity between the documents  0 and 546 is:  0.0\n",
      "The cosine similarity between the documents  0 and 547 is:  0.0\n",
      "The cosine similarity between the documents  0 and 548 is:  0.0\n",
      "The cosine similarity between the documents  0 and 549 is:  0.0\n",
      "The cosine similarity between the documents  0 and 550 is:  0.0\n",
      "The cosine similarity between the documents  0 and 551 is:  nan\n",
      "The cosine similarity between the documents  0 and 552 is:  0.0\n",
      "The cosine similarity between the documents  0 and 553 is:  0.0\n",
      "The cosine similarity between the documents  0 and 554 is:  0.0\n",
      "The cosine similarity between the documents  0 and 555 is:  nan\n",
      "The cosine similarity between the documents  0 and 556 is:  0.0\n",
      "The cosine similarity between the documents  0 and 557 is:  0.0\n",
      "The cosine similarity between the documents  0 and 558 is:  0.0\n",
      "The cosine similarity between the documents  0 and 559 is:  0.0\n",
      "The cosine similarity between the documents  0 and 560 is:  0.0\n",
      "The cosine similarity between the documents  0 and 561 is:  0.0\n",
      "The cosine similarity between the documents  0 and 562 is:  0.0\n",
      "The cosine similarity between the documents  0 and 563 is:  0.0\n",
      "The cosine similarity between the documents  0 and 564 is:  0.0\n",
      "The cosine similarity between the documents  0 and 565 is:  0.0\n",
      "The cosine similarity between the documents  0 and 566 is:  0.0\n",
      "The cosine similarity between the documents  0 and 567 is:  0.0\n",
      "The cosine similarity between the documents  0 and 568 is:  0.0\n",
      "The cosine similarity between the documents  0 and 569 is:  0.0\n",
      "The cosine similarity between the documents  0 and 570 is:  nan\n",
      "The cosine similarity between the documents  0 and 571 is:  0.0\n",
      "The cosine similarity between the documents  0 and 572 is:  0.0\n",
      "The cosine similarity between the documents  0 and 573 is:  0.0\n",
      "The cosine similarity between the documents  0 and 574 is:  0.0\n",
      "The cosine similarity between the documents  0 and 575 is:  0.0\n",
      "The cosine similarity between the documents  0 and 576 is:  0.0\n",
      "The cosine similarity between the documents  0 and 577 is:  0.0\n",
      "The cosine similarity between the documents  0 and 578 is:  0.0\n",
      "The cosine similarity between the documents  0 and 579 is:  0.0\n",
      "The cosine similarity between the documents  0 and 580 is:  nan\n",
      "The cosine similarity between the documents  0 and 581 is:  0.0\n",
      "The cosine similarity between the documents  0 and 582 is:  0.0\n",
      "The cosine similarity between the documents  0 and 583 is:  0.0\n",
      "The cosine similarity between the documents  0 and 584 is:  0.0\n",
      "The cosine similarity between the documents  0 and 585 is:  0.0\n",
      "The cosine similarity between the documents  0 and 586 is:  0.0\n",
      "The cosine similarity between the documents  0 and 587 is:  nan\n",
      "The cosine similarity between the documents  0 and 588 is:  0.0\n",
      "The cosine similarity between the documents  0 and 589 is:  0.0\n",
      "The cosine similarity between the documents  0 and 590 is:  0.0\n",
      "The cosine similarity between the documents  0 and 591 is:  nan\n",
      "The cosine similarity between the documents  0 and 592 is:  0.0\n",
      "The cosine similarity between the documents  0 and 593 is:  0.0\n",
      "The cosine similarity between the documents  0 and 594 is:  nan\n",
      "The cosine similarity between the documents  0 and 595 is:  0.0\n",
      "The cosine similarity between the documents  0 and 596 is:  0.0\n",
      "The cosine similarity between the documents  0 and 597 is:  0.0\n",
      "The cosine similarity between the documents  0 and 598 is:  nan\n",
      "The cosine similarity between the documents  0 and 599 is:  0.0\n",
      "The cosine similarity between the documents  0 and 600 is:  0.0\n",
      "The cosine similarity between the documents  0 and 601 is:  nan\n",
      "The cosine similarity between the documents  0 and 602 is:  0.0\n",
      "The cosine similarity between the documents  0 and 603 is:  nan\n",
      "The cosine similarity between the documents  0 and 604 is:  0.0\n",
      "The cosine similarity between the documents  0 and 605 is:  nan\n",
      "The cosine similarity between the documents  0 and 606 is:  0.0\n",
      "The cosine similarity between the documents  0 and 607 is:  0.0\n",
      "The cosine similarity between the documents  0 and 608 is:  0.0\n",
      "The cosine similarity between the documents  0 and 609 is:  0.0\n",
      "The cosine similarity between the documents  0 and 610 is:  0.0\n",
      "The cosine similarity between the documents  0 and 611 is:  0.0\n",
      "The cosine similarity between the documents  0 and 612 is:  nan\n",
      "The cosine similarity between the documents  0 and 613 is:  0.0\n",
      "The cosine similarity between the documents  0 and 614 is:  0.0\n",
      "The cosine similarity between the documents  0 and 615 is:  0.0\n",
      "The cosine similarity between the documents  0 and 616 is:  0.0\n",
      "The cosine similarity between the documents  0 and 617 is:  0.0\n",
      "The cosine similarity between the documents  0 and 618 is:  0.0\n",
      "The cosine similarity between the documents  0 and 619 is:  0.0\n",
      "The cosine similarity between the documents  0 and 620 is:  0.0\n",
      "The cosine similarity between the documents  0 and 621 is:  0.0\n",
      "The cosine similarity between the documents  0 and 622 is:  nan\n",
      "The cosine similarity between the documents  0 and 623 is:  0.0\n",
      "The cosine similarity between the documents  0 and 624 is:  0.0\n",
      "The cosine similarity between the documents  0 and 625 is:  0.0\n",
      "The cosine similarity between the documents  0 and 626 is:  0.0\n",
      "The cosine similarity between the documents  0 and 627 is:  0.0\n",
      "The cosine similarity between the documents  0 and 628 is:  0.0\n",
      "The cosine similarity between the documents  0 and 629 is:  0.0\n",
      "The cosine similarity between the documents  0 and 630 is:  0.0\n",
      "The cosine similarity between the documents  0 and 631 is:  0.0\n",
      "The cosine similarity between the documents  0 and 632 is:  0.0\n",
      "The cosine similarity between the documents  0 and 633 is:  0.0\n",
      "The cosine similarity between the documents  0 and 634 is:  0.0\n",
      "The cosine similarity between the documents  0 and 635 is:  nan\n",
      "The cosine similarity between the documents  0 and 636 is:  0.0\n",
      "The cosine similarity between the documents  0 and 637 is:  nan\n",
      "The cosine similarity between the documents  0 and 638 is:  0.0\n",
      "The cosine similarity between the documents  0 and 639 is:  0.0\n",
      "The cosine similarity between the documents  0 and 640 is:  0.0\n",
      "The cosine similarity between the documents  0 and 641 is:  0.0\n",
      "The cosine similarity between the documents  0 and 642 is:  0.0\n",
      "The cosine similarity between the documents  0 and 643 is:  0.0\n",
      "The cosine similarity between the documents  0 and 644 is:  0.0\n",
      "The cosine similarity between the documents  0 and 645 is:  0.0\n",
      "The cosine similarity between the documents  0 and 646 is:  0.0\n",
      "The cosine similarity between the documents  0 and 647 is:  nan\n",
      "The cosine similarity between the documents  0 and 648 is:  0.0\n",
      "The cosine similarity between the documents  0 and 649 is:  0.0\n",
      "The cosine similarity between the documents  0 and 650 is:  0.0\n",
      "The cosine similarity between the documents  0 and 651 is:  0.0\n",
      "The cosine similarity between the documents  0 and 652 is:  0.0\n",
      "The cosine similarity between the documents  0 and 653 is:  0.0\n",
      "The cosine similarity between the documents  0 and 654 is:  0.0\n",
      "The cosine similarity between the documents  0 and 655 is:  0.0\n",
      "The cosine similarity between the documents  0 and 656 is:  0.0\n",
      "The cosine similarity between the documents  0 and 657 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 658 is:  0.0\n",
      "The cosine similarity between the documents  0 and 659 is:  0.0\n",
      "The cosine similarity between the documents  0 and 660 is:  nan\n",
      "The cosine similarity between the documents  0 and 661 is:  0.0\n",
      "The cosine similarity between the documents  0 and 662 is:  nan\n",
      "The cosine similarity between the documents  0 and 663 is:  0.0\n",
      "The cosine similarity between the documents  0 and 664 is:  0.0\n",
      "The cosine similarity between the documents  0 and 665 is:  0.0\n",
      "The cosine similarity between the documents  0 and 666 is:  0.0\n",
      "The cosine similarity between the documents  0 and 667 is:  0.0\n",
      "The cosine similarity between the documents  0 and 668 is:  nan\n",
      "The cosine similarity between the documents  0 and 669 is:  0.0\n",
      "The cosine similarity between the documents  0 and 670 is:  0.0\n",
      "The cosine similarity between the documents  0 and 671 is:  0.0\n",
      "The cosine similarity between the documents  0 and 672 is:  0.0\n",
      "The cosine similarity between the documents  0 and 673 is:  0.0\n",
      "The cosine similarity between the documents  0 and 674 is:  0.0\n",
      "The cosine similarity between the documents  0 and 675 is:  nan\n",
      "The cosine similarity between the documents  0 and 676 is:  nan\n",
      "The cosine similarity between the documents  0 and 677 is:  0.0\n",
      "The cosine similarity between the documents  0 and 678 is:  0.0\n",
      "The cosine similarity between the documents  0 and 679 is:  0.0\n",
      "The cosine similarity between the documents  0 and 680 is:  0.0\n",
      "The cosine similarity between the documents  0 and 681 is:  0.0\n",
      "The cosine similarity between the documents  0 and 682 is:  0.0\n",
      "The cosine similarity between the documents  0 and 683 is:  0.0\n",
      "The cosine similarity between the documents  0 and 684 is:  0.0\n",
      "The cosine similarity between the documents  0 and 685 is:  nan\n",
      "The cosine similarity between the documents  0 and 686 is:  nan\n",
      "The cosine similarity between the documents  0 and 687 is:  0.0\n",
      "The cosine similarity between the documents  0 and 688 is:  nan\n",
      "The cosine similarity between the documents  0 and 689 is:  0.0\n",
      "The cosine similarity between the documents  0 and 690 is:  0.0\n",
      "The cosine similarity between the documents  0 and 691 is:  0.0\n",
      "The cosine similarity between the documents  0 and 692 is:  0.0\n",
      "The cosine similarity between the documents  0 and 693 is:  0.0\n",
      "The cosine similarity between the documents  0 and 694 is:  0.0\n",
      "The cosine similarity between the documents  0 and 695 is:  0.0\n",
      "The cosine similarity between the documents  0 and 696 is:  0.0\n",
      "The cosine similarity between the documents  0 and 697 is:  0.0\n",
      "The cosine similarity between the documents  0 and 698 is:  0.0\n",
      "The cosine similarity between the documents  0 and 699 is:  0.0\n",
      "The cosine similarity between the documents  0 and 700 is:  0.0\n",
      "The cosine similarity between the documents  0 and 701 is:  0.0\n",
      "The cosine similarity between the documents  0 and 702 is:  0.0\n",
      "The cosine similarity between the documents  0 and 703 is:  0.0\n",
      "The cosine similarity between the documents  0 and 704 is:  0.0\n",
      "The cosine similarity between the documents  0 and 705 is:  nan\n",
      "The cosine similarity between the documents  0 and 706 is:  0.0\n",
      "The cosine similarity between the documents  0 and 707 is:  0.0\n",
      "The cosine similarity between the documents  0 and 708 is:  0.0\n",
      "The cosine similarity between the documents  0 and 709 is:  0.0\n",
      "The cosine similarity between the documents  0 and 710 is:  0.0\n",
      "The cosine similarity between the documents  0 and 711 is:  0.0\n",
      "The cosine similarity between the documents  0 and 712 is:  nan\n",
      "The cosine similarity between the documents  0 and 713 is:  0.0\n",
      "The cosine similarity between the documents  0 and 714 is:  0.0\n",
      "The cosine similarity between the documents  0 and 715 is:  nan\n",
      "The cosine similarity between the documents  0 and 716 is:  0.0\n",
      "The cosine similarity between the documents  0 and 717 is:  0.0\n",
      "The cosine similarity between the documents  0 and 718 is:  0.0\n",
      "The cosine similarity between the documents  0 and 719 is:  0.0\n",
      "The cosine similarity between the documents  0 and 720 is:  0.0\n",
      "The cosine similarity between the documents  0 and 721 is:  0.0\n",
      "The cosine similarity between the documents  0 and 722 is:  0.0\n",
      "The cosine similarity between the documents  0 and 723 is:  0.0\n",
      "The cosine similarity between the documents  0 and 724 is:  0.0\n",
      "The cosine similarity between the documents  0 and 725 is:  0.0\n",
      "The cosine similarity between the documents  0 and 726 is:  0.0\n",
      "The cosine similarity between the documents  0 and 727 is:  0.0\n",
      "The cosine similarity between the documents  0 and 728 is:  nan\n",
      "The cosine similarity between the documents  0 and 729 is:  nan\n",
      "The cosine similarity between the documents  0 and 730 is:  0.0\n",
      "The cosine similarity between the documents  0 and 731 is:  0.0\n",
      "The cosine similarity between the documents  0 and 732 is:  0.0\n",
      "The cosine similarity between the documents  0 and 733 is:  nan\n",
      "The cosine similarity between the documents  0 and 734 is:  0.0\n",
      "The cosine similarity between the documents  0 and 735 is:  0.0\n",
      "The cosine similarity between the documents  0 and 736 is:  0.0\n",
      "The cosine similarity between the documents  0 and 737 is:  0.0\n",
      "The cosine similarity between the documents  0 and 738 is:  0.0\n",
      "The cosine similarity between the documents  0 and 739 is:  0.0\n",
      "The cosine similarity between the documents  0 and 740 is:  0.0\n",
      "The cosine similarity between the documents  0 and 741 is:  0.0\n",
      "The cosine similarity between the documents  0 and 742 is:  0.0\n",
      "The cosine similarity between the documents  0 and 743 is:  0.0\n",
      "The cosine similarity between the documents  0 and 744 is:  0.0\n",
      "The cosine similarity between the documents  0 and 745 is:  0.0\n",
      "The cosine similarity between the documents  0 and 746 is:  0.0\n",
      "The cosine similarity between the documents  0 and 747 is:  0.0\n",
      "The cosine similarity between the documents  0 and 748 is:  0.0\n",
      "The cosine similarity between the documents  0 and 749 is:  0.0\n",
      "The cosine similarity between the documents  0 and 750 is:  0.0\n",
      "The cosine similarity between the documents  0 and 751 is:  0.0\n",
      "The cosine similarity between the documents  0 and 752 is:  0.0\n",
      "The cosine similarity between the documents  0 and 753 is:  0.0\n",
      "The cosine similarity between the documents  0 and 754 is:  nan\n",
      "The cosine similarity between the documents  0 and 755 is:  0.0\n",
      "The cosine similarity between the documents  0 and 756 is:  0.0\n",
      "The cosine similarity between the documents  0 and 757 is:  nan\n",
      "The cosine similarity between the documents  0 and 758 is:  nan\n",
      "The cosine similarity between the documents  0 and 759 is:  0.0\n",
      "The cosine similarity between the documents  0 and 760 is:  nan\n",
      "The cosine similarity between the documents  0 and 761 is:  0.0\n",
      "The cosine similarity between the documents  0 and 762 is:  0.0\n",
      "The cosine similarity between the documents  0 and 763 is:  0.0\n",
      "The cosine similarity between the documents  0 and 764 is:  nan\n",
      "The cosine similarity between the documents  0 and 765 is:  nan\n",
      "The cosine similarity between the documents  0 and 766 is:  0.0\n",
      "The cosine similarity between the documents  0 and 767 is:  nan\n",
      "The cosine similarity between the documents  0 and 768 is:  0.0\n",
      "The cosine similarity between the documents  0 and 769 is:  0.0\n",
      "The cosine similarity between the documents  0 and 770 is:  0.0\n",
      "The cosine similarity between the documents  0 and 771 is:  0.0\n",
      "The cosine similarity between the documents  0 and 772 is:  nan\n",
      "The cosine similarity between the documents  0 and 773 is:  0.0\n",
      "The cosine similarity between the documents  0 and 774 is:  0.0\n",
      "The cosine similarity between the documents  0 and 775 is:  0.0\n",
      "The cosine similarity between the documents  0 and 776 is:  nan\n",
      "The cosine similarity between the documents  0 and 777 is:  0.0\n",
      "The cosine similarity between the documents  0 and 778 is:  0.0\n",
      "The cosine similarity between the documents  0 and 779 is:  0.0\n",
      "The cosine similarity between the documents  0 and 780 is:  0.0\n",
      "The cosine similarity between the documents  0 and 781 is:  0.0\n",
      "The cosine similarity between the documents  0 and 782 is:  nan\n",
      "The cosine similarity between the documents  0 and 783 is:  0.0\n",
      "The cosine similarity between the documents  0 and 784 is:  0.0\n",
      "The cosine similarity between the documents  0 and 785 is:  0.0\n",
      "The cosine similarity between the documents  0 and 786 is:  0.0\n",
      "The cosine similarity between the documents  0 and 787 is:  0.0\n",
      "The cosine similarity between the documents  0 and 788 is:  0.0\n",
      "The cosine similarity between the documents  0 and 789 is:  0.0\n",
      "The cosine similarity between the documents  0 and 790 is:  0.0\n",
      "The cosine similarity between the documents  0 and 791 is:  0.0\n",
      "The cosine similarity between the documents  0 and 792 is:  0.0\n",
      "The cosine similarity between the documents  0 and 793 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 794 is:  0.0\n",
      "The cosine similarity between the documents  0 and 795 is:  nan\n",
      "The cosine similarity between the documents  0 and 796 is:  0.0\n",
      "The cosine similarity between the documents  0 and 797 is:  0.0\n",
      "The cosine similarity between the documents  0 and 798 is:  nan\n",
      "The cosine similarity between the documents  0 and 799 is:  nan\n",
      "The cosine similarity between the documents  0 and 800 is:  0.0\n",
      "The cosine similarity between the documents  0 and 801 is:  0.0\n",
      "The cosine similarity between the documents  0 and 802 is:  nan\n",
      "The cosine similarity between the documents  0 and 803 is:  0.0\n",
      "The cosine similarity between the documents  0 and 804 is:  nan\n",
      "The cosine similarity between the documents  0 and 805 is:  0.0\n",
      "The cosine similarity between the documents  0 and 806 is:  nan\n",
      "The cosine similarity between the documents  0 and 807 is:  0.0\n",
      "The cosine similarity between the documents  0 and 808 is:  0.0\n",
      "The cosine similarity between the documents  0 and 809 is:  nan\n",
      "The cosine similarity between the documents  0 and 810 is:  0.0\n",
      "The cosine similarity between the documents  0 and 811 is:  nan\n",
      "The cosine similarity between the documents  0 and 812 is:  nan\n",
      "The cosine similarity between the documents  0 and 813 is:  0.0\n",
      "The cosine similarity between the documents  0 and 814 is:  nan\n",
      "The cosine similarity between the documents  0 and 815 is:  0.0\n",
      "The cosine similarity between the documents  0 and 816 is:  0.0\n",
      "The cosine similarity between the documents  0 and 817 is:  nan\n",
      "The cosine similarity between the documents  0 and 818 is:  0.0\n",
      "The cosine similarity between the documents  0 and 819 is:  nan\n",
      "The cosine similarity between the documents  0 and 820 is:  0.0\n",
      "The cosine similarity between the documents  0 and 821 is:  0.0\n",
      "The cosine similarity between the documents  0 and 822 is:  0.0\n",
      "The cosine similarity between the documents  0 and 823 is:  nan\n",
      "The cosine similarity between the documents  0 and 824 is:  0.0\n",
      "The cosine similarity between the documents  0 and 825 is:  nan\n",
      "The cosine similarity between the documents  0 and 826 is:  0.0\n",
      "The cosine similarity between the documents  0 and 827 is:  0.0\n",
      "The cosine similarity between the documents  0 and 828 is:  0.0\n",
      "The cosine similarity between the documents  0 and 829 is:  0.0\n",
      "The cosine similarity between the documents  0 and 830 is:  0.0\n",
      "The cosine similarity between the documents  0 and 831 is:  0.0\n",
      "The cosine similarity between the documents  0 and 832 is:  0.0\n",
      "The cosine similarity between the documents  0 and 833 is:  0.0\n",
      "The cosine similarity between the documents  0 and 834 is:  nan\n",
      "The cosine similarity between the documents  0 and 835 is:  0.0\n",
      "The cosine similarity between the documents  0 and 836 is:  0.0\n",
      "The cosine similarity between the documents  0 and 837 is:  nan\n",
      "The cosine similarity between the documents  0 and 838 is:  0.0\n",
      "The cosine similarity between the documents  0 and 839 is:  0.0\n",
      "The cosine similarity between the documents  0 and 840 is:  0.0\n",
      "The cosine similarity between the documents  0 and 841 is:  0.0\n",
      "The cosine similarity between the documents  0 and 842 is:  0.0\n",
      "The cosine similarity between the documents  0 and 843 is:  0.0\n",
      "The cosine similarity between the documents  0 and 844 is:  0.0\n",
      "The cosine similarity between the documents  0 and 845 is:  0.0\n",
      "The cosine similarity between the documents  0 and 846 is:  0.0\n",
      "The cosine similarity between the documents  0 and 847 is:  0.0\n",
      "The cosine similarity between the documents  0 and 848 is:  0.0\n",
      "The cosine similarity between the documents  0 and 849 is:  0.0\n",
      "The cosine similarity between the documents  0 and 850 is:  0.0\n",
      "The cosine similarity between the documents  0 and 851 is:  nan\n",
      "The cosine similarity between the documents  0 and 852 is:  0.0\n",
      "The cosine similarity between the documents  0 and 853 is:  0.0\n",
      "The cosine similarity between the documents  0 and 854 is:  0.0\n",
      "The cosine similarity between the documents  0 and 855 is:  0.0\n",
      "The cosine similarity between the documents  0 and 856 is:  nan\n",
      "The cosine similarity between the documents  0 and 857 is:  0.0\n",
      "The cosine similarity between the documents  0 and 858 is:  0.0\n",
      "The cosine similarity between the documents  0 and 859 is:  0.0\n",
      "The cosine similarity between the documents  0 and 860 is:  nan\n",
      "The cosine similarity between the documents  0 and 861 is:  nan\n",
      "The cosine similarity between the documents  0 and 862 is:  0.0\n",
      "The cosine similarity between the documents  0 and 863 is:  nan\n",
      "The cosine similarity between the documents  0 and 864 is:  0.0\n",
      "The cosine similarity between the documents  0 and 865 is:  0.0\n",
      "The cosine similarity between the documents  0 and 866 is:  0.0\n",
      "The cosine similarity between the documents  0 and 867 is:  nan\n",
      "The cosine similarity between the documents  0 and 868 is:  nan\n",
      "The cosine similarity between the documents  0 and 869 is:  0.0\n",
      "The cosine similarity between the documents  0 and 870 is:  nan\n",
      "The cosine similarity between the documents  0 and 871 is:  0.0\n",
      "The cosine similarity between the documents  0 and 872 is:  0.0\n",
      "The cosine similarity between the documents  0 and 873 is:  0.0\n",
      "The cosine similarity between the documents  0 and 874 is:  0.0\n",
      "The cosine similarity between the documents  0 and 875 is:  0.0\n",
      "The cosine similarity between the documents  0 and 876 is:  0.0\n",
      "The cosine similarity between the documents  0 and 877 is:  0.0\n",
      "The cosine similarity between the documents  0 and 878 is:  0.0\n",
      "The cosine similarity between the documents  0 and 879 is:  0.0\n",
      "The cosine similarity between the documents  0 and 880 is:  0.0\n",
      "The cosine similarity between the documents  0 and 881 is:  0.0\n",
      "The cosine similarity between the documents  0 and 882 is:  nan\n",
      "The cosine similarity between the documents  0 and 883 is:  0.0\n",
      "The cosine similarity between the documents  0 and 884 is:  0.0\n",
      "The cosine similarity between the documents  0 and 885 is:  nan\n",
      "The cosine similarity between the documents  0 and 886 is:  nan\n",
      "The cosine similarity between the documents  0 and 887 is:  nan\n",
      "The cosine similarity between the documents  0 and 888 is:  0.0\n",
      "The cosine similarity between the documents  0 and 889 is:  0.0\n",
      "The cosine similarity between the documents  0 and 890 is:  0.0\n",
      "The cosine similarity between the documents  0 and 891 is:  nan\n",
      "The cosine similarity between the documents  0 and 892 is:  nan\n",
      "The cosine similarity between the documents  0 and 893 is:  0.0\n",
      "The cosine similarity between the documents  0 and 894 is:  nan\n",
      "The cosine similarity between the documents  0 and 895 is:  0.0\n",
      "The cosine similarity between the documents  0 and 896 is:  0.0\n",
      "The cosine similarity between the documents  0 and 897 is:  0.0\n",
      "The cosine similarity between the documents  0 and 898 is:  nan\n",
      "The cosine similarity between the documents  0 and 899 is:  0.0\n",
      "The cosine similarity between the documents  0 and 900 is:  0.0\n",
      "The cosine similarity between the documents  0 and 901 is:  0.0\n",
      "The cosine similarity between the documents  0 and 902 is:  0.0\n",
      "The cosine similarity between the documents  0 and 903 is:  nan\n",
      "The cosine similarity between the documents  0 and 904 is:  0.0\n",
      "The cosine similarity between the documents  0 and 905 is:  0.0\n",
      "The cosine similarity between the documents  0 and 906 is:  0.0\n",
      "The cosine similarity between the documents  0 and 907 is:  0.0\n",
      "The cosine similarity between the documents  0 and 908 is:  nan\n",
      "The cosine similarity between the documents  0 and 909 is:  0.0\n",
      "The cosine similarity between the documents  0 and 910 is:  0.0\n",
      "The cosine similarity between the documents  0 and 911 is:  0.0\n",
      "The cosine similarity between the documents  0 and 912 is:  nan\n",
      "The cosine similarity between the documents  0 and 913 is:  nan\n",
      "The cosine similarity between the documents  0 and 914 is:  0.0\n",
      "The cosine similarity between the documents  0 and 915 is:  nan\n",
      "The cosine similarity between the documents  0 and 916 is:  0.0\n",
      "The cosine similarity between the documents  0 and 917 is:  0.0\n",
      "The cosine similarity between the documents  0 and 918 is:  0.0\n",
      "The cosine similarity between the documents  0 and 919 is:  0.0\n",
      "The cosine similarity between the documents  0 and 920 is:  0.0\n",
      "The cosine similarity between the documents  0 and 921 is:  nan\n",
      "The cosine similarity between the documents  0 and 922 is:  0.0\n",
      "The cosine similarity between the documents  0 and 923 is:  0.0\n",
      "The cosine similarity between the documents  0 and 924 is:  0.0\n",
      "The cosine similarity between the documents  0 and 925 is:  nan\n",
      "The cosine similarity between the documents  0 and 926 is:  nan\n",
      "The cosine similarity between the documents  0 and 927 is:  0.0\n",
      "The cosine similarity between the documents  0 and 928 is:  nan\n",
      "The cosine similarity between the documents  0 and 929 is:  nan\n",
      "The cosine similarity between the documents  0 and 930 is:  0.0\n",
      "The cosine similarity between the documents  0 and 931 is:  0.0\n",
      "The cosine similarity between the documents  0 and 932 is:  0.0\n",
      "The cosine similarity between the documents  0 and 933 is:  nan\n",
      "The cosine similarity between the documents  0 and 934 is:  nan\n",
      "The cosine similarity between the documents  0 and 935 is:  0.0\n",
      "The cosine similarity between the documents  0 and 936 is:  0.0\n",
      "The cosine similarity between the documents  0 and 937 is:  0.0\n",
      "The cosine similarity between the documents  0 and 938 is:  nan\n",
      "The cosine similarity between the documents  0 and 939 is:  nan\n",
      "The cosine similarity between the documents  0 and 940 is:  0.0\n",
      "The cosine similarity between the documents  0 and 941 is:  nan\n",
      "The cosine similarity between the documents  0 and 942 is:  0.0\n",
      "The cosine similarity between the documents  0 and 943 is:  0.0\n",
      "The cosine similarity between the documents  0 and 944 is:  0.0\n",
      "The cosine similarity between the documents  0 and 945 is:  0.0\n",
      "The cosine similarity between the documents  0 and 946 is:  0.0\n",
      "The cosine similarity between the documents  0 and 947 is:  0.0\n",
      "The cosine similarity between the documents  0 and 948 is:  0.0\n",
      "The cosine similarity between the documents  0 and 949 is:  0.0\n",
      "The cosine similarity between the documents  0 and 950 is:  0.0\n",
      "The cosine similarity between the documents  0 and 951 is:  0.0\n",
      "The cosine similarity between the documents  0 and 952 is:  0.0\n",
      "The cosine similarity between the documents  0 and 953 is:  0.0\n",
      "The cosine similarity between the documents  0 and 954 is:  0.0\n",
      "The cosine similarity between the documents  0 and 955 is:  0.0\n",
      "The cosine similarity between the documents  0 and 956 is:  0.0\n",
      "The cosine similarity between the documents  0 and 957 is:  0.0\n",
      "The cosine similarity between the documents  0 and 958 is:  0.0\n",
      "The cosine similarity between the documents  0 and 959 is:  0.0\n",
      "The cosine similarity between the documents  0 and 960 is:  0.0\n",
      "The cosine similarity between the documents  0 and 961 is:  0.0\n",
      "The cosine similarity between the documents  0 and 962 is:  0.0\n",
      "The cosine similarity between the documents  0 and 963 is:  nan\n",
      "The cosine similarity between the documents  0 and 964 is:  0.0\n",
      "The cosine similarity between the documents  0 and 965 is:  0.0\n",
      "The cosine similarity between the documents  0 and 966 is:  0.0\n",
      "The cosine similarity between the documents  0 and 967 is:  nan\n",
      "The cosine similarity between the documents  0 and 968 is:  nan\n",
      "The cosine similarity between the documents  0 and 969 is:  0.0\n",
      "The cosine similarity between the documents  0 and 970 is:  nan\n",
      "The cosine similarity between the documents  0 and 971 is:  nan\n",
      "The cosine similarity between the documents  0 and 972 is:  0.0\n",
      "The cosine similarity between the documents  0 and 973 is:  0.0\n",
      "The cosine similarity between the documents  0 and 974 is:  0.0\n",
      "The cosine similarity between the documents  0 and 975 is:  0.0\n",
      "The cosine similarity between the documents  0 and 976 is:  0.0\n",
      "The cosine similarity between the documents  0 and 977 is:  0.0\n",
      "The cosine similarity between the documents  0 and 978 is:  0.0\n",
      "The cosine similarity between the documents  0 and 979 is:  0.0\n",
      "The cosine similarity between the documents  0 and 980 is:  0.0\n",
      "The cosine similarity between the documents  0 and 981 is:  0.0\n",
      "The cosine similarity between the documents  0 and 982 is:  0.0\n",
      "The cosine similarity between the documents  0 and 983 is:  nan\n",
      "The cosine similarity between the documents  0 and 984 is:  0.0\n",
      "The cosine similarity between the documents  0 and 985 is:  0.0\n",
      "The cosine similarity between the documents  0 and 986 is:  0.0\n",
      "The cosine similarity between the documents  0 and 987 is:  nan\n",
      "The cosine similarity between the documents  0 and 988 is:  0.0\n",
      "The cosine similarity between the documents  0 and 989 is:  0.0\n",
      "The cosine similarity between the documents  0 and 990 is:  0.0\n",
      "The cosine similarity between the documents  0 and 991 is:  nan\n",
      "The cosine similarity between the documents  0 and 992 is:  0.0\n",
      "The cosine similarity between the documents  0 and 993 is:  nan\n",
      "The cosine similarity between the documents  0 and 994 is:  0.0\n",
      "The cosine similarity between the documents  0 and 995 is:  0.0\n",
      "The cosine similarity between the documents  0 and 996 is:  0.0\n",
      "The cosine similarity between the documents  0 and 997 is:  0.0\n",
      "The cosine similarity between the documents  0 and 998 is:  0.0\n",
      "The cosine similarity between the documents  0 and 999 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1000 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1001 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1002 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1003 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1004 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1005 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1006 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1007 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1008 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1009 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1010 is:  nan\n",
      "The cosine similarity between the documents  0 and 1011 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1012 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1013 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1014 is:  nan\n",
      "The cosine similarity between the documents  0 and 1015 is:  nan\n",
      "The cosine similarity between the documents  0 and 1016 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1017 is:  nan\n",
      "The cosine similarity between the documents  0 and 1018 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1019 is:  nan\n",
      "The cosine similarity between the documents  0 and 1020 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1021 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1022 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1023 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1024 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1025 is:  nan\n",
      "The cosine similarity between the documents  0 and 1026 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1027 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1028 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1029 is:  nan\n",
      "The cosine similarity between the documents  0 and 1030 is:  nan\n",
      "The cosine similarity between the documents  0 and 1031 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1032 is:  nan\n",
      "The cosine similarity between the documents  0 and 1033 is:  nan\n",
      "The cosine similarity between the documents  0 and 1034 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1035 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1036 is:  nan\n",
      "The cosine similarity between the documents  0 and 1037 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1038 is:  nan\n",
      "The cosine similarity between the documents  0 and 1039 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1040 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1041 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1042 is:  nan\n",
      "The cosine similarity between the documents  0 and 1043 is:  nan\n",
      "The cosine similarity between the documents  0 and 1044 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1045 is:  nan\n",
      "The cosine similarity between the documents  0 and 1046 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1047 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1048 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1049 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1050 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1051 is:  nan\n",
      "The cosine similarity between the documents  0 and 1052 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1053 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1054 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1055 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1056 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1057 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1058 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1059 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1060 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1061 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1062 is:  nan\n",
      "The cosine similarity between the documents  0 and 1063 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1064 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1065 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1066 is:  nan\n",
      "The cosine similarity between the documents  0 and 1067 is:  nan\n",
      "The cosine similarity between the documents  0 and 1068 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1069 is:  nan\n",
      "The cosine similarity between the documents  0 and 1070 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1071 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1072 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1073 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1074 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1075 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1076 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1077 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1078 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1079 is:  nan\n",
      "The cosine similarity between the documents  0 and 1080 is:  nan\n",
      "The cosine similarity between the documents  0 and 1081 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1082 is:  nan\n",
      "The cosine similarity between the documents  0 and 1083 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1084 is:  nan\n",
      "The cosine similarity between the documents  0 and 1085 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1086 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1087 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1088 is:  nan\n",
      "The cosine similarity between the documents  0 and 1089 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1090 is:  nan\n",
      "The cosine similarity between the documents  0 and 1091 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1092 is:  nan\n",
      "The cosine similarity between the documents  0 and 1093 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1094 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1095 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1096 is:  nan\n",
      "The cosine similarity between the documents  0 and 1097 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1098 is:  nan\n",
      "The cosine similarity between the documents  0 and 1099 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1100 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1101 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1102 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1103 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1104 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1105 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1106 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1107 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1108 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1109 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1110 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1111 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1112 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1113 is:  nan\n",
      "The cosine similarity between the documents  0 and 1114 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1115 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1116 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1117 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1118 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1119 is:  nan\n",
      "The cosine similarity between the documents  0 and 1120 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1121 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1122 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1123 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1124 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1125 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1126 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1127 is:  nan\n",
      "The cosine similarity between the documents  0 and 1128 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1129 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1130 is:  nan\n",
      "The cosine similarity between the documents  0 and 1131 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1132 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1133 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1134 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1135 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1136 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1137 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1138 is:  nan\n",
      "The cosine similarity between the documents  0 and 1139 is:  nan\n",
      "The cosine similarity between the documents  0 and 1140 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1141 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1142 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1143 is:  nan\n",
      "The cosine similarity between the documents  0 and 1144 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1145 is:  nan\n",
      "The cosine similarity between the documents  0 and 1146 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1147 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1148 is:  nan\n",
      "The cosine similarity between the documents  0 and 1149 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1150 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1151 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1152 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1153 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1154 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1155 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1156 is:  nan\n",
      "The cosine similarity between the documents  0 and 1157 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1158 is:  nan\n",
      "The cosine similarity between the documents  0 and 1159 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1160 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1161 is:  nan\n",
      "The cosine similarity between the documents  0 and 1162 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1163 is:  nan\n",
      "The cosine similarity between the documents  0 and 1164 is:  nan\n",
      "The cosine similarity between the documents  0 and 1165 is:  nan\n",
      "The cosine similarity between the documents  0 and 1166 is:  nan\n",
      "The cosine similarity between the documents  0 and 1167 is:  nan\n",
      "The cosine similarity between the documents  0 and 1168 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1169 is:  nan\n",
      "The cosine similarity between the documents  0 and 1170 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1171 is:  nan\n",
      "The cosine similarity between the documents  0 and 1172 is:  nan\n",
      "The cosine similarity between the documents  0 and 1173 is:  nan\n",
      "The cosine similarity between the documents  0 and 1174 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1175 is:  nan\n",
      "The cosine similarity between the documents  0 and 1176 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1177 is:  nan\n",
      "The cosine similarity between the documents  0 and 1178 is:  nan\n",
      "The cosine similarity between the documents  0 and 1179 is:  nan\n",
      "The cosine similarity between the documents  0 and 1180 is:  nan\n",
      "The cosine similarity between the documents  0 and 1181 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1182 is:  nan\n",
      "The cosine similarity between the documents  0 and 1183 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1184 is:  nan\n",
      "The cosine similarity between the documents  0 and 1185 is:  nan\n",
      "The cosine similarity between the documents  0 and 1186 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1187 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1188 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1189 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1190 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1191 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1192 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1193 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1194 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1195 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1196 is:  1.0\n",
      "The cosine similarity between the documents  0 and 1197 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1198 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1199 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1200 is:  nan\n",
      "The cosine similarity between the documents  0 and 1201 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1202 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1203 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1204 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1205 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1206 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1207 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1208 is:  nan\n",
      "The cosine similarity between the documents  0 and 1209 is:  nan\n",
      "The cosine similarity between the documents  0 and 1210 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1211 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1212 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1213 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1214 is:  1.0\n",
      "The cosine similarity between the documents  0 and 1215 is:  nan\n",
      "The cosine similarity between the documents  0 and 1216 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1217 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1218 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1219 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1220 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1221 is:  nan\n",
      "The cosine similarity between the documents  0 and 1222 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1223 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1224 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1225 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1226 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1227 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1228 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1229 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1230 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1231 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1232 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1233 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1234 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1235 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1236 is:  nan\n",
      "The cosine similarity between the documents  0 and 1237 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1238 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1239 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1240 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1241 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1242 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1243 is:  nan\n",
      "The cosine similarity between the documents  0 and 1244 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1245 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1246 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1247 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1248 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1249 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1250 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1251 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1252 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1253 is:  nan\n",
      "The cosine similarity between the documents  0 and 1254 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1255 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1256 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1257 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1258 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1259 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1260 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1261 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1262 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1263 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1264 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1265 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1266 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1267 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1268 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1269 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1270 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1271 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1272 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1273 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1274 is:  nan\n",
      "The cosine similarity between the documents  0 and 1275 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1276 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1277 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1278 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1279 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1280 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1281 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1282 is:  nan\n",
      "The cosine similarity between the documents  0 and 1283 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1284 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1285 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1286 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1287 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1288 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1289 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1290 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1291 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1292 is:  nan\n",
      "The cosine similarity between the documents  0 and 1293 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1294 is:  nan\n",
      "The cosine similarity between the documents  0 and 1295 is:  nan\n",
      "The cosine similarity between the documents  0 and 1296 is:  nan\n",
      "The cosine similarity between the documents  0 and 1297 is:  nan\n",
      "The cosine similarity between the documents  0 and 1298 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1299 is:  nan\n",
      "The cosine similarity between the documents  0 and 1300 is:  nan\n",
      "The cosine similarity between the documents  0 and 1301 is:  nan\n",
      "The cosine similarity between the documents  0 and 1302 is:  nan\n",
      "The cosine similarity between the documents  0 and 1303 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1304 is:  nan\n",
      "The cosine similarity between the documents  0 and 1305 is:  nan\n",
      "The cosine similarity between the documents  0 and 1306 is:  nan\n",
      "The cosine similarity between the documents  0 and 1307 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1308 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1309 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1310 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1311 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1312 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1313 is:  nan\n",
      "The cosine similarity between the documents  0 and 1314 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1315 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1316 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1317 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1318 is:  nan\n",
      "The cosine similarity between the documents  0 and 1319 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1320 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1321 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1322 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1323 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1324 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1325 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1326 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1327 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1328 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1329 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1330 is:  nan\n",
      "The cosine similarity between the documents  0 and 1331 is:  nan\n",
      "The cosine similarity between the documents  0 and 1332 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1333 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1334 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1335 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1336 is:  nan\n",
      "The cosine similarity between the documents  0 and 1337 is:  nan\n",
      "The cosine similarity between the documents  0 and 1338 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1339 is:  nan\n",
      "The cosine similarity between the documents  0 and 1340 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1341 is:  nan\n",
      "The cosine similarity between the documents  0 and 1342 is:  nan\n",
      "The cosine similarity between the documents  0 and 1343 is:  nan\n",
      "The cosine similarity between the documents  0 and 1344 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1345 is:  nan\n",
      "The cosine similarity between the documents  0 and 1346 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1347 is:  nan\n",
      "The cosine similarity between the documents  0 and 1348 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1349 is:  nan\n",
      "The cosine similarity between the documents  0 and 1350 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1351 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1352 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1353 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1354 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1355 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1356 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1357 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1358 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1359 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1360 is:  nan\n",
      "The cosine similarity between the documents  0 and 1361 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1362 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1363 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1364 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1365 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1366 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1367 is:  nan\n",
      "The cosine similarity between the documents  0 and 1368 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1369 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1370 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1371 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1372 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1373 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1374 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1375 is:  nan\n",
      "The cosine similarity between the documents  0 and 1376 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1377 is:  nan\n",
      "The cosine similarity between the documents  0 and 1378 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1379 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1380 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1381 is:  nan\n",
      "The cosine similarity between the documents  0 and 1382 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1383 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1384 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1385 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1386 is:  nan\n",
      "The cosine similarity between the documents  0 and 1387 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1388 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1389 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1390 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1391 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1392 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1393 is:  1.0\n",
      "The cosine similarity between the documents  0 and 1394 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1395 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1396 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1397 is:  nan\n",
      "The cosine similarity between the documents  0 and 1398 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1399 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1400 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1401 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1402 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1403 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1404 is:  nan\n",
      "The cosine similarity between the documents  0 and 1405 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1406 is:  nan\n",
      "The cosine similarity between the documents  0 and 1407 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1408 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1409 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1410 is:  nan\n",
      "The cosine similarity between the documents  0 and 1411 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1412 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1413 is:  nan\n",
      "The cosine similarity between the documents  0 and 1414 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1415 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1416 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1417 is:  nan\n",
      "The cosine similarity between the documents  0 and 1418 is:  nan\n",
      "The cosine similarity between the documents  0 and 1419 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1420 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1421 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1422 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1423 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1424 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1425 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1426 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1427 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1428 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1429 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1430 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1431 is:  nan\n",
      "The cosine similarity between the documents  0 and 1432 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1433 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1434 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1435 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1436 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1437 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1438 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1439 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1440 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1441 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1442 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1443 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1444 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1445 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1446 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1447 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1448 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1449 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1450 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1451 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1452 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1453 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1454 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1455 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1456 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1457 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1458 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1459 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1460 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1461 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1462 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1463 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1464 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1465 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1466 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1467 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1468 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1469 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1470 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1471 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1472 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1473 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1474 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1475 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1476 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1477 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1478 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1479 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1480 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1481 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1482 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1483 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1484 is:  nan\n",
      "The cosine similarity between the documents  0 and 1485 is:  nan\n",
      "The cosine similarity between the documents  0 and 1486 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1487 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1488 is:  nan\n",
      "The cosine similarity between the documents  0 and 1489 is:  nan\n",
      "The cosine similarity between the documents  0 and 1490 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1491 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1492 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1493 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1494 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1495 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1496 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1497 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1498 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1499 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1500 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1501 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1502 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1503 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1504 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1505 is:  nan\n",
      "The cosine similarity between the documents  0 and 1506 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1507 is:  nan\n",
      "The cosine similarity between the documents  0 and 1508 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1509 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1510 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1511 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1512 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1513 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1514 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1515 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1516 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1517 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1518 is:  nan\n",
      "The cosine similarity between the documents  0 and 1519 is:  nan\n",
      "The cosine similarity between the documents  0 and 1520 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1521 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1522 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1523 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1524 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1525 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1526 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1527 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1528 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1529 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1530 is:  nan\n",
      "The cosine similarity between the documents  0 and 1531 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1532 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1533 is:  nan\n",
      "The cosine similarity between the documents  0 and 1534 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1535 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1536 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1537 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1538 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1539 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1540 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1541 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1542 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1543 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1544 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1545 is:  nan\n",
      "The cosine similarity between the documents  0 and 1546 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1547 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1548 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1549 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1550 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1551 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1552 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1553 is:  nan\n",
      "The cosine similarity between the documents  0 and 1554 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1555 is:  nan\n",
      "The cosine similarity between the documents  0 and 1556 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1557 is:  nan\n",
      "The cosine similarity between the documents  0 and 1558 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1559 is:  nan\n",
      "The cosine similarity between the documents  0 and 1560 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1561 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1562 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1563 is:  nan\n",
      "The cosine similarity between the documents  0 and 1564 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1565 is:  nan\n",
      "The cosine similarity between the documents  0 and 1566 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1567 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1568 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1569 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1570 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1571 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1572 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1573 is:  nan\n",
      "The cosine similarity between the documents  0 and 1574 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1575 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1576 is:  nan\n",
      "The cosine similarity between the documents  0 and 1577 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1578 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1579 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1580 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1581 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1582 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1583 is:  nan\n",
      "The cosine similarity between the documents  0 and 1584 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1585 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1586 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1587 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1588 is:  nan\n",
      "The cosine similarity between the documents  0 and 1589 is:  nan\n",
      "The cosine similarity between the documents  0 and 1590 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1591 is:  nan\n",
      "The cosine similarity between the documents  0 and 1592 is:  nan\n",
      "The cosine similarity between the documents  0 and 1593 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1594 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1595 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1596 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1597 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1598 is:  nan\n",
      "The cosine similarity between the documents  0 and 1599 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1600 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1601 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1602 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1603 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1604 is:  nan\n",
      "The cosine similarity between the documents  0 and 1605 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1606 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1607 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1608 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1609 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1610 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1611 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1612 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1613 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1614 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1615 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1616 is:  nan\n",
      "The cosine similarity between the documents  0 and 1617 is:  nan\n",
      "The cosine similarity between the documents  0 and 1618 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1619 is:  nan\n",
      "The cosine similarity between the documents  0 and 1620 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1621 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1622 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1623 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1624 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1625 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1626 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1627 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1628 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1629 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1630 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1631 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1632 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1633 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1634 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1635 is:  nan\n",
      "The cosine similarity between the documents  0 and 1636 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1637 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1638 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1639 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1640 is:  nan\n",
      "The cosine similarity between the documents  0 and 1641 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1642 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1643 is:  nan\n",
      "The cosine similarity between the documents  0 and 1644 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1645 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1646 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1647 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1648 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1649 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1650 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1651 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1652 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1653 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1654 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1655 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1656 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1657 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1658 is:  nan\n",
      "The cosine similarity between the documents  0 and 1659 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1660 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1661 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1662 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1663 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1664 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1665 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1666 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1667 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1668 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1669 is:  nan\n",
      "The cosine similarity between the documents  0 and 1670 is:  nan\n",
      "The cosine similarity between the documents  0 and 1671 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1672 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1673 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1674 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1675 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1676 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1677 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1678 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1679 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1680 is:  nan\n",
      "The cosine similarity between the documents  0 and 1681 is:  nan\n",
      "The cosine similarity between the documents  0 and 1682 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1683 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1684 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1685 is:  nan\n",
      "The cosine similarity between the documents  0 and 1686 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1687 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1688 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1689 is:  nan\n",
      "The cosine similarity between the documents  0 and 1690 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1691 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1692 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1693 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1694 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1695 is:  nan\n",
      "The cosine similarity between the documents  0 and 1696 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1697 is:  nan\n",
      "The cosine similarity between the documents  0 and 1698 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1699 is:  nan\n",
      "The cosine similarity between the documents  0 and 1700 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1701 is:  nan\n",
      "The cosine similarity between the documents  0 and 1702 is:  nan\n",
      "The cosine similarity between the documents  0 and 1703 is:  nan\n",
      "The cosine similarity between the documents  0 and 1704 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1705 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1706 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1707 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1708 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1709 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1710 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1711 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1712 is:  nan\n",
      "The cosine similarity between the documents  0 and 1713 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1714 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1715 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1716 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1717 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1718 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1719 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1720 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1721 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1722 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1723 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1724 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1725 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1726 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1727 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1728 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1729 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1730 is:  nan\n",
      "The cosine similarity between the documents  0 and 1731 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1732 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1733 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1734 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1735 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1736 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1737 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1738 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1739 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1740 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1741 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1742 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1743 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1744 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1745 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1746 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1747 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1748 is:  nan\n",
      "The cosine similarity between the documents  0 and 1749 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1750 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1751 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1752 is:  nan\n",
      "The cosine similarity between the documents  0 and 1753 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1754 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1755 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1756 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1757 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1758 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1759 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1760 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1761 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1762 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1763 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1764 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1765 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1766 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1767 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1768 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1769 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1770 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1771 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1772 is:  nan\n",
      "The cosine similarity between the documents  0 and 1773 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1774 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1775 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1776 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1777 is:  nan\n",
      "The cosine similarity between the documents  0 and 1778 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1779 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1780 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1781 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1782 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1783 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1784 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1785 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1786 is:  nan\n",
      "The cosine similarity between the documents  0 and 1787 is:  nan\n",
      "The cosine similarity between the documents  0 and 1788 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1789 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1790 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1791 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1792 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1793 is:  nan\n",
      "The cosine similarity between the documents  0 and 1794 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1795 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1796 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1797 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1798 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1799 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1800 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1801 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1802 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1803 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1804 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1805 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1806 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1807 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1808 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1809 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1810 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1811 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1812 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1813 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1814 is:  nan\n",
      "The cosine similarity between the documents  0 and 1815 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1816 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1817 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1818 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1819 is:  nan\n",
      "The cosine similarity between the documents  0 and 1820 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1821 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1822 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1823 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1824 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1825 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1826 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1827 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1828 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1829 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1830 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1831 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1832 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1833 is:  nan\n",
      "The cosine similarity between the documents  0 and 1834 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1835 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1836 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1837 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1838 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1839 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1840 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1841 is:  1.0\n",
      "The cosine similarity between the documents  0 and 1842 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1843 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1844 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1845 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1846 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1847 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1848 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1849 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1850 is:  nan\n",
      "The cosine similarity between the documents  0 and 1851 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1852 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1853 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1854 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1855 is:  nan\n",
      "The cosine similarity between the documents  0 and 1856 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1857 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1858 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1859 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1860 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1861 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1862 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1863 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1864 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1865 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1866 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1867 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1868 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1869 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1870 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1871 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1872 is:  nan\n",
      "The cosine similarity between the documents  0 and 1873 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1874 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1875 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1876 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1877 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1878 is:  nan\n",
      "The cosine similarity between the documents  0 and 1879 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1880 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1881 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1882 is:  nan\n",
      "The cosine similarity between the documents  0 and 1883 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1884 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1885 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1886 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1887 is:  nan\n",
      "The cosine similarity between the documents  0 and 1888 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1889 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1890 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1891 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1892 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1893 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1894 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1895 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1896 is:  1.0\n",
      "The cosine similarity between the documents  0 and 1897 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1898 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1899 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1900 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1901 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1902 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1903 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1904 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1905 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1906 is:  nan\n",
      "The cosine similarity between the documents  0 and 1907 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1908 is:  nan\n",
      "The cosine similarity between the documents  0 and 1909 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1910 is:  nan\n",
      "The cosine similarity between the documents  0 and 1911 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1912 is:  nan\n",
      "The cosine similarity between the documents  0 and 1913 is:  nan\n",
      "The cosine similarity between the documents  0 and 1914 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1915 is:  nan\n",
      "The cosine similarity between the documents  0 and 1916 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1917 is:  nan\n",
      "The cosine similarity between the documents  0 and 1918 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1919 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1920 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1921 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1922 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1923 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1924 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1925 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1926 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1927 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1928 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1929 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1930 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1931 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1932 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1933 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1934 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1935 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1936 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1937 is:  nan\n",
      "The cosine similarity between the documents  0 and 1938 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1939 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1940 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1941 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1942 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1943 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1944 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1945 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1946 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1947 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1948 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1949 is:  nan\n",
      "The cosine similarity between the documents  0 and 1950 is:  nan\n",
      "The cosine similarity between the documents  0 and 1951 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1952 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1953 is:  nan\n",
      "The cosine similarity between the documents  0 and 1954 is:  nan\n",
      "The cosine similarity between the documents  0 and 1955 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1956 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1957 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1958 is:  nan\n",
      "The cosine similarity between the documents  0 and 1959 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1960 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1961 is:  nan\n",
      "The cosine similarity between the documents  0 and 1962 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1963 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1964 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1965 is:  nan\n",
      "The cosine similarity between the documents  0 and 1966 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1967 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1968 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1969 is:  1.0\n",
      "The cosine similarity between the documents  0 and 1970 is:  nan\n",
      "The cosine similarity between the documents  0 and 1971 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1972 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1973 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1974 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1975 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1976 is:  nan\n",
      "The cosine similarity between the documents  0 and 1977 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1978 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1979 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 1980 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1981 is:  nan\n",
      "The cosine similarity between the documents  0 and 1982 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1983 is:  nan\n",
      "The cosine similarity between the documents  0 and 1984 is:  nan\n",
      "The cosine similarity between the documents  0 and 1985 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1986 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1987 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1988 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1989 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1990 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1991 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1992 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1993 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1994 is:  nan\n",
      "The cosine similarity between the documents  0 and 1995 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1996 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1997 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1998 is:  0.0\n",
      "The cosine similarity between the documents  0 and 1999 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2000 is:  nan\n",
      "The cosine similarity between the documents  0 and 2001 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2002 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2003 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2004 is:  nan\n",
      "The cosine similarity between the documents  0 and 2005 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2006 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2007 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2008 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2009 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2010 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2011 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2012 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2013 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2014 is:  nan\n",
      "The cosine similarity between the documents  0 and 2015 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2016 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2017 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2018 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2019 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2020 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2021 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2022 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2023 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2024 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2025 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2026 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2027 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2028 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2029 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2030 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2031 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2032 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2033 is:  nan\n",
      "The cosine similarity between the documents  0 and 2034 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2035 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2036 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2037 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2038 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2039 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2040 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2041 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2042 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2043 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2044 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2045 is:  nan\n",
      "The cosine similarity between the documents  0 and 2046 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2047 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2048 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2049 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2050 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2051 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2052 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2053 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2054 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2055 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2056 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2057 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2058 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2059 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2060 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2061 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2062 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2063 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2064 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2065 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2066 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2067 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2068 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2069 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2070 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2071 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2072 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2073 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2074 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2075 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2076 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2077 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2078 is:  nan\n",
      "The cosine similarity between the documents  0 and 2079 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2080 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2081 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2082 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2083 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2084 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2085 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2086 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2087 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2088 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2089 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2090 is:  nan\n",
      "The cosine similarity between the documents  0 and 2091 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2092 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2093 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2094 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2095 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2096 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2097 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2098 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2099 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2100 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2101 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2102 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2103 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2104 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2105 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2106 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2107 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2108 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2109 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2110 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2111 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 2112 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2113 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2114 is:  nan\n",
      "The cosine similarity between the documents  0 and 2115 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2116 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2117 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2118 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2119 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2120 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2121 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2122 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2123 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2124 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2125 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2126 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2127 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2128 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2129 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2130 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2131 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2132 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2133 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2134 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2135 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2136 is:  nan\n",
      "The cosine similarity between the documents  0 and 2137 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2138 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2139 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2140 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2141 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2142 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2143 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2144 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2145 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2146 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2147 is:  nan\n",
      "The cosine similarity between the documents  0 and 2148 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2149 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2150 is:  nan\n",
      "The cosine similarity between the documents  0 and 2151 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2152 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2153 is:  nan\n",
      "The cosine similarity between the documents  0 and 2154 is:  nan\n",
      "The cosine similarity between the documents  0 and 2155 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2156 is:  nan\n",
      "The cosine similarity between the documents  0 and 2157 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2158 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2159 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2160 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2161 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2162 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2163 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2164 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2165 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2166 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2167 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2168 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2169 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2170 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2171 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2172 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2173 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2174 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2175 is:  nan\n",
      "The cosine similarity between the documents  0 and 2176 is:  nan\n",
      "The cosine similarity between the documents  0 and 2177 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2178 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2179 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2180 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2181 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2182 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2183 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2184 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2185 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2186 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2187 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2188 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2189 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2190 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2191 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2192 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2193 is:  nan\n",
      "The cosine similarity between the documents  0 and 2194 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2195 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2196 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2197 is:  nan\n",
      "The cosine similarity between the documents  0 and 2198 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2199 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2200 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2201 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2202 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2203 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2204 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2205 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2206 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2207 is:  nan\n",
      "The cosine similarity between the documents  0 and 2208 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2209 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2210 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2211 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2212 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2213 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2214 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2215 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2216 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2217 is:  nan\n",
      "The cosine similarity between the documents  0 and 2218 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2219 is:  nan\n",
      "The cosine similarity between the documents  0 and 2220 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2221 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2222 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2223 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2224 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2225 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2226 is:  nan\n",
      "The cosine similarity between the documents  0 and 2227 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2228 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2229 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2230 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2231 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2232 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2233 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2234 is:  nan\n",
      "The cosine similarity between the documents  0 and 2235 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2236 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2237 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2238 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2239 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2240 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2241 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2242 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2243 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2244 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2245 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 2246 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2247 is:  nan\n",
      "The cosine similarity between the documents  0 and 2248 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2249 is:  nan\n",
      "The cosine similarity between the documents  0 and 2250 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2251 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2252 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2253 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2254 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2255 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2256 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2257 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2258 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2259 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2260 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2261 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2262 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2263 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2264 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2265 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2266 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2267 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2268 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2269 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2270 is:  nan\n",
      "The cosine similarity between the documents  0 and 2271 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2272 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2273 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2274 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2275 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2276 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2277 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2278 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2279 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2280 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2281 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2282 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2283 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2284 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2285 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2286 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2287 is:  nan\n",
      "The cosine similarity between the documents  0 and 2288 is:  nan\n",
      "The cosine similarity between the documents  0 and 2289 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2290 is:  nan\n",
      "The cosine similarity between the documents  0 and 2291 is:  nan\n",
      "The cosine similarity between the documents  0 and 2292 is:  nan\n",
      "The cosine similarity between the documents  0 and 2293 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2294 is:  nan\n",
      "The cosine similarity between the documents  0 and 2295 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2296 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2297 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2298 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2299 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2300 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2301 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2302 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2303 is:  nan\n",
      "The cosine similarity between the documents  0 and 2304 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2305 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2306 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2307 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2308 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2309 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2310 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2311 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2312 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2313 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2314 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2315 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2316 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2317 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2318 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2319 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2320 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2321 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2322 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2323 is:  nan\n",
      "The cosine similarity between the documents  0 and 2324 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2325 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2326 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2327 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2328 is:  nan\n",
      "The cosine similarity between the documents  0 and 2329 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2330 is:  0.3779644730092272\n",
      "The cosine similarity between the documents  0 and 2331 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2332 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2333 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2334 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2335 is:  nan\n",
      "The cosine similarity between the documents  0 and 2336 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2337 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2338 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2339 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2340 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2341 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2342 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2343 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2344 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2345 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2346 is:  nan\n",
      "The cosine similarity between the documents  0 and 2347 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2348 is:  nan\n",
      "The cosine similarity between the documents  0 and 2349 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2350 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2351 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2352 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2353 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2354 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2355 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2356 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2357 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2358 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2359 is:  nan\n",
      "The cosine similarity between the documents  0 and 2360 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2361 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2362 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2363 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2364 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2365 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2366 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2367 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2368 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2369 is:  nan\n",
      "The cosine similarity between the documents  0 and 2370 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2371 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 2372 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2373 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2374 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2375 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2376 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2377 is:  nan\n",
      "The cosine similarity between the documents  0 and 2378 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2379 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2380 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2381 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2382 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2383 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2384 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2385 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2386 is:  nan\n",
      "The cosine similarity between the documents  0 and 2387 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2388 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2389 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2390 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2391 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2392 is:  nan\n",
      "The cosine similarity between the documents  0 and 2393 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2394 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2395 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2396 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2397 is:  nan\n",
      "The cosine similarity between the documents  0 and 2398 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2399 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2400 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2401 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2402 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2403 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2404 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2405 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2406 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2407 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2408 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2409 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2410 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2411 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2412 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2413 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2414 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2415 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2416 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2417 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2418 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2419 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2420 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2421 is:  nan\n",
      "The cosine similarity between the documents  0 and 2422 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2423 is:  nan\n",
      "The cosine similarity between the documents  0 and 2424 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2425 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2426 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2427 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2428 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2429 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2430 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2431 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2432 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2433 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2434 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2435 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2436 is:  nan\n",
      "The cosine similarity between the documents  0 and 2437 is:  nan\n",
      "The cosine similarity between the documents  0 and 2438 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2439 is:  nan\n",
      "The cosine similarity between the documents  0 and 2440 is:  nan\n",
      "The cosine similarity between the documents  0 and 2441 is:  nan\n",
      "The cosine similarity between the documents  0 and 2442 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2443 is:  nan\n",
      "The cosine similarity between the documents  0 and 2444 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2445 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2446 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2447 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2448 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2449 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2450 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2451 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2452 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2453 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2454 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2455 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2456 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2457 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2458 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2459 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2460 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2461 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2462 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2463 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2464 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2465 is:  nan\n",
      "The cosine similarity between the documents  0 and 2466 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2467 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2468 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2469 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2470 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2471 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2472 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2473 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2474 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2475 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2476 is:  nan\n",
      "The cosine similarity between the documents  0 and 2477 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2478 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2479 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2480 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2481 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2482 is:  nan\n",
      "The cosine similarity between the documents  0 and 2483 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2484 is:  nan\n",
      "The cosine similarity between the documents  0 and 2485 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2486 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2487 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2488 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2489 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2490 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2491 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2492 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2493 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2494 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2495 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2496 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2497 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2498 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 2499 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2500 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2501 is:  nan\n",
      "The cosine similarity between the documents  0 and 2502 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2503 is:  nan\n",
      "The cosine similarity between the documents  0 and 2504 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2505 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2506 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2507 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2508 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2509 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2510 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2511 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2512 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2513 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2514 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2515 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2516 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2517 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2518 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2519 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2520 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2521 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2522 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2523 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2524 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2525 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2526 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2527 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2528 is:  nan\n",
      "The cosine similarity between the documents  0 and 2529 is:  nan\n",
      "The cosine similarity between the documents  0 and 2530 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2531 is:  nan\n",
      "The cosine similarity between the documents  0 and 2532 is:  nan\n",
      "The cosine similarity between the documents  0 and 2533 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2534 is:  nan\n",
      "The cosine similarity between the documents  0 and 2535 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2536 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2537 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2538 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2539 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2540 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2541 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2542 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2543 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2544 is:  nan\n",
      "The cosine similarity between the documents  0 and 2545 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2546 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2547 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2548 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2549 is:  nan\n",
      "The cosine similarity between the documents  0 and 2550 is:  nan\n",
      "The cosine similarity between the documents  0 and 2551 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2552 is:  nan\n",
      "The cosine similarity between the documents  0 and 2553 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2554 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2555 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2556 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2557 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2558 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2559 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2560 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2561 is:  nan\n",
      "The cosine similarity between the documents  0 and 2562 is:  nan\n",
      "The cosine similarity between the documents  0 and 2563 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2564 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2565 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2566 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2567 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2568 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2569 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2570 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2571 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2572 is:  nan\n",
      "The cosine similarity between the documents  0 and 2573 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2574 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2575 is:  nan\n",
      "The cosine similarity between the documents  0 and 2576 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2577 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2578 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2579 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2580 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2581 is:  nan\n",
      "The cosine similarity between the documents  0 and 2582 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2583 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2584 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2585 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2586 is:  nan\n",
      "The cosine similarity between the documents  0 and 2587 is:  nan\n",
      "The cosine similarity between the documents  0 and 2588 is:  nan\n",
      "The cosine similarity between the documents  0 and 2589 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2590 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2591 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2592 is:  nan\n",
      "The cosine similarity between the documents  0 and 2593 is:  nan\n",
      "The cosine similarity between the documents  0 and 2594 is:  nan\n",
      "The cosine similarity between the documents  0 and 2595 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2596 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2597 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2598 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2599 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2600 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2601 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2602 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2603 is:  nan\n",
      "The cosine similarity between the documents  0 and 2604 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2605 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2606 is:  nan\n",
      "The cosine similarity between the documents  0 and 2607 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2608 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2609 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2610 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2611 is:  nan\n",
      "The cosine similarity between the documents  0 and 2612 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2613 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2614 is:  nan\n",
      "The cosine similarity between the documents  0 and 2615 is:  nan\n",
      "The cosine similarity between the documents  0 and 2616 is:  nan\n",
      "The cosine similarity between the documents  0 and 2617 is:  nan\n",
      "The cosine similarity between the documents  0 and 2618 is:  nan\n",
      "The cosine similarity between the documents  0 and 2619 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2620 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2621 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2622 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2623 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2624 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2625 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2626 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2627 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 2628 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2629 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2630 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2631 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2632 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2633 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2634 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2635 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2636 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2637 is:  nan\n",
      "The cosine similarity between the documents  0 and 2638 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2639 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2640 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2641 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2642 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2643 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2644 is:  nan\n",
      "The cosine similarity between the documents  0 and 2645 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2646 is:  nan\n",
      "The cosine similarity between the documents  0 and 2647 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2648 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2649 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2650 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2651 is:  nan\n",
      "The cosine similarity between the documents  0 and 2652 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2653 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2654 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2655 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2656 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2657 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2658 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2659 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2660 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2661 is:  nan\n",
      "The cosine similarity between the documents  0 and 2662 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2663 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2664 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2665 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2666 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2667 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2668 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2669 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2670 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2671 is:  nan\n",
      "The cosine similarity between the documents  0 and 2672 is:  nan\n",
      "The cosine similarity between the documents  0 and 2673 is:  nan\n",
      "The cosine similarity between the documents  0 and 2674 is:  nan\n",
      "The cosine similarity between the documents  0 and 2675 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2676 is:  nan\n",
      "The cosine similarity between the documents  0 and 2677 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2678 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2679 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2680 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2681 is:  nan\n",
      "The cosine similarity between the documents  0 and 2682 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2683 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2684 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2685 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2686 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2687 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2688 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2689 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2690 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2691 is:  nan\n",
      "The cosine similarity between the documents  0 and 2692 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2693 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2694 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2695 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2696 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2697 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2698 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2699 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2700 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2701 is:  nan\n",
      "The cosine similarity between the documents  0 and 2702 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2703 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2704 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2705 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2706 is:  nan\n",
      "The cosine similarity between the documents  0 and 2707 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2708 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2709 is:  nan\n",
      "The cosine similarity between the documents  0 and 2710 is:  nan\n",
      "The cosine similarity between the documents  0 and 2711 is:  nan\n",
      "The cosine similarity between the documents  0 and 2712 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2713 is:  nan\n",
      "The cosine similarity between the documents  0 and 2714 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2715 is:  nan\n",
      "The cosine similarity between the documents  0 and 2716 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2717 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2718 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2719 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2720 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2721 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2722 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2723 is:  nan\n",
      "The cosine similarity between the documents  0 and 2724 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2725 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2726 is:  nan\n",
      "The cosine similarity between the documents  0 and 2727 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2728 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2729 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2730 is:  nan\n",
      "The cosine similarity between the documents  0 and 2731 is:  nan\n",
      "The cosine similarity between the documents  0 and 2732 is:  nan\n",
      "The cosine similarity between the documents  0 and 2733 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2734 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2735 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2736 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2737 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2738 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2739 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2740 is:  nan\n",
      "The cosine similarity between the documents  0 and 2741 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2742 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2743 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2744 is:  nan\n",
      "The cosine similarity between the documents  0 and 2745 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2746 is:  nan\n",
      "The cosine similarity between the documents  0 and 2747 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2748 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2749 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2750 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2751 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2752 is:  nan\n",
      "The cosine similarity between the documents  0 and 2753 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2754 is:  nan\n",
      "The cosine similarity between the documents  0 and 2755 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 2756 is:  nan\n",
      "The cosine similarity between the documents  0 and 2757 is:  nan\n",
      "The cosine similarity between the documents  0 and 2758 is:  nan\n",
      "The cosine similarity between the documents  0 and 2759 is:  nan\n",
      "The cosine similarity between the documents  0 and 2760 is:  nan\n",
      "The cosine similarity between the documents  0 and 2761 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2762 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2763 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2764 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2765 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2766 is:  nan\n",
      "The cosine similarity between the documents  0 and 2767 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2768 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2769 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2770 is:  nan\n",
      "The cosine similarity between the documents  0 and 2771 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2772 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2773 is:  nan\n",
      "The cosine similarity between the documents  0 and 2774 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2775 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2776 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2777 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2778 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2779 is:  nan\n",
      "The cosine similarity between the documents  0 and 2780 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2781 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2782 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2783 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2784 is:  nan\n",
      "The cosine similarity between the documents  0 and 2785 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2786 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2787 is:  nan\n",
      "The cosine similarity between the documents  0 and 2788 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2789 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2790 is:  nan\n",
      "The cosine similarity between the documents  0 and 2791 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2792 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2793 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2794 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2795 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2796 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2797 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2798 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2799 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2800 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2801 is:  nan\n",
      "The cosine similarity between the documents  0 and 2802 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2803 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2804 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2805 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2806 is:  nan\n",
      "The cosine similarity between the documents  0 and 2807 is:  nan\n",
      "The cosine similarity between the documents  0 and 2808 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2809 is:  nan\n",
      "The cosine similarity between the documents  0 and 2810 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2811 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2812 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2813 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2814 is:  nan\n",
      "The cosine similarity between the documents  0 and 2815 is:  nan\n",
      "The cosine similarity between the documents  0 and 2816 is:  nan\n",
      "The cosine similarity between the documents  0 and 2817 is:  nan\n",
      "The cosine similarity between the documents  0 and 2818 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2819 is:  nan\n",
      "The cosine similarity between the documents  0 and 2820 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2821 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2822 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2823 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2824 is:  nan\n",
      "The cosine similarity between the documents  0 and 2825 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2826 is:  nan\n",
      "The cosine similarity between the documents  0 and 2827 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2828 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2829 is:  nan\n",
      "The cosine similarity between the documents  0 and 2830 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2831 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2832 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2833 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2834 is:  nan\n",
      "The cosine similarity between the documents  0 and 2835 is:  nan\n",
      "The cosine similarity between the documents  0 and 2836 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2837 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2838 is:  nan\n",
      "The cosine similarity between the documents  0 and 2839 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2840 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2841 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2842 is:  nan\n",
      "The cosine similarity between the documents  0 and 2843 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2844 is:  nan\n",
      "The cosine similarity between the documents  0 and 2845 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2846 is:  nan\n",
      "The cosine similarity between the documents  0 and 2847 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2848 is:  nan\n",
      "The cosine similarity between the documents  0 and 2849 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2850 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2851 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2852 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2853 is:  nan\n",
      "The cosine similarity between the documents  0 and 2854 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2855 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2856 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2857 is:  nan\n",
      "The cosine similarity between the documents  0 and 2858 is:  nan\n",
      "The cosine similarity between the documents  0 and 2859 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2860 is:  nan\n",
      "The cosine similarity between the documents  0 and 2861 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2862 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2863 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2864 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2865 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2866 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2867 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2868 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2869 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2870 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2871 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2872 is:  nan\n",
      "The cosine similarity between the documents  0 and 2873 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2874 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2875 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2876 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2877 is:  nan\n",
      "The cosine similarity between the documents  0 and 2878 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2879 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2880 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2881 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2882 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2883 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2884 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2885 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2886 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2887 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2888 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2889 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2890 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 2891 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2892 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2893 is:  nan\n",
      "The cosine similarity between the documents  0 and 2894 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2895 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2896 is:  nan\n",
      "The cosine similarity between the documents  0 and 2897 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2898 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2899 is:  nan\n",
      "The cosine similarity between the documents  0 and 2900 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2901 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2902 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2903 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2904 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2905 is:  nan\n",
      "The cosine similarity between the documents  0 and 2906 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2907 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2908 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2909 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2910 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2911 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2912 is:  nan\n",
      "The cosine similarity between the documents  0 and 2913 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2914 is:  nan\n",
      "The cosine similarity between the documents  0 and 2915 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2916 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2917 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2918 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2919 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2920 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2921 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2922 is:  nan\n",
      "The cosine similarity between the documents  0 and 2923 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2924 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2925 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2926 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2927 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2928 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2929 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2930 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2931 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2932 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2933 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2934 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2935 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2936 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2937 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2938 is:  nan\n",
      "The cosine similarity between the documents  0 and 2939 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2940 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2941 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2942 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2943 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2944 is:  nan\n",
      "The cosine similarity between the documents  0 and 2945 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2946 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2947 is:  nan\n",
      "The cosine similarity between the documents  0 and 2948 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2949 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2950 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2951 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2952 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2953 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2954 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2955 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2956 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2957 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2958 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2959 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2960 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2961 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2962 is:  nan\n",
      "The cosine similarity between the documents  0 and 2963 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2964 is:  nan\n",
      "The cosine similarity between the documents  0 and 2965 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2966 is:  nan\n",
      "The cosine similarity between the documents  0 and 2967 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2968 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2969 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2970 is:  1.0\n",
      "The cosine similarity between the documents  0 and 2971 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2972 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2973 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2974 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2975 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2976 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2977 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2978 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2979 is:  nan\n",
      "The cosine similarity between the documents  0 and 2980 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2981 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2982 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2983 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2984 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2985 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2986 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2987 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2988 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2989 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2990 is:  nan\n",
      "The cosine similarity between the documents  0 and 2991 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2992 is:  nan\n",
      "The cosine similarity between the documents  0 and 2993 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2994 is:  nan\n",
      "The cosine similarity between the documents  0 and 2995 is:  nan\n",
      "The cosine similarity between the documents  0 and 2996 is:  nan\n",
      "The cosine similarity between the documents  0 and 2997 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2998 is:  0.0\n",
      "The cosine similarity between the documents  0 and 2999 is:  nan\n",
      "The cosine similarity between the documents  0 and 3000 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3001 is:  nan\n",
      "The cosine similarity between the documents  0 and 3002 is:  nan\n",
      "The cosine similarity between the documents  0 and 3003 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3004 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3005 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3006 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3007 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3008 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3009 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3010 is:  1.0\n",
      "The cosine similarity between the documents  0 and 3011 is:  nan\n",
      "The cosine similarity between the documents  0 and 3012 is:  1.0\n",
      "The cosine similarity between the documents  0 and 3013 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3014 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3015 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3016 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3017 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3018 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3019 is:  nan\n",
      "The cosine similarity between the documents  0 and 3020 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3021 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3022 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3023 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3024 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3025 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3026 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3027 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3028 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3029 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3030 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3031 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3032 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3033 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3034 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3035 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3036 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3037 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3038 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3039 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3040 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3041 is:  nan\n",
      "The cosine similarity between the documents  0 and 3042 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3043 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3044 is:  nan\n",
      "The cosine similarity between the documents  0 and 3045 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3046 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3047 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3048 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3049 is:  nan\n",
      "The cosine similarity between the documents  0 and 3050 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3051 is:  nan\n",
      "The cosine similarity between the documents  0 and 3052 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3053 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3054 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3055 is:  nan\n",
      "The cosine similarity between the documents  0 and 3056 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3057 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3058 is:  nan\n",
      "The cosine similarity between the documents  0 and 3059 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3060 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3061 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3062 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3063 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3064 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3065 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3066 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3067 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3068 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3069 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3070 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3071 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3072 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3073 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3074 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3075 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3076 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3077 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3078 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3079 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3080 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3081 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3082 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3083 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3084 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3085 is:  nan\n",
      "The cosine similarity between the documents  0 and 3086 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3087 is:  nan\n",
      "The cosine similarity between the documents  0 and 3088 is:  nan\n",
      "The cosine similarity between the documents  0 and 3089 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3090 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3091 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3092 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3093 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3094 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3095 is:  1.0\n",
      "The cosine similarity between the documents  0 and 3096 is:  nan\n",
      "The cosine similarity between the documents  0 and 3097 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3098 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3099 is:  nan\n",
      "The cosine similarity between the documents  0 and 3100 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3101 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3102 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3103 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3104 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3105 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3106 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3107 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3108 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3109 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3110 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3111 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3112 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3113 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3114 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3115 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3116 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3117 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3118 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3119 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3120 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3121 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3122 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3123 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3124 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3125 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3126 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3127 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3128 is:  nan\n",
      "The cosine similarity between the documents  0 and 3129 is:  nan\n",
      "The cosine similarity between the documents  0 and 3130 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3131 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3132 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3133 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3134 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3135 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3136 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3137 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3138 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3139 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3140 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3141 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3142 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3143 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3144 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3145 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3146 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3147 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3148 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3149 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3150 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3151 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3152 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3153 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3154 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3155 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3156 is:  1.0\n",
      "The cosine similarity between the documents  0 and 3157 is:  nan\n",
      "The cosine similarity between the documents  0 and 3158 is:  nan\n",
      "The cosine similarity between the documents  0 and 3159 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3160 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3161 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3162 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3163 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3164 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3165 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3166 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3167 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3168 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3169 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3170 is:  nan\n",
      "The cosine similarity between the documents  0 and 3171 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3172 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3173 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3174 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3175 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3176 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3177 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3178 is:  nan\n",
      "The cosine similarity between the documents  0 and 3179 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3180 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3181 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3182 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3183 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3184 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3185 is:  nan\n",
      "The cosine similarity between the documents  0 and 3186 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3187 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3188 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3189 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3190 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3191 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3192 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3193 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3194 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3195 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3196 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3197 is:  nan\n",
      "The cosine similarity between the documents  0 and 3198 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3199 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3200 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3201 is:  nan\n",
      "The cosine similarity between the documents  0 and 3202 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3203 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3204 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3205 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3206 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3207 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3208 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3209 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3210 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3211 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3212 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3213 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3214 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3215 is:  nan\n",
      "The cosine similarity between the documents  0 and 3216 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3217 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3218 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3219 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3220 is:  nan\n",
      "The cosine similarity between the documents  0 and 3221 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3222 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3223 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3224 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3225 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3226 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3227 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3228 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3229 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3230 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3231 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3232 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3233 is:  nan\n",
      "The cosine similarity between the documents  0 and 3234 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3235 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3236 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3237 is:  nan\n",
      "The cosine similarity between the documents  0 and 3238 is:  nan\n",
      "The cosine similarity between the documents  0 and 3239 is:  nan\n",
      "The cosine similarity between the documents  0 and 3240 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3241 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3242 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3243 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3244 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3245 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3246 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3247 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3248 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3249 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3250 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3251 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3252 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3253 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3254 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3255 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3256 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3257 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3258 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3259 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3260 is:  nan\n",
      "The cosine similarity between the documents  0 and 3261 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3262 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3263 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3264 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3265 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3266 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3267 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3268 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3269 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3270 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3271 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3272 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3273 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3274 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3275 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3276 is:  nan\n",
      "The cosine similarity between the documents  0 and 3277 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3278 is:  nan\n",
      "The cosine similarity between the documents  0 and 3279 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3280 is:  nan\n",
      "The cosine similarity between the documents  0 and 3281 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3282 is:  nan\n",
      "The cosine similarity between the documents  0 and 3283 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3284 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3285 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3286 is:  nan\n",
      "The cosine similarity between the documents  0 and 3287 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3288 is:  nan\n",
      "The cosine similarity between the documents  0 and 3289 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3290 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3291 is:  nan\n",
      "The cosine similarity between the documents  0 and 3292 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3293 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3294 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3295 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3296 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3297 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3298 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3299 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3300 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3301 is:  nan\n",
      "The cosine similarity between the documents  0 and 3302 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3303 is:  nan\n",
      "The cosine similarity between the documents  0 and 3304 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3305 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3306 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3307 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3308 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3309 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3310 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3311 is:  nan\n",
      "The cosine similarity between the documents  0 and 3312 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3313 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3314 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3315 is:  nan\n",
      "The cosine similarity between the documents  0 and 3316 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3317 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3318 is:  nan\n",
      "The cosine similarity between the documents  0 and 3319 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3320 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3321 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3322 is:  nan\n",
      "The cosine similarity between the documents  0 and 3323 is:  nan\n",
      "The cosine similarity between the documents  0 and 3324 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3325 is:  nan\n",
      "The cosine similarity between the documents  0 and 3326 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3327 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3328 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3329 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3330 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3331 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3332 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3333 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3334 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3335 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3336 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3337 is:  nan\n",
      "The cosine similarity between the documents  0 and 3338 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3339 is:  nan\n",
      "The cosine similarity between the documents  0 and 3340 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3341 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3342 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3343 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3344 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3345 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3346 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3347 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3348 is:  nan\n",
      "The cosine similarity between the documents  0 and 3349 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3350 is:  nan\n",
      "The cosine similarity between the documents  0 and 3351 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3352 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3353 is:  nan\n",
      "The cosine similarity between the documents  0 and 3354 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3355 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3356 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3357 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3358 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3359 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3360 is:  nan\n",
      "The cosine similarity between the documents  0 and 3361 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3362 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3363 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3364 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3365 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3366 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3367 is:  nan\n",
      "The cosine similarity between the documents  0 and 3368 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3369 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3370 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3371 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3372 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3373 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3374 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3375 is:  nan\n",
      "The cosine similarity between the documents  0 and 3376 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3377 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3378 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3379 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3380 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3381 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3382 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3383 is:  nan\n",
      "The cosine similarity between the documents  0 and 3384 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3385 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3386 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3387 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3388 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3389 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3390 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3391 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3392 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3393 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3394 is:  nan\n",
      "The cosine similarity between the documents  0 and 3395 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3396 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3397 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3398 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3399 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3400 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3401 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3402 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3403 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3404 is:  nan\n",
      "The cosine similarity between the documents  0 and 3405 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3406 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3407 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3408 is:  nan\n",
      "The cosine similarity between the documents  0 and 3409 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3410 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3411 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3412 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3413 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3414 is:  nan\n",
      "The cosine similarity between the documents  0 and 3415 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3416 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3417 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3418 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3419 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3420 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3421 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3422 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3423 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3424 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3425 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3426 is:  nan\n",
      "The cosine similarity between the documents  0 and 3427 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3428 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3429 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3430 is:  nan\n",
      "The cosine similarity between the documents  0 and 3431 is:  nan\n",
      "The cosine similarity between the documents  0 and 3432 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3433 is:  nan\n",
      "The cosine similarity between the documents  0 and 3434 is:  nan\n",
      "The cosine similarity between the documents  0 and 3435 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3436 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3437 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3438 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3439 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3440 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3441 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3442 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3443 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3444 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3445 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3446 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3447 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3448 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3449 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3450 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3451 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3452 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3453 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3454 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3455 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3456 is:  nan\n",
      "The cosine similarity between the documents  0 and 3457 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3458 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3459 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3460 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3461 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3462 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3463 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3464 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3465 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3466 is:  nan\n",
      "The cosine similarity between the documents  0 and 3467 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3468 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3469 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3470 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3471 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3472 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3473 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3474 is:  nan\n",
      "The cosine similarity between the documents  0 and 3475 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3476 is:  nan\n",
      "The cosine similarity between the documents  0 and 3477 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3478 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3479 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3480 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3481 is:  nan\n",
      "The cosine similarity between the documents  0 and 3482 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3483 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3484 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3485 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3486 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3487 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3488 is:  nan\n",
      "The cosine similarity between the documents  0 and 3489 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3490 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3491 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3492 is:  nan\n",
      "The cosine similarity between the documents  0 and 3493 is:  nan\n",
      "The cosine similarity between the documents  0 and 3494 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3495 is:  nan\n",
      "The cosine similarity between the documents  0 and 3496 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3497 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3498 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3499 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3500 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3501 is:  nan\n",
      "The cosine similarity between the documents  0 and 3502 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3503 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3504 is:  nan\n",
      "The cosine similarity between the documents  0 and 3505 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3506 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3507 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3508 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3509 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3510 is:  1.0\n",
      "The cosine similarity between the documents  0 and 3511 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3512 is:  1.0\n",
      "The cosine similarity between the documents  0 and 3513 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3514 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3515 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3516 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3517 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3518 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3519 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3520 is:  nan\n",
      "The cosine similarity between the documents  0 and 3521 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3522 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3523 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3524 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3525 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3526 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3527 is:  nan\n",
      "The cosine similarity between the documents  0 and 3528 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3529 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3530 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3531 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3532 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3533 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3534 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3535 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3536 is:  nan\n",
      "The cosine similarity between the documents  0 and 3537 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3538 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3539 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3540 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3541 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3542 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3543 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3544 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3545 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3546 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3547 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3548 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3549 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3550 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3551 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3552 is:  nan\n",
      "The cosine similarity between the documents  0 and 3553 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3554 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3555 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3556 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3557 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3558 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3559 is:  nan\n",
      "The cosine similarity between the documents  0 and 3560 is:  nan\n",
      "The cosine similarity between the documents  0 and 3561 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3562 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3563 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3564 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3565 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3566 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3567 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3568 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3569 is:  nan\n",
      "The cosine similarity between the documents  0 and 3570 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3571 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3572 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3573 is:  nan\n",
      "The cosine similarity between the documents  0 and 3574 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3575 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3576 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3577 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3578 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3579 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3580 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3581 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3582 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3583 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3584 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3585 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3586 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3587 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3588 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3589 is:  nan\n",
      "The cosine similarity between the documents  0 and 3590 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3591 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3592 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3593 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3594 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3595 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3596 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3597 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3598 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3599 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3600 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3601 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3602 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3603 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3604 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3605 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3606 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3607 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3608 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3609 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3610 is:  nan\n",
      "The cosine similarity between the documents  0 and 3611 is:  nan\n",
      "The cosine similarity between the documents  0 and 3612 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3613 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3614 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3615 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3616 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3617 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3618 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3619 is:  nan\n",
      "The cosine similarity between the documents  0 and 3620 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3621 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3622 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3623 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3624 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3625 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3626 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3627 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3628 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3629 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3630 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3631 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3632 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3633 is:  nan\n",
      "The cosine similarity between the documents  0 and 3634 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3635 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3636 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3637 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3638 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3639 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3640 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3641 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3642 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3643 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3644 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3645 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3646 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3647 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3648 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3649 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3650 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3651 is:  nan\n",
      "The cosine similarity between the documents  0 and 3652 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3653 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3654 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3655 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3656 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3657 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3658 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3659 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3660 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3661 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3662 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3663 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3664 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3665 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3666 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3667 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3668 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3669 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3670 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3671 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3672 is:  nan\n",
      "The cosine similarity between the documents  0 and 3673 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3674 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3675 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3676 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3677 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3678 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3679 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3680 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3681 is:  nan\n",
      "The cosine similarity between the documents  0 and 3682 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3683 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3684 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3685 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3686 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3687 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3688 is:  nan\n",
      "The cosine similarity between the documents  0 and 3689 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3690 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3691 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3692 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3693 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3694 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3695 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3696 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3697 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3698 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3699 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3700 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3701 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3702 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3703 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3704 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3705 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3706 is:  nan\n",
      "The cosine similarity between the documents  0 and 3707 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3708 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3709 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3710 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3711 is:  nan\n",
      "The cosine similarity between the documents  0 and 3712 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3713 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3714 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3715 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3716 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3717 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3718 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3719 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3720 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3721 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3722 is:  nan\n",
      "The cosine similarity between the documents  0 and 3723 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3724 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3725 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3726 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3727 is:  nan\n",
      "The cosine similarity between the documents  0 and 3728 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3729 is:  nan\n",
      "The cosine similarity between the documents  0 and 3730 is:  nan\n",
      "The cosine similarity between the documents  0 and 3731 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3732 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3733 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3734 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3735 is:  nan\n",
      "The cosine similarity between the documents  0 and 3736 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3737 is:  nan\n",
      "The cosine similarity between the documents  0 and 3738 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3739 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3740 is:  nan\n",
      "The cosine similarity between the documents  0 and 3741 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3742 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3743 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3744 is:  nan\n",
      "The cosine similarity between the documents  0 and 3745 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3746 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3747 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3748 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3749 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3750 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3751 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3752 is:  nan\n",
      "The cosine similarity between the documents  0 and 3753 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3754 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3755 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3756 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3757 is:  nan\n",
      "The cosine similarity between the documents  0 and 3758 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3759 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3760 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3761 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3762 is:  nan\n",
      "The cosine similarity between the documents  0 and 3763 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3764 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3765 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3766 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3767 is:  nan\n",
      "The cosine similarity between the documents  0 and 3768 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3769 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3770 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3771 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3772 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3773 is:  nan\n",
      "The cosine similarity between the documents  0 and 3774 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3775 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3776 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3777 is:  nan\n",
      "The cosine similarity between the documents  0 and 3778 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3779 is:  nan\n",
      "The cosine similarity between the documents  0 and 3780 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3781 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3782 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3783 is:  nan\n",
      "The cosine similarity between the documents  0 and 3784 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3785 is:  nan\n",
      "The cosine similarity between the documents  0 and 3786 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3787 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3788 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3789 is:  nan\n",
      "The cosine similarity between the documents  0 and 3790 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3791 is:  nan\n",
      "The cosine similarity between the documents  0 and 3792 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3793 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3794 is:  nan\n",
      "The cosine similarity between the documents  0 and 3795 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3796 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3797 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3798 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3799 is:  nan\n",
      "The cosine similarity between the documents  0 and 3800 is:  nan\n",
      "The cosine similarity between the documents  0 and 3801 is:  nan\n",
      "The cosine similarity between the documents  0 and 3802 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3803 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3804 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3805 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3806 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3807 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3808 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3809 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3810 is:  nan\n",
      "The cosine similarity between the documents  0 and 3811 is:  nan\n",
      "The cosine similarity between the documents  0 and 3812 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3813 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3814 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3815 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3816 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3817 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3818 is:  nan\n",
      "The cosine similarity between the documents  0 and 3819 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3820 is:  nan\n",
      "The cosine similarity between the documents  0 and 3821 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3822 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3823 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3824 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3825 is:  nan\n",
      "The cosine similarity between the documents  0 and 3826 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3827 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3828 is:  nan\n",
      "The cosine similarity between the documents  0 and 3829 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3830 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3831 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3832 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3833 is:  nan\n",
      "The cosine similarity between the documents  0 and 3834 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3835 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3836 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3837 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3838 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3839 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3840 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3841 is:  nan\n",
      "The cosine similarity between the documents  0 and 3842 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3843 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3844 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3845 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3846 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3847 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3848 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3849 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3850 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3851 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3852 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3853 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3854 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3855 is:  nan\n",
      "The cosine similarity between the documents  0 and 3856 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3857 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3858 is:  nan\n",
      "The cosine similarity between the documents  0 and 3859 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3860 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3861 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3862 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3863 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3864 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3865 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3866 is:  nan\n",
      "The cosine similarity between the documents  0 and 3867 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3868 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3869 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3870 is:  nan\n",
      "The cosine similarity between the documents  0 and 3871 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3872 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3873 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3874 is:  nan\n",
      "The cosine similarity between the documents  0 and 3875 is:  nan\n",
      "The cosine similarity between the documents  0 and 3876 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3877 is:  nan\n",
      "The cosine similarity between the documents  0 and 3878 is:  nan\n",
      "The cosine similarity between the documents  0 and 3879 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3880 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3881 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3882 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3883 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3884 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3885 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3886 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3887 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3888 is:  nan\n",
      "The cosine similarity between the documents  0 and 3889 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3890 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3891 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3892 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3893 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3894 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3895 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3896 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3897 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3898 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3899 is:  nan\n",
      "The cosine similarity between the documents  0 and 3900 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3901 is:  nan\n",
      "The cosine similarity between the documents  0 and 3902 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3903 is:  nan\n",
      "The cosine similarity between the documents  0 and 3904 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3905 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3906 is:  nan\n",
      "The cosine similarity between the documents  0 and 3907 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3908 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3909 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3910 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3911 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3912 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3913 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3914 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3915 is:  nan\n",
      "The cosine similarity between the documents  0 and 3916 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3917 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3918 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3919 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3920 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3921 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3922 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3923 is:  nan\n",
      "The cosine similarity between the documents  0 and 3924 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3925 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3926 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3927 is:  nan\n",
      "The cosine similarity between the documents  0 and 3928 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3929 is:  nan\n",
      "The cosine similarity between the documents  0 and 3930 is:  nan\n",
      "The cosine similarity between the documents  0 and 3931 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3932 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3933 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3934 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3935 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3936 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 3937 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3938 is:  nan\n",
      "The cosine similarity between the documents  0 and 3939 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3940 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3941 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3942 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3943 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3944 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3945 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3946 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3947 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3948 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3949 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3950 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3951 is:  nan\n",
      "The cosine similarity between the documents  0 and 3952 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3953 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3954 is:  nan\n",
      "The cosine similarity between the documents  0 and 3955 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3956 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3957 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3958 is:  nan\n",
      "The cosine similarity between the documents  0 and 3959 is:  nan\n",
      "The cosine similarity between the documents  0 and 3960 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3961 is:  nan\n",
      "The cosine similarity between the documents  0 and 3962 is:  nan\n",
      "The cosine similarity between the documents  0 and 3963 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3964 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3965 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3966 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3967 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3968 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3969 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3970 is:  nan\n",
      "The cosine similarity between the documents  0 and 3971 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3972 is:  nan\n",
      "The cosine similarity between the documents  0 and 3973 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3974 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3975 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3976 is:  nan\n",
      "The cosine similarity between the documents  0 and 3977 is:  nan\n",
      "The cosine similarity between the documents  0 and 3978 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3979 is:  nan\n",
      "The cosine similarity between the documents  0 and 3980 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3981 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3982 is:  nan\n",
      "The cosine similarity between the documents  0 and 3983 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3984 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3985 is:  nan\n",
      "The cosine similarity between the documents  0 and 3986 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3987 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3988 is:  nan\n",
      "The cosine similarity between the documents  0 and 3989 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3990 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3991 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3992 is:  nan\n",
      "The cosine similarity between the documents  0 and 3993 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3994 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3995 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3996 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3997 is:  0.0\n",
      "The cosine similarity between the documents  0 and 3998 is:  nan\n",
      "The cosine similarity between the documents  0 and 3999 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4000 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4001 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4002 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4003 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4004 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4005 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4006 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4007 is:  nan\n",
      "The cosine similarity between the documents  0 and 4008 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4009 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4010 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4011 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4012 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4013 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4014 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4015 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4016 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4017 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4018 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4019 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4020 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4021 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4022 is:  nan\n",
      "The cosine similarity between the documents  0 and 4023 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4024 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4025 is:  nan\n",
      "The cosine similarity between the documents  0 and 4026 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4027 is:  nan\n",
      "The cosine similarity between the documents  0 and 4028 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4029 is:  nan\n",
      "The cosine similarity between the documents  0 and 4030 is:  nan\n",
      "The cosine similarity between the documents  0 and 4031 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4032 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4033 is:  nan\n",
      "The cosine similarity between the documents  0 and 4034 is:  nan\n",
      "The cosine similarity between the documents  0 and 4035 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4036 is:  nan\n",
      "The cosine similarity between the documents  0 and 4037 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4038 is:  nan\n",
      "The cosine similarity between the documents  0 and 4039 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4040 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4041 is:  nan\n",
      "The cosine similarity between the documents  0 and 4042 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4043 is:  nan\n",
      "The cosine similarity between the documents  0 and 4044 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4045 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4046 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4047 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4048 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4049 is:  nan\n",
      "The cosine similarity between the documents  0 and 4050 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4051 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4052 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4053 is:  nan\n",
      "The cosine similarity between the documents  0 and 4054 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4055 is:  nan\n",
      "The cosine similarity between the documents  0 and 4056 is:  nan\n",
      "The cosine similarity between the documents  0 and 4057 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4058 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4059 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4060 is:  nan\n",
      "The cosine similarity between the documents  0 and 4061 is:  nan\n",
      "The cosine similarity between the documents  0 and 4062 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4063 is:  nan\n",
      "The cosine similarity between the documents  0 and 4064 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4065 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4066 is:  nan\n",
      "The cosine similarity between the documents  0 and 4067 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4068 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4069 is:  nan\n",
      "The cosine similarity between the documents  0 and 4070 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4071 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4072 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4073 is:  nan\n",
      "The cosine similarity between the documents  0 and 4074 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4075 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4076 is:  nan\n",
      "The cosine similarity between the documents  0 and 4077 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4078 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4079 is:  nan\n",
      "The cosine similarity between the documents  0 and 4080 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4081 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4082 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4083 is:  nan\n",
      "The cosine similarity between the documents  0 and 4084 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4085 is:  nan\n",
      "The cosine similarity between the documents  0 and 4086 is:  nan\n",
      "The cosine similarity between the documents  0 and 4087 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4088 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4089 is:  nan\n",
      "The cosine similarity between the documents  0 and 4090 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4091 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4092 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4093 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4094 is:  nan\n",
      "The cosine similarity between the documents  0 and 4095 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4096 is:  nan\n",
      "The cosine similarity between the documents  0 and 4097 is:  nan\n",
      "The cosine similarity between the documents  0 and 4098 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4099 is:  nan\n",
      "The cosine similarity between the documents  0 and 4100 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4101 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4102 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4103 is:  nan\n",
      "The cosine similarity between the documents  0 and 4104 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4105 is:  nan\n",
      "The cosine similarity between the documents  0 and 4106 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4107 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4108 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4109 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4110 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4111 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4112 is:  nan\n",
      "The cosine similarity between the documents  0 and 4113 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4114 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4115 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4116 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4117 is:  nan\n",
      "The cosine similarity between the documents  0 and 4118 is:  nan\n",
      "The cosine similarity between the documents  0 and 4119 is:  nan\n",
      "The cosine similarity between the documents  0 and 4120 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4121 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4122 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4123 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4124 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4125 is:  nan\n",
      "The cosine similarity between the documents  0 and 4126 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4127 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4128 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4129 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4130 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4131 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4132 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4133 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4134 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4135 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4136 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4137 is:  nan\n",
      "The cosine similarity between the documents  0 and 4138 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4139 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4140 is:  nan\n",
      "The cosine similarity between the documents  0 and 4141 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4142 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4143 is:  nan\n",
      "The cosine similarity between the documents  0 and 4144 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4145 is:  nan\n",
      "The cosine similarity between the documents  0 and 4146 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4147 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4148 is:  nan\n",
      "The cosine similarity between the documents  0 and 4149 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4150 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4151 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4152 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4153 is:  nan\n",
      "The cosine similarity between the documents  0 and 4154 is:  nan\n",
      "The cosine similarity between the documents  0 and 4155 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4156 is:  nan\n",
      "The cosine similarity between the documents  0 and 4157 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4158 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4159 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4160 is:  nan\n",
      "The cosine similarity between the documents  0 and 4161 is:  nan\n",
      "The cosine similarity between the documents  0 and 4162 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4163 is:  nan\n",
      "The cosine similarity between the documents  0 and 4164 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4165 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4166 is:  nan\n",
      "The cosine similarity between the documents  0 and 4167 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4168 is:  nan\n",
      "The cosine similarity between the documents  0 and 4169 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4170 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4171 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4172 is:  nan\n",
      "The cosine similarity between the documents  0 and 4173 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4174 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4175 is:  nan\n",
      "The cosine similarity between the documents  0 and 4176 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4177 is:  nan\n",
      "The cosine similarity between the documents  0 and 4178 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4179 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4180 is:  nan\n",
      "The cosine similarity between the documents  0 and 4181 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4182 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4183 is:  nan\n",
      "The cosine similarity between the documents  0 and 4184 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4185 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4186 is:  nan\n",
      "The cosine similarity between the documents  0 and 4187 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4188 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4189 is:  nan\n",
      "The cosine similarity between the documents  0 and 4190 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4191 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4192 is:  nan\n",
      "The cosine similarity between the documents  0 and 4193 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4194 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4195 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4196 is:  nan\n",
      "The cosine similarity between the documents  0 and 4197 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4198 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4199 is:  nan\n",
      "The cosine similarity between the documents  0 and 4200 is:  nan\n",
      "The cosine similarity between the documents  0 and 4201 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4202 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4203 is:  nan\n",
      "The cosine similarity between the documents  0 and 4204 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4205 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4206 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4207 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4208 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4209 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4210 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4211 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4212 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4213 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4214 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4215 is:  nan\n",
      "The cosine similarity between the documents  0 and 4216 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4217 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4218 is:  nan\n",
      "The cosine similarity between the documents  0 and 4219 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4220 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4221 is:  nan\n",
      "The cosine similarity between the documents  0 and 4222 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4223 is:  nan\n",
      "The cosine similarity between the documents  0 and 4224 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4225 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4226 is:  nan\n",
      "The cosine similarity between the documents  0 and 4227 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4228 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4229 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4230 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4231 is:  nan\n",
      "The cosine similarity between the documents  0 and 4232 is:  nan\n",
      "The cosine similarity between the documents  0 and 4233 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4234 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4235 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4236 is:  nan\n",
      "The cosine similarity between the documents  0 and 4237 is:  nan\n",
      "The cosine similarity between the documents  0 and 4238 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4239 is:  nan\n",
      "The cosine similarity between the documents  0 and 4240 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4241 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4242 is:  nan\n",
      "The cosine similarity between the documents  0 and 4243 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4244 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4245 is:  nan\n",
      "The cosine similarity between the documents  0 and 4246 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4247 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4248 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4249 is:  nan\n",
      "The cosine similarity between the documents  0 and 4250 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4251 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4252 is:  nan\n",
      "The cosine similarity between the documents  0 and 4253 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4254 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4255 is:  nan\n",
      "The cosine similarity between the documents  0 and 4256 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4257 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4258 is:  nan\n",
      "The cosine similarity between the documents  0 and 4259 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4260 is:  nan\n",
      "The cosine similarity between the documents  0 and 4261 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4262 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4263 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4264 is:  nan\n",
      "The cosine similarity between the documents  0 and 4265 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4266 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4267 is:  nan\n",
      "The cosine similarity between the documents  0 and 4268 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4269 is:  nan\n",
      "The cosine similarity between the documents  0 and 4270 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4271 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4272 is:  nan\n",
      "The cosine similarity between the documents  0 and 4273 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4274 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4275 is:  nan\n",
      "The cosine similarity between the documents  0 and 4276 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4277 is:  nan\n",
      "The cosine similarity between the documents  0 and 4278 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4279 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4280 is:  nan\n",
      "The cosine similarity between the documents  0 and 4281 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4282 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4283 is:  nan\n",
      "The cosine similarity between the documents  0 and 4284 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4285 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4286 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4287 is:  nan\n",
      "The cosine similarity between the documents  0 and 4288 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4289 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4290 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4291 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4292 is:  nan\n",
      "The cosine similarity between the documents  0 and 4293 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4294 is:  nan\n",
      "The cosine similarity between the documents  0 and 4295 is:  nan\n",
      "The cosine similarity between the documents  0 and 4296 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4297 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4298 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4299 is:  nan\n",
      "The cosine similarity between the documents  0 and 4300 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4301 is:  nan\n",
      "The cosine similarity between the documents  0 and 4302 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4303 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4304 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4305 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4306 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4307 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4308 is:  nan\n",
      "The cosine similarity between the documents  0 and 4309 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4310 is:  nan\n",
      "The cosine similarity between the documents  0 and 4311 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4312 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4313 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4314 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4315 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4316 is:  nan\n",
      "The cosine similarity between the documents  0 and 4317 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4318 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4319 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4320 is:  nan\n",
      "The cosine similarity between the documents  0 and 4321 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4322 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4323 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4324 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4325 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4326 is:  nan\n",
      "The cosine similarity between the documents  0 and 4327 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4328 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4329 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4330 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4331 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4332 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4333 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4334 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4335 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4336 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4337 is:  nan\n",
      "The cosine similarity between the documents  0 and 4338 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4339 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4340 is:  nan\n",
      "The cosine similarity between the documents  0 and 4341 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4342 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4343 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4344 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4345 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4346 is:  nan\n",
      "The cosine similarity between the documents  0 and 4347 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4348 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4349 is:  nan\n",
      "The cosine similarity between the documents  0 and 4350 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4351 is:  nan\n",
      "The cosine similarity between the documents  0 and 4352 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4353 is:  nan\n",
      "The cosine similarity between the documents  0 and 4354 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4355 is:  nan\n",
      "The cosine similarity between the documents  0 and 4356 is:  nan\n",
      "The cosine similarity between the documents  0 and 4357 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4358 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4359 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4360 is:  nan\n",
      "The cosine similarity between the documents  0 and 4361 is:  nan\n",
      "The cosine similarity between the documents  0 and 4362 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4363 is:  nan\n",
      "The cosine similarity between the documents  0 and 4364 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4365 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4366 is:  nan\n",
      "The cosine similarity between the documents  0 and 4367 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4368 is:  nan\n",
      "The cosine similarity between the documents  0 and 4369 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4370 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4371 is:  nan\n",
      "The cosine similarity between the documents  0 and 4372 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4373 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4374 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4375 is:  nan\n",
      "The cosine similarity between the documents  0 and 4376 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4377 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4378 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4379 is:  nan\n",
      "The cosine similarity between the documents  0 and 4380 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4381 is:  nan\n",
      "The cosine similarity between the documents  0 and 4382 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4383 is:  nan\n",
      "The cosine similarity between the documents  0 and 4384 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4385 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4386 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4387 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4388 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4389 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4390 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4391 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4392 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4393 is:  nan\n",
      "The cosine similarity between the documents  0 and 4394 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4395 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4396 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4397 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4398 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4399 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4400 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4401 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4402 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4403 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4404 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4405 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4406 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4407 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4408 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4409 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4410 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4411 is:  nan\n",
      "The cosine similarity between the documents  0 and 4412 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4413 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4414 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4415 is:  nan\n",
      "The cosine similarity between the documents  0 and 4416 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4417 is:  nan\n",
      "The cosine similarity between the documents  0 and 4418 is:  nan\n",
      "The cosine similarity between the documents  0 and 4419 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4420 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4421 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4422 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4423 is:  nan\n",
      "The cosine similarity between the documents  0 and 4424 is:  nan\n",
      "The cosine similarity between the documents  0 and 4425 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4426 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4427 is:  nan\n",
      "The cosine similarity between the documents  0 and 4428 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4429 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4430 is:  nan\n",
      "The cosine similarity between the documents  0 and 4431 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4432 is:  nan\n",
      "The cosine similarity between the documents  0 and 4433 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4434 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4435 is:  nan\n",
      "The cosine similarity between the documents  0 and 4436 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4437 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4438 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4439 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4440 is:  nan\n",
      "The cosine similarity between the documents  0 and 4441 is:  nan\n",
      "The cosine similarity between the documents  0 and 4442 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4443 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4444 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4445 is:  nan\n",
      "The cosine similarity between the documents  0 and 4446 is:  nan\n",
      "The cosine similarity between the documents  0 and 4447 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4448 is:  nan\n",
      "The cosine similarity between the documents  0 and 4449 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4450 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4451 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4452 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4453 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4454 is:  nan\n",
      "The cosine similarity between the documents  0 and 4455 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4456 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4457 is:  nan\n",
      "The cosine similarity between the documents  0 and 4458 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4459 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4460 is:  nan\n",
      "The cosine similarity between the documents  0 and 4461 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4462 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4463 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4464 is:  nan\n",
      "The cosine similarity between the documents  0 and 4465 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4466 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4467 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4468 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4469 is:  nan\n",
      "The cosine similarity between the documents  0 and 4470 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4471 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4472 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4473 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4474 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4475 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4476 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4477 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4478 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4479 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4480 is:  nan\n",
      "The cosine similarity between the documents  0 and 4481 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4482 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4483 is:  nan\n",
      "The cosine similarity between the documents  0 and 4484 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4485 is:  nan\n",
      "The cosine similarity between the documents  0 and 4486 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4487 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4488 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4489 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4490 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4491 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4492 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4493 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4494 is:  nan\n",
      "The cosine similarity between the documents  0 and 4495 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4496 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4497 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4498 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4499 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4500 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4501 is:  nan\n",
      "The cosine similarity between the documents  0 and 4502 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4503 is:  nan\n",
      "The cosine similarity between the documents  0 and 4504 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4505 is:  nan\n",
      "The cosine similarity between the documents  0 and 4506 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4507 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4508 is:  nan\n",
      "The cosine similarity between the documents  0 and 4509 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4510 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4511 is:  nan\n",
      "The cosine similarity between the documents  0 and 4512 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4513 is:  nan\n",
      "The cosine similarity between the documents  0 and 4514 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4515 is:  nan\n",
      "The cosine similarity between the documents  0 and 4516 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4517 is:  nan\n",
      "The cosine similarity between the documents  0 and 4518 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4519 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4520 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4521 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4522 is:  nan\n",
      "The cosine similarity between the documents  0 and 4523 is:  nan\n",
      "The cosine similarity between the documents  0 and 4524 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4525 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4526 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4527 is:  nan\n",
      "The cosine similarity between the documents  0 and 4528 is:  nan\n",
      "The cosine similarity between the documents  0 and 4529 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4530 is:  nan\n",
      "The cosine similarity between the documents  0 and 4531 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4532 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4533 is:  nan\n",
      "The cosine similarity between the documents  0 and 4534 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4535 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4536 is:  nan\n",
      "The cosine similarity between the documents  0 and 4537 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4538 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4539 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4540 is:  nan\n",
      "The cosine similarity between the documents  0 and 4541 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4542 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4543 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4544 is:  nan\n",
      "The cosine similarity between the documents  0 and 4545 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4546 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4547 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4548 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4549 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4550 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4551 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4552 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4553 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4554 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4555 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4556 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4557 is:  nan\n",
      "The cosine similarity between the documents  0 and 4558 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4559 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4560 is:  nan\n",
      "The cosine similarity between the documents  0 and 4561 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4562 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4563 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4564 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4565 is:  nan\n",
      "The cosine similarity between the documents  0 and 4566 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4567 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4568 is:  nan\n",
      "The cosine similarity between the documents  0 and 4569 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4570 is:  nan\n",
      "The cosine similarity between the documents  0 and 4571 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4572 is:  nan\n",
      "The cosine similarity between the documents  0 and 4573 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4574 is:  nan\n",
      "The cosine similarity between the documents  0 and 4575 is:  nan\n",
      "The cosine similarity between the documents  0 and 4576 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4577 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4578 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4579 is:  nan\n",
      "The cosine similarity between the documents  0 and 4580 is:  nan\n",
      "The cosine similarity between the documents  0 and 4581 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4582 is:  nan\n",
      "The cosine similarity between the documents  0 and 4583 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4584 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4585 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4586 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4587 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4588 is:  nan\n",
      "The cosine similarity between the documents  0 and 4589 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4590 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4591 is:  nan\n",
      "The cosine similarity between the documents  0 and 4592 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4593 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4594 is:  nan\n",
      "The cosine similarity between the documents  0 and 4595 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4596 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4597 is:  nan\n",
      "The cosine similarity between the documents  0 and 4598 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4599 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4600 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4601 is:  nan\n",
      "The cosine similarity between the documents  0 and 4602 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4603 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4604 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4605 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4606 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4607 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4608 is:  nan\n",
      "The cosine similarity between the documents  0 and 4609 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4610 is:  nan\n",
      "The cosine similarity between the documents  0 and 4611 is:  nan\n",
      "The cosine similarity between the documents  0 and 4612 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4613 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4614 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4615 is:  nan\n",
      "The cosine similarity between the documents  0 and 4616 is:  nan\n",
      "The cosine similarity between the documents  0 and 4617 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4618 is:  nan\n",
      "The cosine similarity between the documents  0 and 4619 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4620 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4621 is:  nan\n",
      "The cosine similarity between the documents  0 and 4622 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4623 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4624 is:  nan\n",
      "The cosine similarity between the documents  0 and 4625 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4626 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4627 is:  nan\n",
      "The cosine similarity between the documents  0 and 4628 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4629 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4630 is:  nan\n",
      "The cosine similarity between the documents  0 and 4631 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4632 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4633 is:  nan\n",
      "The cosine similarity between the documents  0 and 4634 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4635 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4636 is:  nan\n",
      "The cosine similarity between the documents  0 and 4637 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4638 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4639 is:  nan\n",
      "The cosine similarity between the documents  0 and 4640 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4641 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4642 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4643 is:  nan\n",
      "The cosine similarity between the documents  0 and 4644 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4645 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4646 is:  nan\n",
      "The cosine similarity between the documents  0 and 4647 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4648 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4649 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4650 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4651 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4652 is:  nan\n",
      "The cosine similarity between the documents  0 and 4653 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4654 is:  nan\n",
      "The cosine similarity between the documents  0 and 4655 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4656 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4657 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4658 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4659 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4660 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4661 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4662 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4663 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4664 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4665 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4666 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4667 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4668 is:  nan\n",
      "The cosine similarity between the documents  0 and 4669 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4670 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4671 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4672 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4673 is:  nan\n",
      "The cosine similarity between the documents  0 and 4674 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4675 is:  nan\n",
      "The cosine similarity between the documents  0 and 4676 is:  nan\n",
      "The cosine similarity between the documents  0 and 4677 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4678 is:  nan\n",
      "The cosine similarity between the documents  0 and 4679 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4680 is:  nan\n",
      "The cosine similarity between the documents  0 and 4681 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4682 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4683 is:  nan\n",
      "The cosine similarity between the documents  0 and 4684 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4685 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4686 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4687 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4688 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4689 is:  nan\n",
      "The cosine similarity between the documents  0 and 4690 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4691 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4692 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4693 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4694 is:  nan\n",
      "The cosine similarity between the documents  0 and 4695 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4696 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4697 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4698 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4699 is:  nan\n",
      "The cosine similarity between the documents  0 and 4700 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4701 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4702 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4703 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4704 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4705 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4706 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4707 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4708 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4709 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4710 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4711 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4712 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4713 is:  nan\n",
      "The cosine similarity between the documents  0 and 4714 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4715 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4716 is:  nan\n",
      "The cosine similarity between the documents  0 and 4717 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4718 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4719 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4720 is:  nan\n",
      "The cosine similarity between the documents  0 and 4721 is:  nan\n",
      "The cosine similarity between the documents  0 and 4722 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4723 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4724 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4725 is:  nan\n",
      "The cosine similarity between the documents  0 and 4726 is:  nan\n",
      "The cosine similarity between the documents  0 and 4727 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4728 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4729 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4730 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4731 is:  nan\n",
      "The cosine similarity between the documents  0 and 4732 is:  nan\n",
      "The cosine similarity between the documents  0 and 4733 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4734 is:  nan\n",
      "The cosine similarity between the documents  0 and 4735 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4736 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4737 is:  nan\n",
      "The cosine similarity between the documents  0 and 4738 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4739 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4740 is:  nan\n",
      "The cosine similarity between the documents  0 and 4741 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4742 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4743 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4744 is:  nan\n",
      "The cosine similarity between the documents  0 and 4745 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4746 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4747 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4748 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4749 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4750 is:  nan\n",
      "The cosine similarity between the documents  0 and 4751 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4752 is:  nan\n",
      "The cosine similarity between the documents  0 and 4753 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4754 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4755 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4756 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4757 is:  nan\n",
      "The cosine similarity between the documents  0 and 4758 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4759 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4760 is:  nan\n",
      "The cosine similarity between the documents  0 and 4761 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4762 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4763 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4764 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4765 is:  nan\n",
      "The cosine similarity between the documents  0 and 4766 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4767 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4768 is:  nan\n",
      "The cosine similarity between the documents  0 and 4769 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4770 is:  nan\n",
      "The cosine similarity between the documents  0 and 4771 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4772 is:  nan\n",
      "The cosine similarity between the documents  0 and 4773 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4774 is:  nan\n",
      "The cosine similarity between the documents  0 and 4775 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4776 is:  nan\n",
      "The cosine similarity between the documents  0 and 4777 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4778 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4779 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4780 is:  nan\n",
      "The cosine similarity between the documents  0 and 4781 is:  nan\n",
      "The cosine similarity between the documents  0 and 4782 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4783 is:  nan\n",
      "The cosine similarity between the documents  0 and 4784 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4785 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4786 is:  nan\n",
      "The cosine similarity between the documents  0 and 4787 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4788 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4789 is:  nan\n",
      "The cosine similarity between the documents  0 and 4790 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4791 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4792 is:  nan\n",
      "The cosine similarity between the documents  0 and 4793 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4794 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4795 is:  nan\n",
      "The cosine similarity between the documents  0 and 4796 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4797 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4798 is:  nan\n",
      "The cosine similarity between the documents  0 and 4799 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4800 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4801 is:  nan\n",
      "The cosine similarity between the documents  0 and 4802 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4803 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4804 is:  nan\n",
      "The cosine similarity between the documents  0 and 4805 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4806 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4807 is:  nan\n",
      "The cosine similarity between the documents  0 and 4808 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4809 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4810 is:  nan\n",
      "The cosine similarity between the documents  0 and 4811 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4812 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4813 is:  nan\n",
      "The cosine similarity between the documents  0 and 4814 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4815 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4816 is:  nan\n",
      "The cosine similarity between the documents  0 and 4817 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4818 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4819 is:  nan\n",
      "The cosine similarity between the documents  0 and 4820 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4821 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4822 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4823 is:  nan\n",
      "The cosine similarity between the documents  0 and 4824 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4825 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4826 is:  nan\n",
      "The cosine similarity between the documents  0 and 4827 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4828 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4829 is:  nan\n",
      "The cosine similarity between the documents  0 and 4830 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4831 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4832 is:  nan\n",
      "The cosine similarity between the documents  0 and 4833 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4834 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4835 is:  nan\n",
      "The cosine similarity between the documents  0 and 4836 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4837 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4838 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4839 is:  nan\n",
      "The cosine similarity between the documents  0 and 4840 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4841 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4842 is:  nan\n",
      "The cosine similarity between the documents  0 and 4843 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4844 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4845 is:  nan\n",
      "The cosine similarity between the documents  0 and 4846 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4847 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4848 is:  nan\n",
      "The cosine similarity between the documents  0 and 4849 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4850 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4851 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4852 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4853 is:  nan\n",
      "The cosine similarity between the documents  0 and 4854 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4855 is:  nan\n",
      "The cosine similarity between the documents  0 and 4856 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4857 is:  nan\n",
      "The cosine similarity between the documents  0 and 4858 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4859 is:  nan\n",
      "The cosine similarity between the documents  0 and 4860 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4861 is:  nan\n",
      "The cosine similarity between the documents  0 and 4862 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4863 is:  nan\n",
      "The cosine similarity between the documents  0 and 4864 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4865 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4866 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4867 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4868 is:  nan\n",
      "The cosine similarity between the documents  0 and 4869 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4870 is:  nan\n",
      "The cosine similarity between the documents  0 and 4871 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4872 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4873 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4874 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4875 is:  nan\n",
      "The cosine similarity between the documents  0 and 4876 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4877 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4878 is:  nan\n",
      "The cosine similarity between the documents  0 and 4879 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4880 is:  nan\n",
      "The cosine similarity between the documents  0 and 4881 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4882 is:  nan\n",
      "The cosine similarity between the documents  0 and 4883 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4884 is:  nan\n",
      "The cosine similarity between the documents  0 and 4885 is:  nan\n",
      "The cosine similarity between the documents  0 and 4886 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4887 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4888 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4889 is:  nan\n",
      "The cosine similarity between the documents  0 and 4890 is:  nan\n",
      "The cosine similarity between the documents  0 and 4891 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4892 is:  nan\n",
      "The cosine similarity between the documents  0 and 4893 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4894 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4895 is:  nan\n",
      "The cosine similarity between the documents  0 and 4896 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4897 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4898 is:  nan\n",
      "The cosine similarity between the documents  0 and 4899 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4900 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4901 is:  nan\n",
      "The cosine similarity between the documents  0 and 4902 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4903 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4904 is:  nan\n",
      "The cosine similarity between the documents  0 and 4905 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4906 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4907 is:  nan\n",
      "The cosine similarity between the documents  0 and 4908 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4909 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4910 is:  nan\n",
      "The cosine similarity between the documents  0 and 4911 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4912 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4913 is:  nan\n",
      "The cosine similarity between the documents  0 and 4914 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4915 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4916 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4917 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4918 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4919 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4920 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4921 is:  nan\n",
      "The cosine similarity between the documents  0 and 4922 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4923 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4924 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4925 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4926 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4927 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4928 is:  nan\n",
      "The cosine similarity between the documents  0 and 4929 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4930 is:  nan\n",
      "The cosine similarity between the documents  0 and 4931 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4932 is:  nan\n",
      "The cosine similarity between the documents  0 and 4933 is:  nan\n",
      "The cosine similarity between the documents  0 and 4934 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4935 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4936 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4937 is:  nan\n",
      "The cosine similarity between the documents  0 and 4938 is:  nan\n",
      "The cosine similarity between the documents  0 and 4939 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4940 is:  nan\n",
      "The cosine similarity between the documents  0 and 4941 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4942 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4943 is:  nan\n",
      "The cosine similarity between the documents  0 and 4944 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4945 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4946 is:  nan\n",
      "The cosine similarity between the documents  0 and 4947 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4948 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4949 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4950 is:  nan\n",
      "The cosine similarity between the documents  0 and 4951 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4952 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4953 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4954 is:  nan\n",
      "The cosine similarity between the documents  0 and 4955 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4956 is:  nan\n",
      "The cosine similarity between the documents  0 and 4957 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4958 is:  nan\n",
      "The cosine similarity between the documents  0 and 4959 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4960 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4961 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4962 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4963 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4964 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4965 is:  nan\n",
      "The cosine similarity between the documents  0 and 4966 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4967 is:  nan\n",
      "The cosine similarity between the documents  0 and 4968 is:  nan\n",
      "The cosine similarity between the documents  0 and 4969 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4970 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4971 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4972 is:  nan\n",
      "The cosine similarity between the documents  0 and 4973 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4974 is:  nan\n",
      "The cosine similarity between the documents  0 and 4975 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4976 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4977 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4978 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4979 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4980 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4981 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 4982 is:  nan\n",
      "The cosine similarity between the documents  0 and 4983 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4984 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4985 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4986 is:  nan\n",
      "The cosine similarity between the documents  0 and 4987 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4988 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4989 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4990 is:  nan\n",
      "The cosine similarity between the documents  0 and 4991 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4992 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4993 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4994 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4995 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4996 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4997 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4998 is:  0.0\n",
      "The cosine similarity between the documents  0 and 4999 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5000 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5001 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5002 is:  nan\n",
      "The cosine similarity between the documents  0 and 5003 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5004 is:  nan\n",
      "The cosine similarity between the documents  0 and 5005 is:  nan\n",
      "The cosine similarity between the documents  0 and 5006 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5007 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5008 is:  nan\n",
      "The cosine similarity between the documents  0 and 5009 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5010 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5011 is:  nan\n",
      "The cosine similarity between the documents  0 and 5012 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5013 is:  nan\n",
      "The cosine similarity between the documents  0 and 5014 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5015 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5016 is:  nan\n",
      "The cosine similarity between the documents  0 and 5017 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5018 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5019 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5020 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5021 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5022 is:  nan\n",
      "The cosine similarity between the documents  0 and 5023 is:  nan\n",
      "The cosine similarity between the documents  0 and 5024 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5025 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5026 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5027 is:  nan\n",
      "The cosine similarity between the documents  0 and 5028 is:  nan\n",
      "The cosine similarity between the documents  0 and 5029 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5030 is:  nan\n",
      "The cosine similarity between the documents  0 and 5031 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5032 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5033 is:  nan\n",
      "The cosine similarity between the documents  0 and 5034 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5035 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5036 is:  nan\n",
      "The cosine similarity between the documents  0 and 5037 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5038 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5039 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5040 is:  nan\n",
      "The cosine similarity between the documents  0 and 5041 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5042 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5043 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5044 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5045 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5046 is:  nan\n",
      "The cosine similarity between the documents  0 and 5047 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5048 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5049 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5050 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5051 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5052 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5053 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5054 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5055 is:  nan\n",
      "The cosine similarity between the documents  0 and 5056 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5057 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5058 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5059 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5060 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5061 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5062 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5063 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5064 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5065 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5066 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5067 is:  nan\n",
      "The cosine similarity between the documents  0 and 5068 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5069 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5070 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5071 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5072 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5073 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5074 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5075 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5076 is:  nan\n",
      "The cosine similarity between the documents  0 and 5077 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5078 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5079 is:  nan\n",
      "The cosine similarity between the documents  0 and 5080 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5081 is:  nan\n",
      "The cosine similarity between the documents  0 and 5082 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5083 is:  nan\n",
      "The cosine similarity between the documents  0 and 5084 is:  nan\n",
      "The cosine similarity between the documents  0 and 5085 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5086 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5087 is:  nan\n",
      "The cosine similarity between the documents  0 and 5088 is:  nan\n",
      "The cosine similarity between the documents  0 and 5089 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5090 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5091 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5092 is:  nan\n",
      "The cosine similarity between the documents  0 and 5093 is:  nan\n",
      "The cosine similarity between the documents  0 and 5094 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5095 is:  nan\n",
      "The cosine similarity between the documents  0 and 5096 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5097 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5098 is:  nan\n",
      "The cosine similarity between the documents  0 and 5099 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5100 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5101 is:  nan\n",
      "The cosine similarity between the documents  0 and 5102 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5103 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5104 is:  nan\n",
      "The cosine similarity between the documents  0 and 5105 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5106 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5107 is:  nan\n",
      "The cosine similarity between the documents  0 and 5108 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5109 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5110 is:  nan\n",
      "The cosine similarity between the documents  0 and 5111 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5112 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5113 is:  nan\n",
      "The cosine similarity between the documents  0 and 5114 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 5115 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5116 is:  nan\n",
      "The cosine similarity between the documents  0 and 5117 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5118 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5119 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5120 is:  nan\n",
      "The cosine similarity between the documents  0 and 5121 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5122 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5123 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5124 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5125 is:  nan\n",
      "The cosine similarity between the documents  0 and 5126 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5127 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5128 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5129 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5130 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5131 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5132 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5133 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5134 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5135 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5136 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5137 is:  nan\n",
      "The cosine similarity between the documents  0 and 5138 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5139 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5140 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5141 is:  nan\n",
      "The cosine similarity between the documents  0 and 5142 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5143 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5144 is:  nan\n",
      "The cosine similarity between the documents  0 and 5145 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5146 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5147 is:  nan\n",
      "The cosine similarity between the documents  0 and 5148 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5149 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5150 is:  nan\n",
      "The cosine similarity between the documents  0 and 5151 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5152 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5153 is:  nan\n",
      "The cosine similarity between the documents  0 and 5154 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5155 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5156 is:  nan\n",
      "The cosine similarity between the documents  0 and 5157 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5158 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5159 is:  nan\n",
      "The cosine similarity between the documents  0 and 5160 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5161 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5162 is:  nan\n",
      "The cosine similarity between the documents  0 and 5163 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5164 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5165 is:  nan\n",
      "The cosine similarity between the documents  0 and 5166 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5167 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5168 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5169 is:  nan\n",
      "The cosine similarity between the documents  0 and 5170 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5171 is:  nan\n",
      "The cosine similarity between the documents  0 and 5172 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5173 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5174 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5175 is:  nan\n",
      "The cosine similarity between the documents  0 and 5176 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5177 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5178 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5179 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5180 is:  nan\n",
      "The cosine similarity between the documents  0 and 5181 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5182 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5183 is:  nan\n",
      "The cosine similarity between the documents  0 and 5184 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5185 is:  nan\n",
      "The cosine similarity between the documents  0 and 5186 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5187 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5188 is:  nan\n",
      "The cosine similarity between the documents  0 and 5189 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5190 is:  nan\n",
      "The cosine similarity between the documents  0 and 5191 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5192 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5193 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5194 is:  nan\n",
      "The cosine similarity between the documents  0 and 5195 is:  nan\n",
      "The cosine similarity between the documents  0 and 5196 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5197 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5198 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5199 is:  nan\n",
      "The cosine similarity between the documents  0 and 5200 is:  nan\n",
      "The cosine similarity between the documents  0 and 5201 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5202 is:  nan\n",
      "The cosine similarity between the documents  0 and 5203 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5204 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5205 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5206 is:  nan\n",
      "The cosine similarity between the documents  0 and 5207 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5208 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5209 is:  nan\n",
      "The cosine similarity between the documents  0 and 5210 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5211 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5212 is:  nan\n",
      "The cosine similarity between the documents  0 and 5213 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5214 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5215 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5216 is:  nan\n",
      "The cosine similarity between the documents  0 and 5217 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5218 is:  nan\n",
      "The cosine similarity between the documents  0 and 5219 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5220 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5221 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5222 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5223 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5224 is:  nan\n",
      "The cosine similarity between the documents  0 and 5225 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5226 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5227 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5228 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5229 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5230 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5231 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5232 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5233 is:  nan\n",
      "The cosine similarity between the documents  0 and 5234 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5235 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5236 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5237 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5238 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5239 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5240 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5241 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5242 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5243 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5244 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 5245 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5246 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5247 is:  nan\n",
      "The cosine similarity between the documents  0 and 5248 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5249 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5250 is:  nan\n",
      "The cosine similarity between the documents  0 and 5251 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5252 is:  nan\n",
      "The cosine similarity between the documents  0 and 5253 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5254 is:  nan\n",
      "The cosine similarity between the documents  0 and 5255 is:  nan\n",
      "The cosine similarity between the documents  0 and 5256 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5257 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5258 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5259 is:  nan\n",
      "The cosine similarity between the documents  0 and 5260 is:  nan\n",
      "The cosine similarity between the documents  0 and 5261 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5262 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5263 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5264 is:  nan\n",
      "The cosine similarity between the documents  0 and 5265 is:  nan\n",
      "The cosine similarity between the documents  0 and 5266 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5267 is:  nan\n",
      "The cosine similarity between the documents  0 and 5268 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5269 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5270 is:  nan\n",
      "The cosine similarity between the documents  0 and 5271 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5272 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5273 is:  nan\n",
      "The cosine similarity between the documents  0 and 5274 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5275 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5276 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5277 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5278 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5279 is:  nan\n",
      "The cosine similarity between the documents  0 and 5280 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5281 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5282 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5283 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5284 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5285 is:  nan\n",
      "The cosine similarity between the documents  0 and 5286 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5287 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5288 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5289 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5290 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5291 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5292 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5293 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5294 is:  nan\n",
      "The cosine similarity between the documents  0 and 5295 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5296 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5297 is:  nan\n",
      "The cosine similarity between the documents  0 and 5298 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5299 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5300 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5301 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5302 is:  nan\n",
      "The cosine similarity between the documents  0 and 5303 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5304 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5305 is:  nan\n",
      "The cosine similarity between the documents  0 and 5306 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5307 is:  nan\n",
      "The cosine similarity between the documents  0 and 5308 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5309 is:  nan\n",
      "The cosine similarity between the documents  0 and 5310 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5311 is:  nan\n",
      "The cosine similarity between the documents  0 and 5312 is:  nan\n",
      "The cosine similarity between the documents  0 and 5313 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5314 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5315 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5316 is:  nan\n",
      "The cosine similarity between the documents  0 and 5317 is:  nan\n",
      "The cosine similarity between the documents  0 and 5318 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5319 is:  nan\n",
      "The cosine similarity between the documents  0 and 5320 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5321 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5322 is:  nan\n",
      "The cosine similarity between the documents  0 and 5323 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5324 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5325 is:  nan\n",
      "The cosine similarity between the documents  0 and 5326 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5327 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5328 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5329 is:  nan\n",
      "The cosine similarity between the documents  0 and 5330 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5331 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5332 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5333 is:  nan\n",
      "The cosine similarity between the documents  0 and 5334 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5335 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5336 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5337 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5338 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5339 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5340 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5341 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5342 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5343 is:  nan\n",
      "The cosine similarity between the documents  0 and 5344 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5345 is:  nan\n",
      "The cosine similarity between the documents  0 and 5346 is:  nan\n",
      "The cosine similarity between the documents  0 and 5347 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5348 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5349 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5350 is:  nan\n",
      "The cosine similarity between the documents  0 and 5351 is:  nan\n",
      "The cosine similarity between the documents  0 and 5352 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5353 is:  nan\n",
      "The cosine similarity between the documents  0 and 5354 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5355 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5356 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5357 is:  nan\n",
      "The cosine similarity between the documents  0 and 5358 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5359 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5360 is:  nan\n",
      "The cosine similarity between the documents  0 and 5361 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5362 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5363 is:  nan\n",
      "The cosine similarity between the documents  0 and 5364 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5365 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5366 is:  nan\n",
      "The cosine similarity between the documents  0 and 5367 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5368 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5369 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5370 is:  nan\n",
      "The cosine similarity between the documents  0 and 5371 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5372 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5373 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5374 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5375 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5376 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5377 is:  nan\n",
      "The cosine similarity between the documents  0 and 5378 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  0 and 5379 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5380 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5381 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5382 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5383 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5384 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5385 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5386 is:  nan\n",
      "The cosine similarity between the documents  0 and 5387 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5388 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5389 is:  nan\n",
      "The cosine similarity between the documents  0 and 5390 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5391 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5392 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5393 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5394 is:  nan\n",
      "The cosine similarity between the documents  0 and 5395 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5396 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5397 is:  nan\n",
      "The cosine similarity between the documents  0 and 5398 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5399 is:  nan\n",
      "The cosine similarity between the documents  0 and 5400 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5401 is:  nan\n",
      "The cosine similarity between the documents  0 and 5402 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5403 is:  nan\n",
      "The cosine similarity between the documents  0 and 5404 is:  nan\n",
      "The cosine similarity between the documents  0 and 5405 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5406 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5407 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5408 is:  nan\n",
      "The cosine similarity between the documents  0 and 5409 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5410 is:  nan\n",
      "The cosine similarity between the documents  0 and 5411 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5412 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5413 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5414 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5415 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5416 is:  nan\n",
      "The cosine similarity between the documents  0 and 5417 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5418 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5419 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5420 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5421 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5422 is:  nan\n",
      "The cosine similarity between the documents  0 and 5423 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5424 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5425 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5426 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5427 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5428 is:  0.0\n",
      "The cosine similarity between the documents  0 and 5429 is:  nan\n",
      "The cosine similarity between the documents  1 and 2 is:  0.0\n",
      "The cosine similarity between the documents  1 and 3 is:  0.0\n",
      "The cosine similarity between the documents  1 and 4 is:  0.0\n",
      "The cosine similarity between the documents  1 and 5 is:  nan\n",
      "The cosine similarity between the documents  1 and 6 is:  0.0\n",
      "The cosine similarity between the documents  1 and 7 is:  0.0\n",
      "The cosine similarity between the documents  1 and 8 is:  0.0\n",
      "The cosine similarity between the documents  1 and 9 is:  0.0\n",
      "The cosine similarity between the documents  1 and 10 is:  0.0\n",
      "The cosine similarity between the documents  1 and 11 is:  0.0\n",
      "The cosine similarity between the documents  1 and 12 is:  0.0\n",
      "The cosine similarity between the documents  1 and 13 is:  0.0\n",
      "The cosine similarity between the documents  1 and 14 is:  0.0\n",
      "The cosine similarity between the documents  1 and 15 is:  0.0\n",
      "The cosine similarity between the documents  1 and 16 is:  0.0\n",
      "The cosine similarity between the documents  1 and 17 is:  nan\n",
      "The cosine similarity between the documents  1 and 18 is:  0.0\n",
      "The cosine similarity between the documents  1 and 19 is:  0.0\n",
      "The cosine similarity between the documents  1 and 20 is:  0.0\n",
      "The cosine similarity between the documents  1 and 21 is:  0.0\n",
      "The cosine similarity between the documents  1 and 22 is:  nan\n",
      "The cosine similarity between the documents  1 and 23 is:  0.0\n",
      "The cosine similarity between the documents  1 and 24 is:  0.0\n",
      "The cosine similarity between the documents  1 and 25 is:  nan\n",
      "The cosine similarity between the documents  1 and 26 is:  0.0\n",
      "The cosine similarity between the documents  1 and 27 is:  nan\n",
      "The cosine similarity between the documents  1 and 28 is:  0.0\n",
      "The cosine similarity between the documents  1 and 29 is:  nan\n",
      "The cosine similarity between the documents  1 and 30 is:  0.0\n",
      "The cosine similarity between the documents  1 and 31 is:  nan\n",
      "The cosine similarity between the documents  1 and 32 is:  0.0\n",
      "The cosine similarity between the documents  1 and 33 is:  0.0\n",
      "The cosine similarity between the documents  1 and 34 is:  0.0\n",
      "The cosine similarity between the documents  1 and 35 is:  0.0\n",
      "The cosine similarity between the documents  1 and 36 is:  0.0\n",
      "The cosine similarity between the documents  1 and 37 is:  0.0\n",
      "The cosine similarity between the documents  1 and 38 is:  0.0\n",
      "The cosine similarity between the documents  1 and 39 is:  0.0\n",
      "The cosine similarity between the documents  1 and 40 is:  0.0\n",
      "The cosine similarity between the documents  1 and 41 is:  0.0\n",
      "The cosine similarity between the documents  1 and 42 is:  0.0\n",
      "The cosine similarity between the documents  1 and 43 is:  0.0\n",
      "The cosine similarity between the documents  1 and 44 is:  0.0\n",
      "The cosine similarity between the documents  1 and 45 is:  0.0\n",
      "The cosine similarity between the documents  1 and 46 is:  nan\n",
      "The cosine similarity between the documents  1 and 47 is:  0.0\n",
      "The cosine similarity between the documents  1 and 48 is:  nan\n",
      "The cosine similarity between the documents  1 and 49 is:  0.0\n",
      "The cosine similarity between the documents  1 and 50 is:  nan\n",
      "The cosine similarity between the documents  1 and 51 is:  0.0\n",
      "The cosine similarity between the documents  1 and 52 is:  0.0\n",
      "The cosine similarity between the documents  1 and 53 is:  0.0\n",
      "The cosine similarity between the documents  1 and 54 is:  nan\n",
      "The cosine similarity between the documents  1 and 55 is:  0.0\n",
      "The cosine similarity between the documents  1 and 56 is:  0.0\n",
      "The cosine similarity between the documents  1 and 57 is:  0.0\n",
      "The cosine similarity between the documents  1 and 58 is:  0.0\n",
      "The cosine similarity between the documents  1 and 59 is:  0.0\n",
      "The cosine similarity between the documents  1 and 60 is:  0.0\n",
      "The cosine similarity between the documents  1 and 61 is:  0.0\n",
      "The cosine similarity between the documents  1 and 62 is:  0.0\n",
      "The cosine similarity between the documents  1 and 63 is:  0.0\n",
      "The cosine similarity between the documents  1 and 64 is:  0.0\n",
      "The cosine similarity between the documents  1 and 65 is:  nan\n",
      "The cosine similarity between the documents  1 and 66 is:  0.0\n",
      "The cosine similarity between the documents  1 and 67 is:  0.0\n",
      "The cosine similarity between the documents  1 and 68 is:  0.0\n",
      "The cosine similarity between the documents  1 and 69 is:  0.0\n",
      "The cosine similarity between the documents  1 and 70 is:  0.0\n",
      "The cosine similarity between the documents  1 and 71 is:  0.0\n",
      "The cosine similarity between the documents  1 and 72 is:  0.0\n",
      "The cosine similarity between the documents  1 and 73 is:  0.0\n",
      "The cosine similarity between the documents  1 and 74 is:  0.0\n",
      "The cosine similarity between the documents  1 and 75 is:  nan\n",
      "The cosine similarity between the documents  1 and 76 is:  nan\n",
      "The cosine similarity between the documents  1 and 77 is:  0.0\n",
      "The cosine similarity between the documents  1 and 78 is:  0.0\n",
      "The cosine similarity between the documents  1 and 79 is:  0.0\n",
      "The cosine similarity between the documents  1 and 80 is:  0.0\n",
      "The cosine similarity between the documents  1 and 81 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 82 is:  0.0\n",
      "The cosine similarity between the documents  1 and 83 is:  0.0\n",
      "The cosine similarity between the documents  1 and 84 is:  nan\n",
      "The cosine similarity between the documents  1 and 85 is:  0.0\n",
      "The cosine similarity between the documents  1 and 86 is:  0.0\n",
      "The cosine similarity between the documents  1 and 87 is:  0.0\n",
      "The cosine similarity between the documents  1 and 88 is:  0.0\n",
      "The cosine similarity between the documents  1 and 89 is:  0.0\n",
      "The cosine similarity between the documents  1 and 90 is:  0.0\n",
      "The cosine similarity between the documents  1 and 91 is:  0.0\n",
      "The cosine similarity between the documents  1 and 92 is:  0.0\n",
      "The cosine similarity between the documents  1 and 93 is:  0.0\n",
      "The cosine similarity between the documents  1 and 94 is:  0.0\n",
      "The cosine similarity between the documents  1 and 95 is:  0.0\n",
      "The cosine similarity between the documents  1 and 96 is:  0.0\n",
      "The cosine similarity between the documents  1 and 97 is:  0.0\n",
      "The cosine similarity between the documents  1 and 98 is:  nan\n",
      "The cosine similarity between the documents  1 and 99 is:  0.0\n",
      "The cosine similarity between the documents  1 and 100 is:  0.0\n",
      "The cosine similarity between the documents  1 and 101 is:  0.0\n",
      "The cosine similarity between the documents  1 and 102 is:  0.0\n",
      "The cosine similarity between the documents  1 and 103 is:  0.0\n",
      "The cosine similarity between the documents  1 and 104 is:  0.0\n",
      "The cosine similarity between the documents  1 and 105 is:  0.0\n",
      "The cosine similarity between the documents  1 and 106 is:  0.0\n",
      "The cosine similarity between the documents  1 and 107 is:  nan\n",
      "The cosine similarity between the documents  1 and 108 is:  0.0\n",
      "The cosine similarity between the documents  1 and 109 is:  0.0\n",
      "The cosine similarity between the documents  1 and 110 is:  0.0\n",
      "The cosine similarity between the documents  1 and 111 is:  0.0\n",
      "The cosine similarity between the documents  1 and 112 is:  nan\n",
      "The cosine similarity between the documents  1 and 113 is:  0.0\n",
      "The cosine similarity between the documents  1 and 114 is:  0.0\n",
      "The cosine similarity between the documents  1 and 115 is:  0.0\n",
      "The cosine similarity between the documents  1 and 116 is:  0.0\n",
      "The cosine similarity between the documents  1 and 117 is:  0.0\n",
      "The cosine similarity between the documents  1 and 118 is:  0.0\n",
      "The cosine similarity between the documents  1 and 119 is:  0.0\n",
      "The cosine similarity between the documents  1 and 120 is:  0.0\n",
      "The cosine similarity between the documents  1 and 121 is:  0.0\n",
      "The cosine similarity between the documents  1 and 122 is:  nan\n",
      "The cosine similarity between the documents  1 and 123 is:  0.0\n",
      "The cosine similarity between the documents  1 and 124 is:  0.0\n",
      "The cosine similarity between the documents  1 and 125 is:  0.0\n",
      "The cosine similarity between the documents  1 and 126 is:  0.0\n",
      "The cosine similarity between the documents  1 and 127 is:  0.0\n",
      "The cosine similarity between the documents  1 and 128 is:  0.0\n",
      "The cosine similarity between the documents  1 and 129 is:  0.0\n",
      "The cosine similarity between the documents  1 and 130 is:  0.0\n",
      "The cosine similarity between the documents  1 and 131 is:  0.0\n",
      "The cosine similarity between the documents  1 and 132 is:  0.0\n",
      "The cosine similarity between the documents  1 and 133 is:  0.0\n",
      "The cosine similarity between the documents  1 and 134 is:  0.0\n",
      "The cosine similarity between the documents  1 and 135 is:  0.0\n",
      "The cosine similarity between the documents  1 and 136 is:  0.0\n",
      "The cosine similarity between the documents  1 and 137 is:  0.0\n",
      "The cosine similarity between the documents  1 and 138 is:  0.0\n",
      "The cosine similarity between the documents  1 and 139 is:  0.0\n",
      "The cosine similarity between the documents  1 and 140 is:  0.0\n",
      "The cosine similarity between the documents  1 and 141 is:  0.0\n",
      "The cosine similarity between the documents  1 and 142 is:  0.0\n",
      "The cosine similarity between the documents  1 and 143 is:  0.0\n",
      "The cosine similarity between the documents  1 and 144 is:  0.0\n",
      "The cosine similarity between the documents  1 and 145 is:  0.0\n",
      "The cosine similarity between the documents  1 and 146 is:  nan\n",
      "The cosine similarity between the documents  1 and 147 is:  0.0\n",
      "The cosine similarity between the documents  1 and 148 is:  0.0\n",
      "The cosine similarity between the documents  1 and 149 is:  0.0\n",
      "The cosine similarity between the documents  1 and 150 is:  nan\n",
      "The cosine similarity between the documents  1 and 151 is:  nan\n",
      "The cosine similarity between the documents  1 and 152 is:  0.0\n",
      "The cosine similarity between the documents  1 and 153 is:  nan\n",
      "The cosine similarity between the documents  1 and 154 is:  nan\n",
      "The cosine similarity between the documents  1 and 155 is:  0.0\n",
      "The cosine similarity between the documents  1 and 156 is:  nan\n",
      "The cosine similarity between the documents  1 and 157 is:  0.0\n",
      "The cosine similarity between the documents  1 and 158 is:  0.0\n",
      "The cosine similarity between the documents  1 and 159 is:  0.0\n",
      "The cosine similarity between the documents  1 and 160 is:  0.0\n",
      "The cosine similarity between the documents  1 and 161 is:  0.0\n",
      "The cosine similarity between the documents  1 and 162 is:  0.0\n",
      "The cosine similarity between the documents  1 and 163 is:  nan\n",
      "The cosine similarity between the documents  1 and 164 is:  0.0\n",
      "The cosine similarity between the documents  1 and 165 is:  nan\n",
      "The cosine similarity between the documents  1 and 166 is:  nan\n",
      "The cosine similarity between the documents  1 and 167 is:  0.0\n",
      "The cosine similarity between the documents  1 and 168 is:  0.0\n",
      "The cosine similarity between the documents  1 and 169 is:  0.0\n",
      "The cosine similarity between the documents  1 and 170 is:  0.0\n",
      "The cosine similarity between the documents  1 and 171 is:  0.0\n",
      "The cosine similarity between the documents  1 and 172 is:  0.0\n",
      "The cosine similarity between the documents  1 and 173 is:  0.0\n",
      "The cosine similarity between the documents  1 and 174 is:  nan\n",
      "The cosine similarity between the documents  1 and 175 is:  0.0\n",
      "The cosine similarity between the documents  1 and 176 is:  nan\n",
      "The cosine similarity between the documents  1 and 177 is:  0.0\n",
      "The cosine similarity between the documents  1 and 178 is:  nan\n",
      "The cosine similarity between the documents  1 and 179 is:  0.0\n",
      "The cosine similarity between the documents  1 and 180 is:  0.0\n",
      "The cosine similarity between the documents  1 and 181 is:  0.0\n",
      "The cosine similarity between the documents  1 and 182 is:  0.0\n",
      "The cosine similarity between the documents  1 and 183 is:  0.0\n",
      "The cosine similarity between the documents  1 and 184 is:  0.0\n",
      "The cosine similarity between the documents  1 and 185 is:  0.0\n",
      "The cosine similarity between the documents  1 and 186 is:  nan\n",
      "The cosine similarity between the documents  1 and 187 is:  0.0\n",
      "The cosine similarity between the documents  1 and 188 is:  0.0\n",
      "The cosine similarity between the documents  1 and 189 is:  nan\n",
      "The cosine similarity between the documents  1 and 190 is:  0.0\n",
      "The cosine similarity between the documents  1 and 191 is:  0.0\n",
      "The cosine similarity between the documents  1 and 192 is:  0.0\n",
      "The cosine similarity between the documents  1 and 193 is:  0.0\n",
      "The cosine similarity between the documents  1 and 194 is:  0.0\n",
      "The cosine similarity between the documents  1 and 195 is:  1.0\n",
      "The cosine similarity between the documents  1 and 196 is:  0.0\n",
      "The cosine similarity between the documents  1 and 197 is:  0.0\n",
      "The cosine similarity between the documents  1 and 198 is:  0.0\n",
      "The cosine similarity between the documents  1 and 199 is:  0.0\n",
      "The cosine similarity between the documents  1 and 200 is:  0.0\n",
      "The cosine similarity between the documents  1 and 201 is:  0.0\n",
      "The cosine similarity between the documents  1 and 202 is:  0.0\n",
      "The cosine similarity between the documents  1 and 203 is:  0.0\n",
      "The cosine similarity between the documents  1 and 204 is:  0.0\n",
      "The cosine similarity between the documents  1 and 205 is:  0.0\n",
      "The cosine similarity between the documents  1 and 206 is:  0.0\n",
      "The cosine similarity between the documents  1 and 207 is:  0.0\n",
      "The cosine similarity between the documents  1 and 208 is:  0.0\n",
      "The cosine similarity between the documents  1 and 209 is:  0.0\n",
      "The cosine similarity between the documents  1 and 210 is:  0.0\n",
      "The cosine similarity between the documents  1 and 211 is:  0.0\n",
      "The cosine similarity between the documents  1 and 212 is:  0.0\n",
      "The cosine similarity between the documents  1 and 213 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 214 is:  0.0\n",
      "The cosine similarity between the documents  1 and 215 is:  0.0\n",
      "The cosine similarity between the documents  1 and 216 is:  0.0\n",
      "The cosine similarity between the documents  1 and 217 is:  0.0\n",
      "The cosine similarity between the documents  1 and 218 is:  0.0\n",
      "The cosine similarity between the documents  1 and 219 is:  0.0\n",
      "The cosine similarity between the documents  1 and 220 is:  0.0\n",
      "The cosine similarity between the documents  1 and 221 is:  0.0\n",
      "The cosine similarity between the documents  1 and 222 is:  0.0\n",
      "The cosine similarity between the documents  1 and 223 is:  0.0\n",
      "The cosine similarity between the documents  1 and 224 is:  nan\n",
      "The cosine similarity between the documents  1 and 225 is:  0.0\n",
      "The cosine similarity between the documents  1 and 226 is:  0.0\n",
      "The cosine similarity between the documents  1 and 227 is:  0.0\n",
      "The cosine similarity between the documents  1 and 228 is:  0.0\n",
      "The cosine similarity between the documents  1 and 229 is:  nan\n",
      "The cosine similarity between the documents  1 and 230 is:  0.0\n",
      "The cosine similarity between the documents  1 and 231 is:  nan\n",
      "The cosine similarity between the documents  1 and 232 is:  0.0\n",
      "The cosine similarity between the documents  1 and 233 is:  nan\n",
      "The cosine similarity between the documents  1 and 234 is:  0.0\n",
      "The cosine similarity between the documents  1 and 235 is:  nan\n",
      "The cosine similarity between the documents  1 and 236 is:  0.0\n",
      "The cosine similarity between the documents  1 and 237 is:  nan\n",
      "The cosine similarity between the documents  1 and 238 is:  0.0\n",
      "The cosine similarity between the documents  1 and 239 is:  0.0\n",
      "The cosine similarity between the documents  1 and 240 is:  0.0\n",
      "The cosine similarity between the documents  1 and 241 is:  0.0\n",
      "The cosine similarity between the documents  1 and 242 is:  nan\n",
      "The cosine similarity between the documents  1 and 243 is:  0.0\n",
      "The cosine similarity between the documents  1 and 244 is:  0.0\n",
      "The cosine similarity between the documents  1 and 245 is:  0.0\n",
      "The cosine similarity between the documents  1 and 246 is:  nan\n",
      "The cosine similarity between the documents  1 and 247 is:  0.0\n",
      "The cosine similarity between the documents  1 and 248 is:  0.0\n",
      "The cosine similarity between the documents  1 and 249 is:  0.0\n",
      "The cosine similarity between the documents  1 and 250 is:  nan\n",
      "The cosine similarity between the documents  1 and 251 is:  nan\n",
      "The cosine similarity between the documents  1 and 252 is:  0.0\n",
      "The cosine similarity between the documents  1 and 253 is:  nan\n",
      "The cosine similarity between the documents  1 and 254 is:  nan\n",
      "The cosine similarity between the documents  1 and 255 is:  0.0\n",
      "The cosine similarity between the documents  1 and 256 is:  0.0\n",
      "The cosine similarity between the documents  1 and 257 is:  0.0\n",
      "The cosine similarity between the documents  1 and 258 is:  0.0\n",
      "The cosine similarity between the documents  1 and 259 is:  0.0\n",
      "The cosine similarity between the documents  1 and 260 is:  nan\n",
      "The cosine similarity between the documents  1 and 261 is:  0.0\n",
      "The cosine similarity between the documents  1 and 262 is:  0.0\n",
      "The cosine similarity between the documents  1 and 263 is:  0.0\n",
      "The cosine similarity between the documents  1 and 264 is:  0.0\n",
      "The cosine similarity between the documents  1 and 265 is:  0.0\n",
      "The cosine similarity between the documents  1 and 266 is:  0.0\n",
      "The cosine similarity between the documents  1 and 267 is:  0.0\n",
      "The cosine similarity between the documents  1 and 268 is:  0.0\n",
      "The cosine similarity between the documents  1 and 269 is:  0.0\n",
      "The cosine similarity between the documents  1 and 270 is:  0.0\n",
      "The cosine similarity between the documents  1 and 271 is:  0.0\n",
      "The cosine similarity between the documents  1 and 272 is:  0.0\n",
      "The cosine similarity between the documents  1 and 273 is:  0.0\n",
      "The cosine similarity between the documents  1 and 274 is:  0.0\n",
      "The cosine similarity between the documents  1 and 275 is:  0.0\n",
      "The cosine similarity between the documents  1 and 276 is:  nan\n",
      "The cosine similarity between the documents  1 and 277 is:  0.0\n",
      "The cosine similarity between the documents  1 and 278 is:  nan\n",
      "The cosine similarity between the documents  1 and 279 is:  0.0\n",
      "The cosine similarity between the documents  1 and 280 is:  0.0\n",
      "The cosine similarity between the documents  1 and 281 is:  0.0\n",
      "The cosine similarity between the documents  1 and 282 is:  0.0\n",
      "The cosine similarity between the documents  1 and 283 is:  0.0\n",
      "The cosine similarity between the documents  1 and 284 is:  0.0\n",
      "The cosine similarity between the documents  1 and 285 is:  0.0\n",
      "The cosine similarity between the documents  1 and 286 is:  0.0\n",
      "The cosine similarity between the documents  1 and 287 is:  0.0\n",
      "The cosine similarity between the documents  1 and 288 is:  0.0\n",
      "The cosine similarity between the documents  1 and 289 is:  0.0\n",
      "The cosine similarity between the documents  1 and 290 is:  0.0\n",
      "The cosine similarity between the documents  1 and 291 is:  0.0\n",
      "The cosine similarity between the documents  1 and 292 is:  0.0\n",
      "The cosine similarity between the documents  1 and 293 is:  0.0\n",
      "The cosine similarity between the documents  1 and 294 is:  0.0\n",
      "The cosine similarity between the documents  1 and 295 is:  nan\n",
      "The cosine similarity between the documents  1 and 296 is:  0.0\n",
      "The cosine similarity between the documents  1 and 297 is:  0.0\n",
      "The cosine similarity between the documents  1 and 298 is:  0.0\n",
      "The cosine similarity between the documents  1 and 299 is:  0.0\n",
      "The cosine similarity between the documents  1 and 300 is:  0.0\n",
      "The cosine similarity between the documents  1 and 301 is:  nan\n",
      "The cosine similarity between the documents  1 and 302 is:  0.0\n",
      "The cosine similarity between the documents  1 and 303 is:  0.0\n",
      "The cosine similarity between the documents  1 and 304 is:  nan\n",
      "The cosine similarity between the documents  1 and 305 is:  0.0\n",
      "The cosine similarity between the documents  1 and 306 is:  0.0\n",
      "The cosine similarity between the documents  1 and 307 is:  0.0\n",
      "The cosine similarity between the documents  1 and 308 is:  0.0\n",
      "The cosine similarity between the documents  1 and 309 is:  0.0\n",
      "The cosine similarity between the documents  1 and 310 is:  nan\n",
      "The cosine similarity between the documents  1 and 311 is:  0.0\n",
      "The cosine similarity between the documents  1 and 312 is:  0.0\n",
      "The cosine similarity between the documents  1 and 313 is:  0.0\n",
      "The cosine similarity between the documents  1 and 314 is:  nan\n",
      "The cosine similarity between the documents  1 and 315 is:  0.0\n",
      "The cosine similarity between the documents  1 and 316 is:  0.0\n",
      "The cosine similarity between the documents  1 and 317 is:  0.0\n",
      "The cosine similarity between the documents  1 and 318 is:  0.0\n",
      "The cosine similarity between the documents  1 and 319 is:  0.0\n",
      "The cosine similarity between the documents  1 and 320 is:  nan\n",
      "The cosine similarity between the documents  1 and 321 is:  0.0\n",
      "The cosine similarity between the documents  1 and 322 is:  nan\n",
      "The cosine similarity between the documents  1 and 323 is:  0.0\n",
      "The cosine similarity between the documents  1 and 324 is:  0.0\n",
      "The cosine similarity between the documents  1 and 325 is:  0.0\n",
      "The cosine similarity between the documents  1 and 326 is:  0.0\n",
      "The cosine similarity between the documents  1 and 327 is:  nan\n",
      "The cosine similarity between the documents  1 and 328 is:  0.0\n",
      "The cosine similarity between the documents  1 and 329 is:  0.0\n",
      "The cosine similarity between the documents  1 and 330 is:  0.0\n",
      "The cosine similarity between the documents  1 and 331 is:  0.0\n",
      "The cosine similarity between the documents  1 and 332 is:  nan\n",
      "The cosine similarity between the documents  1 and 333 is:  0.0\n",
      "The cosine similarity between the documents  1 and 334 is:  0.0\n",
      "The cosine similarity between the documents  1 and 335 is:  0.0\n",
      "The cosine similarity between the documents  1 and 336 is:  0.0\n",
      "The cosine similarity between the documents  1 and 337 is:  0.0\n",
      "The cosine similarity between the documents  1 and 338 is:  0.0\n",
      "The cosine similarity between the documents  1 and 339 is:  0.0\n",
      "The cosine similarity between the documents  1 and 340 is:  0.0\n",
      "The cosine similarity between the documents  1 and 341 is:  0.0\n",
      "The cosine similarity between the documents  1 and 342 is:  0.0\n",
      "The cosine similarity between the documents  1 and 343 is:  0.0\n",
      "The cosine similarity between the documents  1 and 344 is:  0.0\n",
      "The cosine similarity between the documents  1 and 345 is:  0.0\n",
      "The cosine similarity between the documents  1 and 346 is:  0.0\n",
      "The cosine similarity between the documents  1 and 347 is:  0.0\n",
      "The cosine similarity between the documents  1 and 348 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 349 is:  nan\n",
      "The cosine similarity between the documents  1 and 350 is:  0.0\n",
      "The cosine similarity between the documents  1 and 351 is:  0.0\n",
      "The cosine similarity between the documents  1 and 352 is:  0.0\n",
      "The cosine similarity between the documents  1 and 353 is:  0.0\n",
      "The cosine similarity between the documents  1 and 354 is:  0.0\n",
      "The cosine similarity between the documents  1 and 355 is:  0.0\n",
      "The cosine similarity between the documents  1 and 356 is:  0.0\n",
      "The cosine similarity between the documents  1 and 357 is:  0.0\n",
      "The cosine similarity between the documents  1 and 358 is:  0.0\n",
      "The cosine similarity between the documents  1 and 359 is:  0.0\n",
      "The cosine similarity between the documents  1 and 360 is:  0.0\n",
      "The cosine similarity between the documents  1 and 361 is:  0.0\n",
      "The cosine similarity between the documents  1 and 362 is:  0.0\n",
      "The cosine similarity between the documents  1 and 363 is:  0.0\n",
      "The cosine similarity between the documents  1 and 364 is:  0.0\n",
      "The cosine similarity between the documents  1 and 365 is:  0.0\n",
      "The cosine similarity between the documents  1 and 366 is:  0.0\n",
      "The cosine similarity between the documents  1 and 367 is:  0.0\n",
      "The cosine similarity between the documents  1 and 368 is:  0.0\n",
      "The cosine similarity between the documents  1 and 369 is:  0.0\n",
      "The cosine similarity between the documents  1 and 370 is:  0.0\n",
      "The cosine similarity between the documents  1 and 371 is:  0.0\n",
      "The cosine similarity between the documents  1 and 372 is:  0.0\n",
      "The cosine similarity between the documents  1 and 373 is:  0.0\n",
      "The cosine similarity between the documents  1 and 374 is:  0.0\n",
      "The cosine similarity between the documents  1 and 375 is:  0.0\n",
      "The cosine similarity between the documents  1 and 376 is:  nan\n",
      "The cosine similarity between the documents  1 and 377 is:  0.0\n",
      "The cosine similarity between the documents  1 and 378 is:  0.0\n",
      "The cosine similarity between the documents  1 and 379 is:  0.0\n",
      "The cosine similarity between the documents  1 and 380 is:  nan\n",
      "The cosine similarity between the documents  1 and 381 is:  nan\n",
      "The cosine similarity between the documents  1 and 382 is:  0.0\n",
      "The cosine similarity between the documents  1 and 383 is:  nan\n",
      "The cosine similarity between the documents  1 and 384 is:  0.0\n",
      "The cosine similarity between the documents  1 and 385 is:  nan\n",
      "The cosine similarity between the documents  1 and 386 is:  0.0\n",
      "The cosine similarity between the documents  1 and 387 is:  0.0\n",
      "The cosine similarity between the documents  1 and 388 is:  0.0\n",
      "The cosine similarity between the documents  1 and 389 is:  nan\n",
      "The cosine similarity between the documents  1 and 390 is:  nan\n",
      "The cosine similarity between the documents  1 and 391 is:  0.0\n",
      "The cosine similarity between the documents  1 and 392 is:  nan\n",
      "The cosine similarity between the documents  1 and 393 is:  nan\n",
      "The cosine similarity between the documents  1 and 394 is:  0.0\n",
      "The cosine similarity between the documents  1 and 395 is:  0.0\n",
      "The cosine similarity between the documents  1 and 396 is:  0.0\n",
      "The cosine similarity between the documents  1 and 397 is:  0.0\n",
      "The cosine similarity between the documents  1 and 398 is:  0.0\n",
      "The cosine similarity between the documents  1 and 399 is:  0.0\n",
      "The cosine similarity between the documents  1 and 400 is:  0.0\n",
      "The cosine similarity between the documents  1 and 401 is:  0.0\n",
      "The cosine similarity between the documents  1 and 402 is:  0.0\n",
      "The cosine similarity between the documents  1 and 403 is:  0.0\n",
      "The cosine similarity between the documents  1 and 404 is:  0.0\n",
      "The cosine similarity between the documents  1 and 405 is:  0.0\n",
      "The cosine similarity between the documents  1 and 406 is:  0.0\n",
      "The cosine similarity between the documents  1 and 407 is:  0.0\n",
      "The cosine similarity between the documents  1 and 408 is:  0.0\n",
      "The cosine similarity between the documents  1 and 409 is:  nan\n",
      "The cosine similarity between the documents  1 and 410 is:  0.0\n",
      "The cosine similarity between the documents  1 and 411 is:  0.0\n",
      "The cosine similarity between the documents  1 and 412 is:  0.0\n",
      "The cosine similarity between the documents  1 and 413 is:  0.0\n",
      "The cosine similarity between the documents  1 and 414 is:  0.0\n",
      "The cosine similarity between the documents  1 and 415 is:  0.0\n",
      "The cosine similarity between the documents  1 and 416 is:  0.0\n",
      "The cosine similarity between the documents  1 and 417 is:  0.0\n",
      "The cosine similarity between the documents  1 and 418 is:  0.0\n",
      "The cosine similarity between the documents  1 and 419 is:  0.0\n",
      "The cosine similarity between the documents  1 and 420 is:  0.0\n",
      "The cosine similarity between the documents  1 and 421 is:  0.0\n",
      "The cosine similarity between the documents  1 and 422 is:  0.0\n",
      "The cosine similarity between the documents  1 and 423 is:  0.0\n",
      "The cosine similarity between the documents  1 and 424 is:  0.0\n",
      "The cosine similarity between the documents  1 and 425 is:  0.0\n",
      "The cosine similarity between the documents  1 and 426 is:  0.0\n",
      "The cosine similarity between the documents  1 and 427 is:  0.0\n",
      "The cosine similarity between the documents  1 and 428 is:  0.0\n",
      "The cosine similarity between the documents  1 and 429 is:  nan\n",
      "The cosine similarity between the documents  1 and 430 is:  0.0\n",
      "The cosine similarity between the documents  1 and 431 is:  0.0\n",
      "The cosine similarity between the documents  1 and 432 is:  0.0\n",
      "The cosine similarity between the documents  1 and 433 is:  0.0\n",
      "The cosine similarity between the documents  1 and 434 is:  0.0\n",
      "The cosine similarity between the documents  1 and 435 is:  0.0\n",
      "The cosine similarity between the documents  1 and 436 is:  0.0\n",
      "The cosine similarity between the documents  1 and 437 is:  0.0\n",
      "The cosine similarity between the documents  1 and 438 is:  0.0\n",
      "The cosine similarity between the documents  1 and 439 is:  0.0\n",
      "The cosine similarity between the documents  1 and 440 is:  0.0\n",
      "The cosine similarity between the documents  1 and 441 is:  0.0\n",
      "The cosine similarity between the documents  1 and 442 is:  0.0\n",
      "The cosine similarity between the documents  1 and 443 is:  0.0\n",
      "The cosine similarity between the documents  1 and 444 is:  0.0\n",
      "The cosine similarity between the documents  1 and 445 is:  nan\n",
      "The cosine similarity between the documents  1 and 446 is:  0.0\n",
      "The cosine similarity between the documents  1 and 447 is:  0.0\n",
      "The cosine similarity between the documents  1 and 448 is:  0.0\n",
      "The cosine similarity between the documents  1 and 449 is:  0.0\n",
      "The cosine similarity between the documents  1 and 450 is:  0.0\n",
      "The cosine similarity between the documents  1 and 451 is:  0.0\n",
      "The cosine similarity between the documents  1 and 452 is:  0.0\n",
      "The cosine similarity between the documents  1 and 453 is:  0.0\n",
      "The cosine similarity between the documents  1 and 454 is:  0.0\n",
      "The cosine similarity between the documents  1 and 455 is:  0.0\n",
      "The cosine similarity between the documents  1 and 456 is:  0.0\n",
      "The cosine similarity between the documents  1 and 457 is:  nan\n",
      "The cosine similarity between the documents  1 and 458 is:  0.0\n",
      "The cosine similarity between the documents  1 and 459 is:  nan\n",
      "The cosine similarity between the documents  1 and 460 is:  0.0\n",
      "The cosine similarity between the documents  1 and 461 is:  0.0\n",
      "The cosine similarity between the documents  1 and 462 is:  0.0\n",
      "The cosine similarity between the documents  1 and 463 is:  nan\n",
      "The cosine similarity between the documents  1 and 464 is:  nan\n",
      "The cosine similarity between the documents  1 and 465 is:  0.0\n",
      "The cosine similarity between the documents  1 and 466 is:  nan\n",
      "The cosine similarity between the documents  1 and 467 is:  0.0\n",
      "The cosine similarity between the documents  1 and 468 is:  0.0\n",
      "The cosine similarity between the documents  1 and 469 is:  0.0\n",
      "The cosine similarity between the documents  1 and 470 is:  nan\n",
      "The cosine similarity between the documents  1 and 471 is:  nan\n",
      "The cosine similarity between the documents  1 and 472 is:  0.0\n",
      "The cosine similarity between the documents  1 and 473 is:  nan\n",
      "The cosine similarity between the documents  1 and 474 is:  0.0\n",
      "The cosine similarity between the documents  1 and 475 is:  0.0\n",
      "The cosine similarity between the documents  1 and 476 is:  0.0\n",
      "The cosine similarity between the documents  1 and 477 is:  0.0\n",
      "The cosine similarity between the documents  1 and 478 is:  0.0\n",
      "The cosine similarity between the documents  1 and 479 is:  0.0\n",
      "The cosine similarity between the documents  1 and 480 is:  0.0\n",
      "The cosine similarity between the documents  1 and 481 is:  0.0\n",
      "The cosine similarity between the documents  1 and 482 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 483 is:  0.0\n",
      "The cosine similarity between the documents  1 and 484 is:  0.0\n",
      "The cosine similarity between the documents  1 and 485 is:  0.0\n",
      "The cosine similarity between the documents  1 and 486 is:  0.0\n",
      "The cosine similarity between the documents  1 and 487 is:  0.0\n",
      "The cosine similarity between the documents  1 and 488 is:  nan\n",
      "The cosine similarity between the documents  1 and 489 is:  0.0\n",
      "The cosine similarity between the documents  1 and 490 is:  0.0\n",
      "The cosine similarity between the documents  1 and 491 is:  0.0\n",
      "The cosine similarity between the documents  1 and 492 is:  0.0\n",
      "The cosine similarity between the documents  1 and 493 is:  0.0\n",
      "The cosine similarity between the documents  1 and 494 is:  0.0\n",
      "The cosine similarity between the documents  1 and 495 is:  0.0\n",
      "The cosine similarity between the documents  1 and 496 is:  0.0\n",
      "The cosine similarity between the documents  1 and 497 is:  0.0\n",
      "The cosine similarity between the documents  1 and 498 is:  nan\n",
      "The cosine similarity between the documents  1 and 499 is:  0.0\n",
      "The cosine similarity between the documents  1 and 500 is:  0.0\n",
      "The cosine similarity between the documents  1 and 501 is:  0.0\n",
      "The cosine similarity between the documents  1 and 502 is:  0.0\n",
      "The cosine similarity between the documents  1 and 503 is:  0.0\n",
      "The cosine similarity between the documents  1 and 504 is:  0.0\n",
      "The cosine similarity between the documents  1 and 505 is:  0.0\n",
      "The cosine similarity between the documents  1 and 506 is:  0.0\n",
      "The cosine similarity between the documents  1 and 507 is:  0.0\n",
      "The cosine similarity between the documents  1 and 508 is:  0.0\n",
      "The cosine similarity between the documents  1 and 509 is:  0.0\n",
      "The cosine similarity between the documents  1 and 510 is:  0.0\n",
      "The cosine similarity between the documents  1 and 511 is:  0.0\n",
      "The cosine similarity between the documents  1 and 512 is:  nan\n",
      "The cosine similarity between the documents  1 and 513 is:  0.0\n",
      "The cosine similarity between the documents  1 and 514 is:  nan\n",
      "The cosine similarity between the documents  1 and 515 is:  nan\n",
      "The cosine similarity between the documents  1 and 516 is:  nan\n",
      "The cosine similarity between the documents  1 and 517 is:  0.0\n",
      "The cosine similarity between the documents  1 and 518 is:  0.0\n",
      "The cosine similarity between the documents  1 and 519 is:  0.0\n",
      "The cosine similarity between the documents  1 and 520 is:  0.0\n",
      "The cosine similarity between the documents  1 and 521 is:  0.0\n",
      "The cosine similarity between the documents  1 and 522 is:  0.0\n",
      "The cosine similarity between the documents  1 and 523 is:  0.0\n",
      "The cosine similarity between the documents  1 and 524 is:  0.0\n",
      "The cosine similarity between the documents  1 and 525 is:  0.0\n",
      "The cosine similarity between the documents  1 and 526 is:  0.0\n",
      "The cosine similarity between the documents  1 and 527 is:  0.0\n",
      "The cosine similarity between the documents  1 and 528 is:  0.0\n",
      "The cosine similarity between the documents  1 and 529 is:  0.0\n",
      "The cosine similarity between the documents  1 and 530 is:  0.0\n",
      "The cosine similarity between the documents  1 and 531 is:  0.0\n",
      "The cosine similarity between the documents  1 and 532 is:  0.0\n",
      "The cosine similarity between the documents  1 and 533 is:  0.0\n",
      "The cosine similarity between the documents  1 and 534 is:  0.0\n",
      "The cosine similarity between the documents  1 and 535 is:  0.0\n",
      "The cosine similarity between the documents  1 and 536 is:  0.0\n",
      "The cosine similarity between the documents  1 and 537 is:  0.0\n",
      "The cosine similarity between the documents  1 and 538 is:  0.0\n",
      "The cosine similarity between the documents  1 and 539 is:  0.0\n",
      "The cosine similarity between the documents  1 and 540 is:  0.0\n",
      "The cosine similarity between the documents  1 and 541 is:  0.0\n",
      "The cosine similarity between the documents  1 and 542 is:  0.0\n",
      "The cosine similarity between the documents  1 and 543 is:  0.0\n",
      "The cosine similarity between the documents  1 and 544 is:  nan\n",
      "The cosine similarity between the documents  1 and 545 is:  0.0\n",
      "The cosine similarity between the documents  1 and 546 is:  0.0\n",
      "The cosine similarity between the documents  1 and 547 is:  0.0\n",
      "The cosine similarity between the documents  1 and 548 is:  0.0\n",
      "The cosine similarity between the documents  1 and 549 is:  0.0\n",
      "The cosine similarity between the documents  1 and 550 is:  0.0\n",
      "The cosine similarity between the documents  1 and 551 is:  nan\n",
      "The cosine similarity between the documents  1 and 552 is:  0.0\n",
      "The cosine similarity between the documents  1 and 553 is:  0.0\n",
      "The cosine similarity between the documents  1 and 554 is:  0.0\n",
      "The cosine similarity between the documents  1 and 555 is:  nan\n",
      "The cosine similarity between the documents  1 and 556 is:  0.0\n",
      "The cosine similarity between the documents  1 and 557 is:  0.0\n",
      "The cosine similarity between the documents  1 and 558 is:  0.0\n",
      "The cosine similarity between the documents  1 and 559 is:  0.0\n",
      "The cosine similarity between the documents  1 and 560 is:  0.0\n",
      "The cosine similarity between the documents  1 and 561 is:  0.0\n",
      "The cosine similarity between the documents  1 and 562 is:  0.0\n",
      "The cosine similarity between the documents  1 and 563 is:  0.0\n",
      "The cosine similarity between the documents  1 and 564 is:  0.0\n",
      "The cosine similarity between the documents  1 and 565 is:  0.0\n",
      "The cosine similarity between the documents  1 and 566 is:  0.0\n",
      "The cosine similarity between the documents  1 and 567 is:  0.0\n",
      "The cosine similarity between the documents  1 and 568 is:  0.0\n",
      "The cosine similarity between the documents  1 and 569 is:  0.0\n",
      "The cosine similarity between the documents  1 and 570 is:  nan\n",
      "The cosine similarity between the documents  1 and 571 is:  0.0\n",
      "The cosine similarity between the documents  1 and 572 is:  0.0\n",
      "The cosine similarity between the documents  1 and 573 is:  0.0\n",
      "The cosine similarity between the documents  1 and 574 is:  0.0\n",
      "The cosine similarity between the documents  1 and 575 is:  0.0\n",
      "The cosine similarity between the documents  1 and 576 is:  0.0\n",
      "The cosine similarity between the documents  1 and 577 is:  0.0\n",
      "The cosine similarity between the documents  1 and 578 is:  0.0\n",
      "The cosine similarity between the documents  1 and 579 is:  0.0\n",
      "The cosine similarity between the documents  1 and 580 is:  nan\n",
      "The cosine similarity between the documents  1 and 581 is:  0.0\n",
      "The cosine similarity between the documents  1 and 582 is:  0.0\n",
      "The cosine similarity between the documents  1 and 583 is:  0.0\n",
      "The cosine similarity between the documents  1 and 584 is:  0.0\n",
      "The cosine similarity between the documents  1 and 585 is:  0.0\n",
      "The cosine similarity between the documents  1 and 586 is:  0.0\n",
      "The cosine similarity between the documents  1 and 587 is:  nan\n",
      "The cosine similarity between the documents  1 and 588 is:  0.0\n",
      "The cosine similarity between the documents  1 and 589 is:  0.0\n",
      "The cosine similarity between the documents  1 and 590 is:  0.0\n",
      "The cosine similarity between the documents  1 and 591 is:  nan\n",
      "The cosine similarity between the documents  1 and 592 is:  0.0\n",
      "The cosine similarity between the documents  1 and 593 is:  0.0\n",
      "The cosine similarity between the documents  1 and 594 is:  nan\n",
      "The cosine similarity between the documents  1 and 595 is:  0.0\n",
      "The cosine similarity between the documents  1 and 596 is:  0.0\n",
      "The cosine similarity between the documents  1 and 597 is:  0.0\n",
      "The cosine similarity between the documents  1 and 598 is:  nan\n",
      "The cosine similarity between the documents  1 and 599 is:  0.0\n",
      "The cosine similarity between the documents  1 and 600 is:  0.0\n",
      "The cosine similarity between the documents  1 and 601 is:  nan\n",
      "The cosine similarity between the documents  1 and 602 is:  0.0\n",
      "The cosine similarity between the documents  1 and 603 is:  nan\n",
      "The cosine similarity between the documents  1 and 604 is:  0.0\n",
      "The cosine similarity between the documents  1 and 605 is:  nan\n",
      "The cosine similarity between the documents  1 and 606 is:  0.0\n",
      "The cosine similarity between the documents  1 and 607 is:  0.0\n",
      "The cosine similarity between the documents  1 and 608 is:  0.0\n",
      "The cosine similarity between the documents  1 and 609 is:  0.0\n",
      "The cosine similarity between the documents  1 and 610 is:  0.0\n",
      "The cosine similarity between the documents  1 and 611 is:  0.0\n",
      "The cosine similarity between the documents  1 and 612 is:  nan\n",
      "The cosine similarity between the documents  1 and 613 is:  0.0\n",
      "The cosine similarity between the documents  1 and 614 is:  0.0\n",
      "The cosine similarity between the documents  1 and 615 is:  0.0\n",
      "The cosine similarity between the documents  1 and 616 is:  0.0\n",
      "The cosine similarity between the documents  1 and 617 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 618 is:  0.0\n",
      "The cosine similarity between the documents  1 and 619 is:  0.0\n",
      "The cosine similarity between the documents  1 and 620 is:  0.0\n",
      "The cosine similarity between the documents  1 and 621 is:  0.0\n",
      "The cosine similarity between the documents  1 and 622 is:  nan\n",
      "The cosine similarity between the documents  1 and 623 is:  0.0\n",
      "The cosine similarity between the documents  1 and 624 is:  0.0\n",
      "The cosine similarity between the documents  1 and 625 is:  0.0\n",
      "The cosine similarity between the documents  1 and 626 is:  0.0\n",
      "The cosine similarity between the documents  1 and 627 is:  0.0\n",
      "The cosine similarity between the documents  1 and 628 is:  0.0\n",
      "The cosine similarity between the documents  1 and 629 is:  0.0\n",
      "The cosine similarity between the documents  1 and 630 is:  0.0\n",
      "The cosine similarity between the documents  1 and 631 is:  0.0\n",
      "The cosine similarity between the documents  1 and 632 is:  0.0\n",
      "The cosine similarity between the documents  1 and 633 is:  0.0\n",
      "The cosine similarity between the documents  1 and 634 is:  0.0\n",
      "The cosine similarity between the documents  1 and 635 is:  nan\n",
      "The cosine similarity between the documents  1 and 636 is:  0.0\n",
      "The cosine similarity between the documents  1 and 637 is:  nan\n",
      "The cosine similarity between the documents  1 and 638 is:  0.0\n",
      "The cosine similarity between the documents  1 and 639 is:  0.0\n",
      "The cosine similarity between the documents  1 and 640 is:  0.0\n",
      "The cosine similarity between the documents  1 and 641 is:  0.0\n",
      "The cosine similarity between the documents  1 and 642 is:  0.0\n",
      "The cosine similarity between the documents  1 and 643 is:  0.0\n",
      "The cosine similarity between the documents  1 and 644 is:  0.0\n",
      "The cosine similarity between the documents  1 and 645 is:  0.0\n",
      "The cosine similarity between the documents  1 and 646 is:  0.0\n",
      "The cosine similarity between the documents  1 and 647 is:  nan\n",
      "The cosine similarity between the documents  1 and 648 is:  0.0\n",
      "The cosine similarity between the documents  1 and 649 is:  0.0\n",
      "The cosine similarity between the documents  1 and 650 is:  0.0\n",
      "The cosine similarity between the documents  1 and 651 is:  0.0\n",
      "The cosine similarity between the documents  1 and 652 is:  0.0\n",
      "The cosine similarity between the documents  1 and 653 is:  0.0\n",
      "The cosine similarity between the documents  1 and 654 is:  0.0\n",
      "The cosine similarity between the documents  1 and 655 is:  0.0\n",
      "The cosine similarity between the documents  1 and 656 is:  0.0\n",
      "The cosine similarity between the documents  1 and 657 is:  0.0\n",
      "The cosine similarity between the documents  1 and 658 is:  0.0\n",
      "The cosine similarity between the documents  1 and 659 is:  0.0\n",
      "The cosine similarity between the documents  1 and 660 is:  nan\n",
      "The cosine similarity between the documents  1 and 661 is:  0.0\n",
      "The cosine similarity between the documents  1 and 662 is:  nan\n",
      "The cosine similarity between the documents  1 and 663 is:  0.0\n",
      "The cosine similarity between the documents  1 and 664 is:  0.0\n",
      "The cosine similarity between the documents  1 and 665 is:  0.0\n",
      "The cosine similarity between the documents  1 and 666 is:  0.0\n",
      "The cosine similarity between the documents  1 and 667 is:  0.0\n",
      "The cosine similarity between the documents  1 and 668 is:  nan\n",
      "The cosine similarity between the documents  1 and 669 is:  0.0\n",
      "The cosine similarity between the documents  1 and 670 is:  0.0\n",
      "The cosine similarity between the documents  1 and 671 is:  0.0\n",
      "The cosine similarity between the documents  1 and 672 is:  0.0\n",
      "The cosine similarity between the documents  1 and 673 is:  0.0\n",
      "The cosine similarity between the documents  1 and 674 is:  0.0\n",
      "The cosine similarity between the documents  1 and 675 is:  nan\n",
      "The cosine similarity between the documents  1 and 676 is:  nan\n",
      "The cosine similarity between the documents  1 and 677 is:  0.0\n",
      "The cosine similarity between the documents  1 and 678 is:  0.0\n",
      "The cosine similarity between the documents  1 and 679 is:  0.0\n",
      "The cosine similarity between the documents  1 and 680 is:  0.0\n",
      "The cosine similarity between the documents  1 and 681 is:  0.0\n",
      "The cosine similarity between the documents  1 and 682 is:  0.0\n",
      "The cosine similarity between the documents  1 and 683 is:  0.0\n",
      "The cosine similarity between the documents  1 and 684 is:  0.0\n",
      "The cosine similarity between the documents  1 and 685 is:  nan\n",
      "The cosine similarity between the documents  1 and 686 is:  nan\n",
      "The cosine similarity between the documents  1 and 687 is:  0.0\n",
      "The cosine similarity between the documents  1 and 688 is:  nan\n",
      "The cosine similarity between the documents  1 and 689 is:  0.0\n",
      "The cosine similarity between the documents  1 and 690 is:  0.0\n",
      "The cosine similarity between the documents  1 and 691 is:  0.0\n",
      "The cosine similarity between the documents  1 and 692 is:  0.0\n",
      "The cosine similarity between the documents  1 and 693 is:  0.0\n",
      "The cosine similarity between the documents  1 and 694 is:  0.0\n",
      "The cosine similarity between the documents  1 and 695 is:  0.0\n",
      "The cosine similarity between the documents  1 and 696 is:  0.0\n",
      "The cosine similarity between the documents  1 and 697 is:  0.0\n",
      "The cosine similarity between the documents  1 and 698 is:  0.0\n",
      "The cosine similarity between the documents  1 and 699 is:  0.0\n",
      "The cosine similarity between the documents  1 and 700 is:  0.0\n",
      "The cosine similarity between the documents  1 and 701 is:  0.0\n",
      "The cosine similarity between the documents  1 and 702 is:  0.0\n",
      "The cosine similarity between the documents  1 and 703 is:  0.0\n",
      "The cosine similarity between the documents  1 and 704 is:  0.0\n",
      "The cosine similarity between the documents  1 and 705 is:  nan\n",
      "The cosine similarity between the documents  1 and 706 is:  0.0\n",
      "The cosine similarity between the documents  1 and 707 is:  0.0\n",
      "The cosine similarity between the documents  1 and 708 is:  0.0\n",
      "The cosine similarity between the documents  1 and 709 is:  0.0\n",
      "The cosine similarity between the documents  1 and 710 is:  0.0\n",
      "The cosine similarity between the documents  1 and 711 is:  0.0\n",
      "The cosine similarity between the documents  1 and 712 is:  nan\n",
      "The cosine similarity between the documents  1 and 713 is:  0.0\n",
      "The cosine similarity between the documents  1 and 714 is:  0.0\n",
      "The cosine similarity between the documents  1 and 715 is:  nan\n",
      "The cosine similarity between the documents  1 and 716 is:  0.0\n",
      "The cosine similarity between the documents  1 and 717 is:  0.0\n",
      "The cosine similarity between the documents  1 and 718 is:  0.0\n",
      "The cosine similarity between the documents  1 and 719 is:  0.0\n",
      "The cosine similarity between the documents  1 and 720 is:  0.0\n",
      "The cosine similarity between the documents  1 and 721 is:  0.0\n",
      "The cosine similarity between the documents  1 and 722 is:  0.0\n",
      "The cosine similarity between the documents  1 and 723 is:  0.0\n",
      "The cosine similarity between the documents  1 and 724 is:  0.0\n",
      "The cosine similarity between the documents  1 and 725 is:  0.0\n",
      "The cosine similarity between the documents  1 and 726 is:  0.0\n",
      "The cosine similarity between the documents  1 and 727 is:  0.0\n",
      "The cosine similarity between the documents  1 and 728 is:  nan\n",
      "The cosine similarity between the documents  1 and 729 is:  nan\n",
      "The cosine similarity between the documents  1 and 730 is:  0.0\n",
      "The cosine similarity between the documents  1 and 731 is:  0.0\n",
      "The cosine similarity between the documents  1 and 732 is:  0.0\n",
      "The cosine similarity between the documents  1 and 733 is:  nan\n",
      "The cosine similarity between the documents  1 and 734 is:  0.0\n",
      "The cosine similarity between the documents  1 and 735 is:  0.0\n",
      "The cosine similarity between the documents  1 and 736 is:  0.0\n",
      "The cosine similarity between the documents  1 and 737 is:  0.0\n",
      "The cosine similarity between the documents  1 and 738 is:  0.0\n",
      "The cosine similarity between the documents  1 and 739 is:  0.0\n",
      "The cosine similarity between the documents  1 and 740 is:  0.0\n",
      "The cosine similarity between the documents  1 and 741 is:  0.0\n",
      "The cosine similarity between the documents  1 and 742 is:  0.0\n",
      "The cosine similarity between the documents  1 and 743 is:  0.0\n",
      "The cosine similarity between the documents  1 and 744 is:  0.0\n",
      "The cosine similarity between the documents  1 and 745 is:  0.0\n",
      "The cosine similarity between the documents  1 and 746 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 747 is:  0.0\n",
      "The cosine similarity between the documents  1 and 748 is:  0.0\n",
      "The cosine similarity between the documents  1 and 749 is:  0.0\n",
      "The cosine similarity between the documents  1 and 750 is:  0.0\n",
      "The cosine similarity between the documents  1 and 751 is:  0.0\n",
      "The cosine similarity between the documents  1 and 752 is:  0.0\n",
      "The cosine similarity between the documents  1 and 753 is:  0.0\n",
      "The cosine similarity between the documents  1 and 754 is:  nan\n",
      "The cosine similarity between the documents  1 and 755 is:  0.0\n",
      "The cosine similarity between the documents  1 and 756 is:  0.0\n",
      "The cosine similarity between the documents  1 and 757 is:  nan\n",
      "The cosine similarity between the documents  1 and 758 is:  nan\n",
      "The cosine similarity between the documents  1 and 759 is:  0.0\n",
      "The cosine similarity between the documents  1 and 760 is:  nan\n",
      "The cosine similarity between the documents  1 and 761 is:  0.0\n",
      "The cosine similarity between the documents  1 and 762 is:  0.0\n",
      "The cosine similarity between the documents  1 and 763 is:  0.0\n",
      "The cosine similarity between the documents  1 and 764 is:  nan\n",
      "The cosine similarity between the documents  1 and 765 is:  nan\n",
      "The cosine similarity between the documents  1 and 766 is:  0.0\n",
      "The cosine similarity between the documents  1 and 767 is:  nan\n",
      "The cosine similarity between the documents  1 and 768 is:  0.0\n",
      "The cosine similarity between the documents  1 and 769 is:  0.0\n",
      "The cosine similarity between the documents  1 and 770 is:  0.0\n",
      "The cosine similarity between the documents  1 and 771 is:  0.0\n",
      "The cosine similarity between the documents  1 and 772 is:  nan\n",
      "The cosine similarity between the documents  1 and 773 is:  0.0\n",
      "The cosine similarity between the documents  1 and 774 is:  0.0\n",
      "The cosine similarity between the documents  1 and 775 is:  0.0\n",
      "The cosine similarity between the documents  1 and 776 is:  nan\n",
      "The cosine similarity between the documents  1 and 777 is:  0.0\n",
      "The cosine similarity between the documents  1 and 778 is:  0.0\n",
      "The cosine similarity between the documents  1 and 779 is:  0.0\n",
      "The cosine similarity between the documents  1 and 780 is:  0.0\n",
      "The cosine similarity between the documents  1 and 781 is:  0.0\n",
      "The cosine similarity between the documents  1 and 782 is:  nan\n",
      "The cosine similarity between the documents  1 and 783 is:  0.0\n",
      "The cosine similarity between the documents  1 and 784 is:  0.0\n",
      "The cosine similarity between the documents  1 and 785 is:  0.0\n",
      "The cosine similarity between the documents  1 and 786 is:  0.0\n",
      "The cosine similarity between the documents  1 and 787 is:  0.0\n",
      "The cosine similarity between the documents  1 and 788 is:  0.0\n",
      "The cosine similarity between the documents  1 and 789 is:  0.0\n",
      "The cosine similarity between the documents  1 and 790 is:  0.0\n",
      "The cosine similarity between the documents  1 and 791 is:  0.0\n",
      "The cosine similarity between the documents  1 and 792 is:  0.0\n",
      "The cosine similarity between the documents  1 and 793 is:  0.0\n",
      "The cosine similarity between the documents  1 and 794 is:  0.0\n",
      "The cosine similarity between the documents  1 and 795 is:  nan\n",
      "The cosine similarity between the documents  1 and 796 is:  0.0\n",
      "The cosine similarity between the documents  1 and 797 is:  0.0\n",
      "The cosine similarity between the documents  1 and 798 is:  nan\n",
      "The cosine similarity between the documents  1 and 799 is:  nan\n",
      "The cosine similarity between the documents  1 and 800 is:  0.0\n",
      "The cosine similarity between the documents  1 and 801 is:  0.0\n",
      "The cosine similarity between the documents  1 and 802 is:  nan\n",
      "The cosine similarity between the documents  1 and 803 is:  0.0\n",
      "The cosine similarity between the documents  1 and 804 is:  nan\n",
      "The cosine similarity between the documents  1 and 805 is:  0.0\n",
      "The cosine similarity between the documents  1 and 806 is:  nan\n",
      "The cosine similarity between the documents  1 and 807 is:  0.0\n",
      "The cosine similarity between the documents  1 and 808 is:  0.0\n",
      "The cosine similarity between the documents  1 and 809 is:  nan\n",
      "The cosine similarity between the documents  1 and 810 is:  0.0\n",
      "The cosine similarity between the documents  1 and 811 is:  nan\n",
      "The cosine similarity between the documents  1 and 812 is:  nan\n",
      "The cosine similarity between the documents  1 and 813 is:  0.0\n",
      "The cosine similarity between the documents  1 and 814 is:  nan\n",
      "The cosine similarity between the documents  1 and 815 is:  0.0\n",
      "The cosine similarity between the documents  1 and 816 is:  0.0\n",
      "The cosine similarity between the documents  1 and 817 is:  nan\n",
      "The cosine similarity between the documents  1 and 818 is:  0.0\n",
      "The cosine similarity between the documents  1 and 819 is:  nan\n",
      "The cosine similarity between the documents  1 and 820 is:  0.0\n",
      "The cosine similarity between the documents  1 and 821 is:  0.0\n",
      "The cosine similarity between the documents  1 and 822 is:  0.0\n",
      "The cosine similarity between the documents  1 and 823 is:  nan\n",
      "The cosine similarity between the documents  1 and 824 is:  0.0\n",
      "The cosine similarity between the documents  1 and 825 is:  nan\n",
      "The cosine similarity between the documents  1 and 826 is:  0.0\n",
      "The cosine similarity between the documents  1 and 827 is:  0.0\n",
      "The cosine similarity between the documents  1 and 828 is:  0.0\n",
      "The cosine similarity between the documents  1 and 829 is:  0.0\n",
      "The cosine similarity between the documents  1 and 830 is:  0.0\n",
      "The cosine similarity between the documents  1 and 831 is:  0.0\n",
      "The cosine similarity between the documents  1 and 832 is:  0.0\n",
      "The cosine similarity between the documents  1 and 833 is:  0.0\n",
      "The cosine similarity between the documents  1 and 834 is:  nan\n",
      "The cosine similarity between the documents  1 and 835 is:  0.0\n",
      "The cosine similarity between the documents  1 and 836 is:  0.0\n",
      "The cosine similarity between the documents  1 and 837 is:  nan\n",
      "The cosine similarity between the documents  1 and 838 is:  0.0\n",
      "The cosine similarity between the documents  1 and 839 is:  0.0\n",
      "The cosine similarity between the documents  1 and 840 is:  0.0\n",
      "The cosine similarity between the documents  1 and 841 is:  0.0\n",
      "The cosine similarity between the documents  1 and 842 is:  0.0\n",
      "The cosine similarity between the documents  1 and 843 is:  0.0\n",
      "The cosine similarity between the documents  1 and 844 is:  0.0\n",
      "The cosine similarity between the documents  1 and 845 is:  0.0\n",
      "The cosine similarity between the documents  1 and 846 is:  0.0\n",
      "The cosine similarity between the documents  1 and 847 is:  0.0\n",
      "The cosine similarity between the documents  1 and 848 is:  0.0\n",
      "The cosine similarity between the documents  1 and 849 is:  0.0\n",
      "The cosine similarity between the documents  1 and 850 is:  0.0\n",
      "The cosine similarity between the documents  1 and 851 is:  nan\n",
      "The cosine similarity between the documents  1 and 852 is:  0.0\n",
      "The cosine similarity between the documents  1 and 853 is:  0.0\n",
      "The cosine similarity between the documents  1 and 854 is:  0.0\n",
      "The cosine similarity between the documents  1 and 855 is:  0.0\n",
      "The cosine similarity between the documents  1 and 856 is:  nan\n",
      "The cosine similarity between the documents  1 and 857 is:  0.0\n",
      "The cosine similarity between the documents  1 and 858 is:  0.0\n",
      "The cosine similarity between the documents  1 and 859 is:  0.0\n",
      "The cosine similarity between the documents  1 and 860 is:  nan\n",
      "The cosine similarity between the documents  1 and 861 is:  nan\n",
      "The cosine similarity between the documents  1 and 862 is:  0.0\n",
      "The cosine similarity between the documents  1 and 863 is:  nan\n",
      "The cosine similarity between the documents  1 and 864 is:  0.0\n",
      "The cosine similarity between the documents  1 and 865 is:  0.0\n",
      "The cosine similarity between the documents  1 and 866 is:  0.0\n",
      "The cosine similarity between the documents  1 and 867 is:  nan\n",
      "The cosine similarity between the documents  1 and 868 is:  nan\n",
      "The cosine similarity between the documents  1 and 869 is:  0.0\n",
      "The cosine similarity between the documents  1 and 870 is:  nan\n",
      "The cosine similarity between the documents  1 and 871 is:  0.0\n",
      "The cosine similarity between the documents  1 and 872 is:  0.0\n",
      "The cosine similarity between the documents  1 and 873 is:  0.0\n",
      "The cosine similarity between the documents  1 and 874 is:  0.0\n",
      "The cosine similarity between the documents  1 and 875 is:  0.0\n",
      "The cosine similarity between the documents  1 and 876 is:  0.0\n",
      "The cosine similarity between the documents  1 and 877 is:  0.0\n",
      "The cosine similarity between the documents  1 and 878 is:  0.0\n",
      "The cosine similarity between the documents  1 and 879 is:  0.0\n",
      "The cosine similarity between the documents  1 and 880 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 881 is:  0.0\n",
      "The cosine similarity between the documents  1 and 882 is:  nan\n",
      "The cosine similarity between the documents  1 and 883 is:  0.0\n",
      "The cosine similarity between the documents  1 and 884 is:  0.0\n",
      "The cosine similarity between the documents  1 and 885 is:  nan\n",
      "The cosine similarity between the documents  1 and 886 is:  nan\n",
      "The cosine similarity between the documents  1 and 887 is:  nan\n",
      "The cosine similarity between the documents  1 and 888 is:  0.0\n",
      "The cosine similarity between the documents  1 and 889 is:  0.0\n",
      "The cosine similarity between the documents  1 and 890 is:  0.0\n",
      "The cosine similarity between the documents  1 and 891 is:  nan\n",
      "The cosine similarity between the documents  1 and 892 is:  nan\n",
      "The cosine similarity between the documents  1 and 893 is:  0.0\n",
      "The cosine similarity between the documents  1 and 894 is:  nan\n",
      "The cosine similarity between the documents  1 and 895 is:  0.0\n",
      "The cosine similarity between the documents  1 and 896 is:  0.0\n",
      "The cosine similarity between the documents  1 and 897 is:  0.0\n",
      "The cosine similarity between the documents  1 and 898 is:  nan\n",
      "The cosine similarity between the documents  1 and 899 is:  0.0\n",
      "The cosine similarity between the documents  1 and 900 is:  0.0\n",
      "The cosine similarity between the documents  1 and 901 is:  0.0\n",
      "The cosine similarity between the documents  1 and 902 is:  0.0\n",
      "The cosine similarity between the documents  1 and 903 is:  nan\n",
      "The cosine similarity between the documents  1 and 904 is:  0.0\n",
      "The cosine similarity between the documents  1 and 905 is:  0.0\n",
      "The cosine similarity between the documents  1 and 906 is:  0.0\n",
      "The cosine similarity between the documents  1 and 907 is:  0.0\n",
      "The cosine similarity between the documents  1 and 908 is:  nan\n",
      "The cosine similarity between the documents  1 and 909 is:  0.0\n",
      "The cosine similarity between the documents  1 and 910 is:  0.0\n",
      "The cosine similarity between the documents  1 and 911 is:  0.0\n",
      "The cosine similarity between the documents  1 and 912 is:  nan\n",
      "The cosine similarity between the documents  1 and 913 is:  nan\n",
      "The cosine similarity between the documents  1 and 914 is:  0.0\n",
      "The cosine similarity between the documents  1 and 915 is:  nan\n",
      "The cosine similarity between the documents  1 and 916 is:  0.0\n",
      "The cosine similarity between the documents  1 and 917 is:  0.0\n",
      "The cosine similarity between the documents  1 and 918 is:  0.0\n",
      "The cosine similarity between the documents  1 and 919 is:  0.0\n",
      "The cosine similarity between the documents  1 and 920 is:  0.0\n",
      "The cosine similarity between the documents  1 and 921 is:  nan\n",
      "The cosine similarity between the documents  1 and 922 is:  0.0\n",
      "The cosine similarity between the documents  1 and 923 is:  0.0\n",
      "The cosine similarity between the documents  1 and 924 is:  0.0\n",
      "The cosine similarity between the documents  1 and 925 is:  nan\n",
      "The cosine similarity between the documents  1 and 926 is:  nan\n",
      "The cosine similarity between the documents  1 and 927 is:  0.0\n",
      "The cosine similarity between the documents  1 and 928 is:  nan\n",
      "The cosine similarity between the documents  1 and 929 is:  nan\n",
      "The cosine similarity between the documents  1 and 930 is:  0.0\n",
      "The cosine similarity between the documents  1 and 931 is:  0.0\n",
      "The cosine similarity between the documents  1 and 932 is:  0.0\n",
      "The cosine similarity between the documents  1 and 933 is:  nan\n",
      "The cosine similarity between the documents  1 and 934 is:  nan\n",
      "The cosine similarity between the documents  1 and 935 is:  0.0\n",
      "The cosine similarity between the documents  1 and 936 is:  0.0\n",
      "The cosine similarity between the documents  1 and 937 is:  0.0\n",
      "The cosine similarity between the documents  1 and 938 is:  nan\n",
      "The cosine similarity between the documents  1 and 939 is:  nan\n",
      "The cosine similarity between the documents  1 and 940 is:  0.0\n",
      "The cosine similarity between the documents  1 and 941 is:  nan\n",
      "The cosine similarity between the documents  1 and 942 is:  0.0\n",
      "The cosine similarity between the documents  1 and 943 is:  0.0\n",
      "The cosine similarity between the documents  1 and 944 is:  0.0\n",
      "The cosine similarity between the documents  1 and 945 is:  0.0\n",
      "The cosine similarity between the documents  1 and 946 is:  0.0\n",
      "The cosine similarity between the documents  1 and 947 is:  0.0\n",
      "The cosine similarity between the documents  1 and 948 is:  0.0\n",
      "The cosine similarity between the documents  1 and 949 is:  0.0\n",
      "The cosine similarity between the documents  1 and 950 is:  0.0\n",
      "The cosine similarity between the documents  1 and 951 is:  0.0\n",
      "The cosine similarity between the documents  1 and 952 is:  0.0\n",
      "The cosine similarity between the documents  1 and 953 is:  0.0\n",
      "The cosine similarity between the documents  1 and 954 is:  0.0\n",
      "The cosine similarity between the documents  1 and 955 is:  0.0\n",
      "The cosine similarity between the documents  1 and 956 is:  0.0\n",
      "The cosine similarity between the documents  1 and 957 is:  0.0\n",
      "The cosine similarity between the documents  1 and 958 is:  0.0\n",
      "The cosine similarity between the documents  1 and 959 is:  0.0\n",
      "The cosine similarity between the documents  1 and 960 is:  0.0\n",
      "The cosine similarity between the documents  1 and 961 is:  0.0\n",
      "The cosine similarity between the documents  1 and 962 is:  0.0\n",
      "The cosine similarity between the documents  1 and 963 is:  nan\n",
      "The cosine similarity between the documents  1 and 964 is:  0.0\n",
      "The cosine similarity between the documents  1 and 965 is:  0.0\n",
      "The cosine similarity between the documents  1 and 966 is:  0.0\n",
      "The cosine similarity between the documents  1 and 967 is:  nan\n",
      "The cosine similarity between the documents  1 and 968 is:  nan\n",
      "The cosine similarity between the documents  1 and 969 is:  0.0\n",
      "The cosine similarity between the documents  1 and 970 is:  nan\n",
      "The cosine similarity between the documents  1 and 971 is:  nan\n",
      "The cosine similarity between the documents  1 and 972 is:  0.0\n",
      "The cosine similarity between the documents  1 and 973 is:  0.0\n",
      "The cosine similarity between the documents  1 and 974 is:  0.0\n",
      "The cosine similarity between the documents  1 and 975 is:  0.0\n",
      "The cosine similarity between the documents  1 and 976 is:  0.0\n",
      "The cosine similarity between the documents  1 and 977 is:  0.0\n",
      "The cosine similarity between the documents  1 and 978 is:  0.0\n",
      "The cosine similarity between the documents  1 and 979 is:  0.0\n",
      "The cosine similarity between the documents  1 and 980 is:  0.0\n",
      "The cosine similarity between the documents  1 and 981 is:  0.0\n",
      "The cosine similarity between the documents  1 and 982 is:  0.0\n",
      "The cosine similarity between the documents  1 and 983 is:  nan\n",
      "The cosine similarity between the documents  1 and 984 is:  0.0\n",
      "The cosine similarity between the documents  1 and 985 is:  0.0\n",
      "The cosine similarity between the documents  1 and 986 is:  0.0\n",
      "The cosine similarity between the documents  1 and 987 is:  nan\n",
      "The cosine similarity between the documents  1 and 988 is:  0.0\n",
      "The cosine similarity between the documents  1 and 989 is:  0.0\n",
      "The cosine similarity between the documents  1 and 990 is:  0.0\n",
      "The cosine similarity between the documents  1 and 991 is:  nan\n",
      "The cosine similarity between the documents  1 and 992 is:  0.0\n",
      "The cosine similarity between the documents  1 and 993 is:  nan\n",
      "The cosine similarity between the documents  1 and 994 is:  0.0\n",
      "The cosine similarity between the documents  1 and 995 is:  0.0\n",
      "The cosine similarity between the documents  1 and 996 is:  0.0\n",
      "The cosine similarity between the documents  1 and 997 is:  0.0\n",
      "The cosine similarity between the documents  1 and 998 is:  0.0\n",
      "The cosine similarity between the documents  1 and 999 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1000 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1001 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1002 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1003 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1004 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1005 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1006 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1007 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1008 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1009 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1010 is:  nan\n",
      "The cosine similarity between the documents  1 and 1011 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1012 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1013 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1014 is:  nan\n",
      "The cosine similarity between the documents  1 and 1015 is:  nan\n",
      "The cosine similarity between the documents  1 and 1016 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1017 is:  nan\n",
      "The cosine similarity between the documents  1 and 1018 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1019 is:  nan\n",
      "The cosine similarity between the documents  1 and 1020 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1021 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1022 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1023 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1024 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1025 is:  nan\n",
      "The cosine similarity between the documents  1 and 1026 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1027 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1028 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1029 is:  nan\n",
      "The cosine similarity between the documents  1 and 1030 is:  nan\n",
      "The cosine similarity between the documents  1 and 1031 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1032 is:  nan\n",
      "The cosine similarity between the documents  1 and 1033 is:  nan\n",
      "The cosine similarity between the documents  1 and 1034 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1035 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1036 is:  nan\n",
      "The cosine similarity between the documents  1 and 1037 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1038 is:  nan\n",
      "The cosine similarity between the documents  1 and 1039 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1040 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1041 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1042 is:  nan\n",
      "The cosine similarity between the documents  1 and 1043 is:  nan\n",
      "The cosine similarity between the documents  1 and 1044 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1045 is:  nan\n",
      "The cosine similarity between the documents  1 and 1046 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1047 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1048 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1049 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1050 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1051 is:  nan\n",
      "The cosine similarity between the documents  1 and 1052 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1053 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1054 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1055 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1056 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1057 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1058 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1059 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1060 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1061 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1062 is:  nan\n",
      "The cosine similarity between the documents  1 and 1063 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1064 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1065 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1066 is:  nan\n",
      "The cosine similarity between the documents  1 and 1067 is:  nan\n",
      "The cosine similarity between the documents  1 and 1068 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1069 is:  nan\n",
      "The cosine similarity between the documents  1 and 1070 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1071 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1072 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1073 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1074 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1075 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1076 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1077 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1078 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1079 is:  nan\n",
      "The cosine similarity between the documents  1 and 1080 is:  nan\n",
      "The cosine similarity between the documents  1 and 1081 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1082 is:  nan\n",
      "The cosine similarity between the documents  1 and 1083 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1084 is:  nan\n",
      "The cosine similarity between the documents  1 and 1085 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1086 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1087 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1088 is:  nan\n",
      "The cosine similarity between the documents  1 and 1089 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1090 is:  nan\n",
      "The cosine similarity between the documents  1 and 1091 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1092 is:  nan\n",
      "The cosine similarity between the documents  1 and 1093 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1094 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1095 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1096 is:  nan\n",
      "The cosine similarity between the documents  1 and 1097 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1098 is:  nan\n",
      "The cosine similarity between the documents  1 and 1099 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1100 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1101 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1102 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1103 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1104 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1105 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1106 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1107 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1108 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1109 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1110 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1111 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1112 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1113 is:  nan\n",
      "The cosine similarity between the documents  1 and 1114 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1115 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1116 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1117 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1118 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1119 is:  nan\n",
      "The cosine similarity between the documents  1 and 1120 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1121 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1122 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1123 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1124 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1125 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1126 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1127 is:  nan\n",
      "The cosine similarity between the documents  1 and 1128 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1129 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1130 is:  nan\n",
      "The cosine similarity between the documents  1 and 1131 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1132 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1133 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1134 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1135 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1136 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1137 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1138 is:  nan\n",
      "The cosine similarity between the documents  1 and 1139 is:  nan\n",
      "The cosine similarity between the documents  1 and 1140 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1141 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1142 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1143 is:  nan\n",
      "The cosine similarity between the documents  1 and 1144 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1145 is:  nan\n",
      "The cosine similarity between the documents  1 and 1146 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1147 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1148 is:  nan\n",
      "The cosine similarity between the documents  1 and 1149 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1150 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1151 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1152 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1153 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1154 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1155 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1156 is:  nan\n",
      "The cosine similarity between the documents  1 and 1157 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1158 is:  nan\n",
      "The cosine similarity between the documents  1 and 1159 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1160 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1161 is:  nan\n",
      "The cosine similarity between the documents  1 and 1162 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1163 is:  nan\n",
      "The cosine similarity between the documents  1 and 1164 is:  nan\n",
      "The cosine similarity between the documents  1 and 1165 is:  nan\n",
      "The cosine similarity between the documents  1 and 1166 is:  nan\n",
      "The cosine similarity between the documents  1 and 1167 is:  nan\n",
      "The cosine similarity between the documents  1 and 1168 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1169 is:  nan\n",
      "The cosine similarity between the documents  1 and 1170 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1171 is:  nan\n",
      "The cosine similarity between the documents  1 and 1172 is:  nan\n",
      "The cosine similarity between the documents  1 and 1173 is:  nan\n",
      "The cosine similarity between the documents  1 and 1174 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1175 is:  nan\n",
      "The cosine similarity between the documents  1 and 1176 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1177 is:  nan\n",
      "The cosine similarity between the documents  1 and 1178 is:  nan\n",
      "The cosine similarity between the documents  1 and 1179 is:  nan\n",
      "The cosine similarity between the documents  1 and 1180 is:  nan\n",
      "The cosine similarity between the documents  1 and 1181 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1182 is:  nan\n",
      "The cosine similarity between the documents  1 and 1183 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1184 is:  nan\n",
      "The cosine similarity between the documents  1 and 1185 is:  nan\n",
      "The cosine similarity between the documents  1 and 1186 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1187 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1188 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1189 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1190 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1191 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1192 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1193 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1194 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1195 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1196 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1197 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1198 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1199 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1200 is:  nan\n",
      "The cosine similarity between the documents  1 and 1201 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1202 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1203 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1204 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1205 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1206 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1207 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1208 is:  nan\n",
      "The cosine similarity between the documents  1 and 1209 is:  nan\n",
      "The cosine similarity between the documents  1 and 1210 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1211 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1212 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1213 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1214 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1215 is:  nan\n",
      "The cosine similarity between the documents  1 and 1216 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1217 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1218 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1219 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1220 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1221 is:  nan\n",
      "The cosine similarity between the documents  1 and 1222 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1223 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1224 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1225 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1226 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1227 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1228 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1229 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1230 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1231 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1232 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1233 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1234 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1235 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1236 is:  nan\n",
      "The cosine similarity between the documents  1 and 1237 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1238 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1239 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1240 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1241 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1242 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1243 is:  nan\n",
      "The cosine similarity between the documents  1 and 1244 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1245 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1246 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1247 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1248 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1249 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1250 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1251 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1252 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1253 is:  nan\n",
      "The cosine similarity between the documents  1 and 1254 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1255 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1256 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1257 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1258 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1259 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1260 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1261 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1262 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1263 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1264 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1265 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1266 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1267 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1268 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1269 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1270 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1271 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1272 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1273 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1274 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1275 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1276 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1277 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1278 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1279 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1280 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1281 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1282 is:  nan\n",
      "The cosine similarity between the documents  1 and 1283 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1284 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1285 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1286 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1287 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1288 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1289 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1290 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1291 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1292 is:  nan\n",
      "The cosine similarity between the documents  1 and 1293 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1294 is:  nan\n",
      "The cosine similarity between the documents  1 and 1295 is:  nan\n",
      "The cosine similarity between the documents  1 and 1296 is:  nan\n",
      "The cosine similarity between the documents  1 and 1297 is:  nan\n",
      "The cosine similarity between the documents  1 and 1298 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1299 is:  nan\n",
      "The cosine similarity between the documents  1 and 1300 is:  nan\n",
      "The cosine similarity between the documents  1 and 1301 is:  nan\n",
      "The cosine similarity between the documents  1 and 1302 is:  nan\n",
      "The cosine similarity between the documents  1 and 1303 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1304 is:  nan\n",
      "The cosine similarity between the documents  1 and 1305 is:  nan\n",
      "The cosine similarity between the documents  1 and 1306 is:  nan\n",
      "The cosine similarity between the documents  1 and 1307 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1308 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1309 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1310 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1311 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1312 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1313 is:  nan\n",
      "The cosine similarity between the documents  1 and 1314 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1315 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1316 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1317 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1318 is:  nan\n",
      "The cosine similarity between the documents  1 and 1319 is:  nan\n",
      "The cosine similarity between the documents  1 and 1320 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1321 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1322 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1323 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1324 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1325 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1326 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1327 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1328 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1329 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1330 is:  nan\n",
      "The cosine similarity between the documents  1 and 1331 is:  nan\n",
      "The cosine similarity between the documents  1 and 1332 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1333 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1334 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1335 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1336 is:  nan\n",
      "The cosine similarity between the documents  1 and 1337 is:  nan\n",
      "The cosine similarity between the documents  1 and 1338 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1339 is:  nan\n",
      "The cosine similarity between the documents  1 and 1340 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1341 is:  nan\n",
      "The cosine similarity between the documents  1 and 1342 is:  nan\n",
      "The cosine similarity between the documents  1 and 1343 is:  nan\n",
      "The cosine similarity between the documents  1 and 1344 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1345 is:  nan\n",
      "The cosine similarity between the documents  1 and 1346 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1347 is:  nan\n",
      "The cosine similarity between the documents  1 and 1348 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1349 is:  nan\n",
      "The cosine similarity between the documents  1 and 1350 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1351 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1352 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1353 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1354 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1355 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1356 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1357 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1358 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1359 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1360 is:  nan\n",
      "The cosine similarity between the documents  1 and 1361 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1362 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1363 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1364 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1365 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1366 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1367 is:  nan\n",
      "The cosine similarity between the documents  1 and 1368 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1369 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1370 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1371 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1372 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1373 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1374 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1375 is:  nan\n",
      "The cosine similarity between the documents  1 and 1376 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1377 is:  nan\n",
      "The cosine similarity between the documents  1 and 1378 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1379 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1380 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1381 is:  nan\n",
      "The cosine similarity between the documents  1 and 1382 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1383 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1384 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1385 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1386 is:  nan\n",
      "The cosine similarity between the documents  1 and 1387 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1388 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1389 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1390 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1391 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1392 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1393 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1394 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1395 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1396 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1397 is:  nan\n",
      "The cosine similarity between the documents  1 and 1398 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1399 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1400 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1401 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1402 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1403 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1404 is:  nan\n",
      "The cosine similarity between the documents  1 and 1405 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1406 is:  nan\n",
      "The cosine similarity between the documents  1 and 1407 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1408 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1409 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1410 is:  nan\n",
      "The cosine similarity between the documents  1 and 1411 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1412 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1413 is:  nan\n",
      "The cosine similarity between the documents  1 and 1414 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1415 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1416 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1417 is:  nan\n",
      "The cosine similarity between the documents  1 and 1418 is:  nan\n",
      "The cosine similarity between the documents  1 and 1419 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1420 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1421 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1422 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1423 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1424 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1425 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1426 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1427 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1428 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1429 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1430 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1431 is:  nan\n",
      "The cosine similarity between the documents  1 and 1432 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1433 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1434 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1435 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1436 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1437 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1438 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1439 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1440 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1441 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1442 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1443 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1444 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1445 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1446 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1447 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1448 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1449 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1450 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1451 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1452 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1453 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1454 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1455 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1456 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1457 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1458 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1459 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1460 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1461 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1462 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1463 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1464 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1465 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1466 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1467 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1468 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1469 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1470 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1471 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1472 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1473 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1474 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1475 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1476 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1477 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1478 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1479 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1480 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1481 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1482 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1483 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1484 is:  nan\n",
      "The cosine similarity between the documents  1 and 1485 is:  nan\n",
      "The cosine similarity between the documents  1 and 1486 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1487 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1488 is:  nan\n",
      "The cosine similarity between the documents  1 and 1489 is:  nan\n",
      "The cosine similarity between the documents  1 and 1490 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1491 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1492 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1493 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1494 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1495 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1496 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1497 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1498 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1499 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1500 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1501 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1502 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1503 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1504 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1505 is:  nan\n",
      "The cosine similarity between the documents  1 and 1506 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1507 is:  nan\n",
      "The cosine similarity between the documents  1 and 1508 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1509 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1510 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1511 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1512 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1513 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1514 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1515 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1516 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1517 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1518 is:  nan\n",
      "The cosine similarity between the documents  1 and 1519 is:  nan\n",
      "The cosine similarity between the documents  1 and 1520 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1521 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1522 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1523 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1524 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1525 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1526 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1527 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1528 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1529 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1530 is:  nan\n",
      "The cosine similarity between the documents  1 and 1531 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1532 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1533 is:  nan\n",
      "The cosine similarity between the documents  1 and 1534 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1535 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1536 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1537 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1538 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1539 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1540 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1541 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1542 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1543 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1544 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1545 is:  nan\n",
      "The cosine similarity between the documents  1 and 1546 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1547 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1548 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1549 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1550 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1551 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1552 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1553 is:  nan\n",
      "The cosine similarity between the documents  1 and 1554 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1555 is:  nan\n",
      "The cosine similarity between the documents  1 and 1556 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1557 is:  nan\n",
      "The cosine similarity between the documents  1 and 1558 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1559 is:  nan\n",
      "The cosine similarity between the documents  1 and 1560 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1561 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1562 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1563 is:  nan\n",
      "The cosine similarity between the documents  1 and 1564 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1565 is:  nan\n",
      "The cosine similarity between the documents  1 and 1566 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1567 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1568 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1569 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1570 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1571 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1572 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1573 is:  nan\n",
      "The cosine similarity between the documents  1 and 1574 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1575 is:  1.0\n",
      "The cosine similarity between the documents  1 and 1576 is:  nan\n",
      "The cosine similarity between the documents  1 and 1577 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1578 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1579 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1580 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1581 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1582 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1583 is:  nan\n",
      "The cosine similarity between the documents  1 and 1584 is:  nan\n",
      "The cosine similarity between the documents  1 and 1585 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1586 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1587 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1588 is:  nan\n",
      "The cosine similarity between the documents  1 and 1589 is:  nan\n",
      "The cosine similarity between the documents  1 and 1590 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1591 is:  nan\n",
      "The cosine similarity between the documents  1 and 1592 is:  nan\n",
      "The cosine similarity between the documents  1 and 1593 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1594 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1595 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1596 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1597 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1598 is:  nan\n",
      "The cosine similarity between the documents  1 and 1599 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1600 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1601 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1602 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1603 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1604 is:  nan\n",
      "The cosine similarity between the documents  1 and 1605 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1606 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1607 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1608 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1609 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1610 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1611 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1612 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1613 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1614 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1615 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1616 is:  nan\n",
      "The cosine similarity between the documents  1 and 1617 is:  nan\n",
      "The cosine similarity between the documents  1 and 1618 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1619 is:  nan\n",
      "The cosine similarity between the documents  1 and 1620 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1621 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1622 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1623 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1624 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1625 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1626 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1627 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1628 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1629 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1630 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1631 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1632 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1633 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1634 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1635 is:  nan\n",
      "The cosine similarity between the documents  1 and 1636 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1637 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1638 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1639 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1640 is:  nan\n",
      "The cosine similarity between the documents  1 and 1641 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1642 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1643 is:  nan\n",
      "The cosine similarity between the documents  1 and 1644 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1645 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1646 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1647 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1648 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1649 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1650 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1651 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1652 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1653 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1654 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1655 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1656 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1657 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1658 is:  nan\n",
      "The cosine similarity between the documents  1 and 1659 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1660 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1661 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1662 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1663 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1664 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1665 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1666 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1667 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1668 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1669 is:  nan\n",
      "The cosine similarity between the documents  1 and 1670 is:  nan\n",
      "The cosine similarity between the documents  1 and 1671 is:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1672 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1673 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1674 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1675 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1676 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1677 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1678 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1679 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1680 is:  nan\n",
      "The cosine similarity between the documents  1 and 1681 is:  nan\n",
      "The cosine similarity between the documents  1 and 1682 is:  1.0\n",
      "The cosine similarity between the documents  1 and 1683 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1684 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1685 is:  nan\n",
      "The cosine similarity between the documents  1 and 1686 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1687 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1688 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1689 is:  nan\n",
      "The cosine similarity between the documents  1 and 1690 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1691 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1692 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1693 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1694 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1695 is:  nan\n",
      "The cosine similarity between the documents  1 and 1696 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1697 is:  nan\n",
      "The cosine similarity between the documents  1 and 1698 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1699 is:  nan\n",
      "The cosine similarity between the documents  1 and 1700 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1701 is:  nan\n",
      "The cosine similarity between the documents  1 and 1702 is:  nan\n",
      "The cosine similarity between the documents  1 and 1703 is:  nan\n",
      "The cosine similarity between the documents  1 and 1704 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1705 is:  1.0\n",
      "The cosine similarity between the documents  1 and 1706 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1707 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1708 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1709 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1710 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1711 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1712 is:  nan\n",
      "The cosine similarity between the documents  1 and 1713 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1714 is:  nan\n",
      "The cosine similarity between the documents  1 and 1715 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1716 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1717 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1718 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1719 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1720 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1721 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1722 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1723 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1724 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1725 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1726 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1727 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1728 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1729 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1730 is:  nan\n",
      "The cosine similarity between the documents  1 and 1731 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1732 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1733 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1734 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1735 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1736 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1737 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1738 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1739 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1740 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1741 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1742 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1743 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1744 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1745 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1746 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1747 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1748 is:  nan\n",
      "The cosine similarity between the documents  1 and 1749 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1750 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1751 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1752 is:  nan\n",
      "The cosine similarity between the documents  1 and 1753 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1754 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1755 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1756 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1757 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1758 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1759 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1760 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1761 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1762 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1763 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1764 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1765 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1766 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1767 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1768 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1769 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1770 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1771 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1772 is:  nan\n",
      "The cosine similarity between the documents  1 and 1773 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1774 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1775 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1776 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1777 is:  nan\n",
      "The cosine similarity between the documents  1 and 1778 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1779 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1780 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1781 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1782 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1783 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1784 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1785 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1786 is:  nan\n",
      "The cosine similarity between the documents  1 and 1787 is:  nan\n",
      "The cosine similarity between the documents  1 and 1788 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1789 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1790 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1791 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1792 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1793 is:  nan\n",
      "The cosine similarity between the documents  1 and 1794 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1795 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1796 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1797 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1798 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1799 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1800 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1801 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1802 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1803 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1804 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1805 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1806 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1807 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1808 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1809 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1810 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1811 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1812 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1813 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1814 is:  nan\n",
      "The cosine similarity between the documents  1 and 1815 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1816 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1817 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1818 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1819 is:  nan\n",
      "The cosine similarity between the documents  1 and 1820 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1821 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1822 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1823 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1824 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1825 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1826 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1827 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1828 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1829 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1830 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1831 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1832 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1833 is:  nan\n",
      "The cosine similarity between the documents  1 and 1834 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1835 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1836 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1837 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1838 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1839 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1840 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1841 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1842 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1843 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1844 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1845 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1846 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1847 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1848 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1849 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1850 is:  nan\n",
      "The cosine similarity between the documents  1 and 1851 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1852 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1853 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1854 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1855 is:  nan\n",
      "The cosine similarity between the documents  1 and 1856 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1857 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1858 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1859 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1860 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1861 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1862 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1863 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1864 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1865 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1866 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1867 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1868 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1869 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1870 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1871 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1872 is:  nan\n",
      "The cosine similarity between the documents  1 and 1873 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1874 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1875 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1876 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1877 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1878 is:  nan\n",
      "The cosine similarity between the documents  1 and 1879 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1880 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1881 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1882 is:  nan\n",
      "The cosine similarity between the documents  1 and 1883 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1884 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1885 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1886 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1887 is:  nan\n",
      "The cosine similarity between the documents  1 and 1888 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1889 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1890 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1891 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1892 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1893 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1894 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1895 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1896 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1897 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1898 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1899 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1900 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1901 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1902 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1903 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1904 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1905 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1906 is:  nan\n",
      "The cosine similarity between the documents  1 and 1907 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1908 is:  nan\n",
      "The cosine similarity between the documents  1 and 1909 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1910 is:  nan\n",
      "The cosine similarity between the documents  1 and 1911 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1912 is:  nan\n",
      "The cosine similarity between the documents  1 and 1913 is:  nan\n",
      "The cosine similarity between the documents  1 and 1914 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1915 is:  nan\n",
      "The cosine similarity between the documents  1 and 1916 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1917 is:  nan\n",
      "The cosine similarity between the documents  1 and 1918 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1919 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1920 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1921 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1922 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1923 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1924 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1925 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1926 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1927 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1928 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1929 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1930 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1931 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1932 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1933 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1934 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1935 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1936 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1937 is:  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 1938 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1939 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1940 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1941 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1942 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1943 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1944 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1945 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1946 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1947 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1948 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1949 is:  nan\n",
      "The cosine similarity between the documents  1 and 1950 is:  nan\n",
      "The cosine similarity between the documents  1 and 1951 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1952 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1953 is:  nan\n",
      "The cosine similarity between the documents  1 and 1954 is:  nan\n",
      "The cosine similarity between the documents  1 and 1955 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1956 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1957 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1958 is:  nan\n",
      "The cosine similarity between the documents  1 and 1959 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1960 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1961 is:  nan\n",
      "The cosine similarity between the documents  1 and 1962 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1963 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1964 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1965 is:  nan\n",
      "The cosine similarity between the documents  1 and 1966 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1967 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1968 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1969 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1970 is:  nan\n",
      "The cosine similarity between the documents  1 and 1971 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1972 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1973 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1974 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1975 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1976 is:  nan\n",
      "The cosine similarity between the documents  1 and 1977 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1978 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1979 is:  nan\n",
      "The cosine similarity between the documents  1 and 1980 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1981 is:  nan\n",
      "The cosine similarity between the documents  1 and 1982 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1983 is:  nan\n",
      "The cosine similarity between the documents  1 and 1984 is:  nan\n",
      "The cosine similarity between the documents  1 and 1985 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1986 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1987 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1988 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1989 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1990 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1991 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1992 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1993 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1994 is:  nan\n",
      "The cosine similarity between the documents  1 and 1995 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1996 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1997 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1998 is:  0.0\n",
      "The cosine similarity between the documents  1 and 1999 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2000 is:  nan\n",
      "The cosine similarity between the documents  1 and 2001 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2002 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2003 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2004 is:  nan\n",
      "The cosine similarity between the documents  1 and 2005 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2006 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2007 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2008 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2009 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2010 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2011 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2012 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2013 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2014 is:  nan\n",
      "The cosine similarity between the documents  1 and 2015 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2016 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2017 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2018 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2019 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2020 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2021 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2022 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2023 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2024 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2025 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2026 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2027 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2028 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2029 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2030 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2031 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2032 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2033 is:  nan\n",
      "The cosine similarity between the documents  1 and 2034 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2035 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2036 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2037 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2038 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2039 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2040 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2041 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2042 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2043 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2044 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2045 is:  nan\n",
      "The cosine similarity between the documents  1 and 2046 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2047 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2048 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2049 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2050 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2051 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2052 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2053 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2054 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2055 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2056 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2057 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2058 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2059 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2060 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2061 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2062 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2063 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2064 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2065 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2066 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2067 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2068 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2069 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2070 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2071 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 2072 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2073 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2074 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2075 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2076 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2077 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2078 is:  nan\n",
      "The cosine similarity between the documents  1 and 2079 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2080 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2081 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2082 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2083 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2084 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2085 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2086 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2087 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2088 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2089 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2090 is:  nan\n",
      "The cosine similarity between the documents  1 and 2091 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2092 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2093 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2094 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2095 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2096 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2097 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2098 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2099 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2100 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2101 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2102 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2103 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2104 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2105 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2106 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2107 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2108 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2109 is:  1.0\n",
      "The cosine similarity between the documents  1 and 2110 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2111 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2112 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2113 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2114 is:  nan\n",
      "The cosine similarity between the documents  1 and 2115 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2116 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2117 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2118 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2119 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2120 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2121 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2122 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2123 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2124 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2125 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2126 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2127 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2128 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2129 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2130 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2131 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2132 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2133 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2134 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2135 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2136 is:  nan\n",
      "The cosine similarity between the documents  1 and 2137 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2138 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2139 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2140 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2141 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2142 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2143 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2144 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2145 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2146 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2147 is:  nan\n",
      "The cosine similarity between the documents  1 and 2148 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2149 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2150 is:  nan\n",
      "The cosine similarity between the documents  1 and 2151 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2152 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2153 is:  nan\n",
      "The cosine similarity between the documents  1 and 2154 is:  nan\n",
      "The cosine similarity between the documents  1 and 2155 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2156 is:  nan\n",
      "The cosine similarity between the documents  1 and 2157 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2158 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2159 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2160 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2161 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2162 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2163 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2164 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2165 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2166 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2167 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2168 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2169 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2170 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2171 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2172 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2173 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2174 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2175 is:  nan\n",
      "The cosine similarity between the documents  1 and 2176 is:  nan\n",
      "The cosine similarity between the documents  1 and 2177 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2178 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2179 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2180 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2181 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2182 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2183 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2184 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2185 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2186 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2187 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2188 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2189 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2190 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2191 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2192 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2193 is:  nan\n",
      "The cosine similarity between the documents  1 and 2194 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2195 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2196 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2197 is:  nan\n",
      "The cosine similarity between the documents  1 and 2198 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2199 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2200 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2201 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2202 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2203 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2204 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2205 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 2206 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2207 is:  nan\n",
      "The cosine similarity between the documents  1 and 2208 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2209 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2210 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2211 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2212 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2213 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2214 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2215 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2216 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2217 is:  nan\n",
      "The cosine similarity between the documents  1 and 2218 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2219 is:  nan\n",
      "The cosine similarity between the documents  1 and 2220 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2221 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2222 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2223 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2224 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2225 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2226 is:  nan\n",
      "The cosine similarity between the documents  1 and 2227 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2228 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2229 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2230 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2231 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2232 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2233 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2234 is:  nan\n",
      "The cosine similarity between the documents  1 and 2235 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2236 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2237 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2238 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2239 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2240 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2241 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2242 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2243 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2244 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2245 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2246 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2247 is:  nan\n",
      "The cosine similarity between the documents  1 and 2248 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2249 is:  nan\n",
      "The cosine similarity between the documents  1 and 2250 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2251 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2252 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2253 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2254 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2255 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2256 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2257 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2258 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2259 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2260 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2261 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2262 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2263 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2264 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2265 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2266 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2267 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2268 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2269 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2270 is:  nan\n",
      "The cosine similarity between the documents  1 and 2271 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2272 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2273 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2274 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2275 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2276 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2277 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2278 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2279 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2280 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2281 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2282 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2283 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2284 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2285 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2286 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2287 is:  nan\n",
      "The cosine similarity between the documents  1 and 2288 is:  nan\n",
      "The cosine similarity between the documents  1 and 2289 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2290 is:  nan\n",
      "The cosine similarity between the documents  1 and 2291 is:  nan\n",
      "The cosine similarity between the documents  1 and 2292 is:  nan\n",
      "The cosine similarity between the documents  1 and 2293 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2294 is:  nan\n",
      "The cosine similarity between the documents  1 and 2295 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2296 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2297 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2298 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2299 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2300 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2301 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2302 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2303 is:  nan\n",
      "The cosine similarity between the documents  1 and 2304 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2305 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2306 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2307 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2308 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2309 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2310 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2311 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2312 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2313 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2314 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2315 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2316 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2317 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2318 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2319 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2320 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2321 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2322 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2323 is:  nan\n",
      "The cosine similarity between the documents  1 and 2324 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2325 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2326 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2327 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2328 is:  nan\n",
      "The cosine similarity between the documents  1 and 2329 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2330 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2331 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2332 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2333 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2334 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2335 is:  nan\n",
      "The cosine similarity between the documents  1 and 2336 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2337 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 2338 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2339 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2340 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2341 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2342 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2343 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2344 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2345 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2346 is:  nan\n",
      "The cosine similarity between the documents  1 and 2347 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2348 is:  nan\n",
      "The cosine similarity between the documents  1 and 2349 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2350 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2351 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2352 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2353 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2354 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2355 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2356 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2357 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2358 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2359 is:  nan\n",
      "The cosine similarity between the documents  1 and 2360 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2361 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2362 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2363 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2364 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2365 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2366 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2367 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2368 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2369 is:  nan\n",
      "The cosine similarity between the documents  1 and 2370 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2371 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2372 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2373 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2374 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2375 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2376 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2377 is:  nan\n",
      "The cosine similarity between the documents  1 and 2378 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2379 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2380 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2381 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2382 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2383 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2384 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2385 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2386 is:  nan\n",
      "The cosine similarity between the documents  1 and 2387 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2388 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2389 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2390 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2391 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2392 is:  nan\n",
      "The cosine similarity between the documents  1 and 2393 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2394 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2395 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2396 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2397 is:  nan\n",
      "The cosine similarity between the documents  1 and 2398 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2399 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2400 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2401 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2402 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2403 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2404 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2405 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2406 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2407 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2408 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2409 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2410 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2411 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2412 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2413 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2414 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2415 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2416 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2417 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2418 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2419 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2420 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2421 is:  nan\n",
      "The cosine similarity between the documents  1 and 2422 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2423 is:  nan\n",
      "The cosine similarity between the documents  1 and 2424 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2425 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2426 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2427 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2428 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2429 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2430 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2431 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2432 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2433 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2434 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2435 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2436 is:  nan\n",
      "The cosine similarity between the documents  1 and 2437 is:  nan\n",
      "The cosine similarity between the documents  1 and 2438 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2439 is:  nan\n",
      "The cosine similarity between the documents  1 and 2440 is:  nan\n",
      "The cosine similarity between the documents  1 and 2441 is:  nan\n",
      "The cosine similarity between the documents  1 and 2442 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2443 is:  nan\n",
      "The cosine similarity between the documents  1 and 2444 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2445 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2446 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2447 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2448 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2449 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2450 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2451 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2452 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2453 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2454 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2455 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2456 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2457 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2458 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2459 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2460 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2461 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2462 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2463 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2464 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2465 is:  nan\n",
      "The cosine similarity between the documents  1 and 2466 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2467 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2468 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 2469 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2470 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2471 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2472 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2473 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2474 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2475 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2476 is:  nan\n",
      "The cosine similarity between the documents  1 and 2477 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2478 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2479 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2480 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2481 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2482 is:  nan\n",
      "The cosine similarity between the documents  1 and 2483 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2484 is:  nan\n",
      "The cosine similarity between the documents  1 and 2485 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2486 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2487 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2488 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2489 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2490 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2491 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2492 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2493 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2494 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2495 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2496 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2497 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2498 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2499 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2500 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2501 is:  nan\n",
      "The cosine similarity between the documents  1 and 2502 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2503 is:  nan\n",
      "The cosine similarity between the documents  1 and 2504 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2505 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2506 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2507 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2508 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2509 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2510 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2511 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2512 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2513 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2514 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2515 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2516 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2517 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2518 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2519 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2520 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2521 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2522 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2523 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2524 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2525 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2526 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2527 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2528 is:  nan\n",
      "The cosine similarity between the documents  1 and 2529 is:  nan\n",
      "The cosine similarity between the documents  1 and 2530 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2531 is:  nan\n",
      "The cosine similarity between the documents  1 and 2532 is:  nan\n",
      "The cosine similarity between the documents  1 and 2533 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2534 is:  nan\n",
      "The cosine similarity between the documents  1 and 2535 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2536 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2537 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2538 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2539 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2540 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2541 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2542 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2543 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2544 is:  nan\n",
      "The cosine similarity between the documents  1 and 2545 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2546 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2547 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2548 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2549 is:  nan\n",
      "The cosine similarity between the documents  1 and 2550 is:  nan\n",
      "The cosine similarity between the documents  1 and 2551 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2552 is:  nan\n",
      "The cosine similarity between the documents  1 and 2553 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2554 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2555 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2556 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2557 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2558 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2559 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2560 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2561 is:  nan\n",
      "The cosine similarity between the documents  1 and 2562 is:  nan\n",
      "The cosine similarity between the documents  1 and 2563 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2564 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2565 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2566 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2567 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2568 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2569 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2570 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2571 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2572 is:  nan\n",
      "The cosine similarity between the documents  1 and 2573 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2574 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2575 is:  nan\n",
      "The cosine similarity between the documents  1 and 2576 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2577 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2578 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2579 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2580 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2581 is:  nan\n",
      "The cosine similarity between the documents  1 and 2582 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2583 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2584 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2585 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2586 is:  nan\n",
      "The cosine similarity between the documents  1 and 2587 is:  nan\n",
      "The cosine similarity between the documents  1 and 2588 is:  nan\n",
      "The cosine similarity between the documents  1 and 2589 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2590 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2591 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2592 is:  nan\n",
      "The cosine similarity between the documents  1 and 2593 is:  nan\n",
      "The cosine similarity between the documents  1 and 2594 is:  nan\n",
      "The cosine similarity between the documents  1 and 2595 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2596 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2597 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2598 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2599 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2600 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 2601 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2602 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2603 is:  nan\n",
      "The cosine similarity between the documents  1 and 2604 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2605 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2606 is:  nan\n",
      "The cosine similarity between the documents  1 and 2607 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2608 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2609 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2610 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2611 is:  nan\n",
      "The cosine similarity between the documents  1 and 2612 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2613 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2614 is:  nan\n",
      "The cosine similarity between the documents  1 and 2615 is:  nan\n",
      "The cosine similarity between the documents  1 and 2616 is:  nan\n",
      "The cosine similarity between the documents  1 and 2617 is:  nan\n",
      "The cosine similarity between the documents  1 and 2618 is:  nan\n",
      "The cosine similarity between the documents  1 and 2619 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2620 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2621 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2622 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2623 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2624 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2625 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2626 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2627 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2628 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2629 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2630 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2631 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2632 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2633 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2634 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2635 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2636 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2637 is:  nan\n",
      "The cosine similarity between the documents  1 and 2638 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2639 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2640 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2641 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2642 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2643 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2644 is:  nan\n",
      "The cosine similarity between the documents  1 and 2645 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2646 is:  nan\n",
      "The cosine similarity between the documents  1 and 2647 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2648 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2649 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2650 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2651 is:  nan\n",
      "The cosine similarity between the documents  1 and 2652 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2653 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2654 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2655 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2656 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2657 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2658 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2659 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2660 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2661 is:  nan\n",
      "The cosine similarity between the documents  1 and 2662 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2663 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2664 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2665 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2666 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2667 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2668 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2669 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2670 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2671 is:  nan\n",
      "The cosine similarity between the documents  1 and 2672 is:  nan\n",
      "The cosine similarity between the documents  1 and 2673 is:  nan\n",
      "The cosine similarity between the documents  1 and 2674 is:  nan\n",
      "The cosine similarity between the documents  1 and 2675 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2676 is:  nan\n",
      "The cosine similarity between the documents  1 and 2677 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2678 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2679 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2680 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2681 is:  nan\n",
      "The cosine similarity between the documents  1 and 2682 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2683 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2684 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2685 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2686 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2687 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2688 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2689 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2690 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2691 is:  nan\n",
      "The cosine similarity between the documents  1 and 2692 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2693 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2694 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2695 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2696 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2697 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2698 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2699 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2700 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2701 is:  nan\n",
      "The cosine similarity between the documents  1 and 2702 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2703 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2704 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2705 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2706 is:  nan\n",
      "The cosine similarity between the documents  1 and 2707 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2708 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2709 is:  nan\n",
      "The cosine similarity between the documents  1 and 2710 is:  nan\n",
      "The cosine similarity between the documents  1 and 2711 is:  nan\n",
      "The cosine similarity between the documents  1 and 2712 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2713 is:  nan\n",
      "The cosine similarity between the documents  1 and 2714 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2715 is:  nan\n",
      "The cosine similarity between the documents  1 and 2716 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2717 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2718 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2719 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2720 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2721 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2722 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2723 is:  nan\n",
      "The cosine similarity between the documents  1 and 2724 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2725 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2726 is:  nan\n",
      "The cosine similarity between the documents  1 and 2727 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2728 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2729 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2730 is:  nan\n",
      "The cosine similarity between the documents  1 and 2731 is:  nan\n",
      "The cosine similarity between the documents  1 and 2732 is:  nan\n",
      "The cosine similarity between the documents  1 and 2733 is:  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between the documents  1 and 2734 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2735 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2736 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2737 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2738 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2739 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2740 is:  nan\n",
      "The cosine similarity between the documents  1 and 2741 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2742 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2743 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2744 is:  nan\n",
      "The cosine similarity between the documents  1 and 2745 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2746 is:  nan\n",
      "The cosine similarity between the documents  1 and 2747 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2748 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2749 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2750 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2751 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2752 is:  nan\n",
      "The cosine similarity between the documents  1 and 2753 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2754 is:  nan\n",
      "The cosine similarity between the documents  1 and 2755 is:  nan\n",
      "The cosine similarity between the documents  1 and 2756 is:  nan\n",
      "The cosine similarity between the documents  1 and 2757 is:  nan\n",
      "The cosine similarity between the documents  1 and 2758 is:  nan\n",
      "The cosine similarity between the documents  1 and 2759 is:  nan\n",
      "The cosine similarity between the documents  1 and 2760 is:  nan\n",
      "The cosine similarity between the documents  1 and 2761 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2762 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2763 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2764 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2765 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2766 is:  nan\n",
      "The cosine similarity between the documents  1 and 2767 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2768 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2769 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2770 is:  nan\n",
      "The cosine similarity between the documents  1 and 2771 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2772 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2773 is:  nan\n",
      "The cosine similarity between the documents  1 and 2774 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2775 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2776 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2777 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2778 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2779 is:  nan\n",
      "The cosine similarity between the documents  1 and 2780 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2781 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2782 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2783 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2784 is:  nan\n",
      "The cosine similarity between the documents  1 and 2785 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2786 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2787 is:  nan\n",
      "The cosine similarity between the documents  1 and 2788 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2789 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2790 is:  nan\n",
      "The cosine similarity between the documents  1 and 2791 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2792 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2793 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2794 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2795 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2796 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2797 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2798 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2799 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2800 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2801 is:  nan\n",
      "The cosine similarity between the documents  1 and 2802 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2803 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2804 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2805 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2806 is:  nan\n",
      "The cosine similarity between the documents  1 and 2807 is:  nan\n",
      "The cosine similarity between the documents  1 and 2808 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2809 is:  nan\n",
      "The cosine similarity between the documents  1 and 2810 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2811 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2812 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2813 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2814 is:  nan\n",
      "The cosine similarity between the documents  1 and 2815 is:  nan\n",
      "The cosine similarity between the documents  1 and 2816 is:  nan\n",
      "The cosine similarity between the documents  1 and 2817 is:  nan\n",
      "The cosine similarity between the documents  1 and 2818 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2819 is:  nan\n",
      "The cosine similarity between the documents  1 and 2820 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2821 is:  0.0\n",
      "The cosine similarity between the documents  1 and 2822 is:  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13936/3750801822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbow_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         print(\"The cosine similarity between the documents \", i, \"and\", j, \"is: \",\n\u001b[1;32m----> 4\u001b[1;33m               cosine_similarity(bow_matrix.toarray()[i], bow_matrix.toarray()[j]))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m         \u001b[0mcsr_todense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for i in range(bow_matrix.shape[0]):\n",
    "#     for j in range(i + 1, bow_matrix.shape[0]):\n",
    "#         print(\"The cosine similarity between the documents \", i, \"and\", j, \"is: \",\n",
    "#               cosine_similarity(bow_matrix.toarray()[i], bow_matrix.toarray()[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c319fe97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'term expansion and finbert ﬁne - tuning for hypernym and synonym ranking of financial terms ankush chopra∗† , sohom ghosh† fidelity investments , ai coe , bengaluru , india { ankush01729 , sohom1ghosh}@gmail.com abstract hypernym and synonym matching are one of the mainstream natural language processing ( nlp ) tasks . in this paper , we present systems that at- tempt to solve this problem . we designed these systems to participate in the finsim-3 , a shared task of finnlp workshop at ijcai-2021 . the shared task is focused on solving this problem for the ﬁnancial domain . we experimented with var- ious transformer based pre - trained embeddings by ﬁne - tuning these for either classiﬁcation or phrase similarity tasks . we also augmented the provided dataset with abbreviations derived from prospectus provided by the organizers and deﬁnitions of the ﬁnancial terms from dbpedia [ auer et al . , 2007 ] , investopedia , and the financial industry business ontology ( fibo ) . our best performing system uses both finbert [ araci , 2019 ] and data augmenta- tion from the afore - mentioned sources . we ob- served that term expansion using data augmenta- tion in conjunction with semantic similarity is ben- eﬁcial for this task and could be beneﬁcial for the other tasks that deal with short phrases . our best performing model ( accuracy : 0.917 , rank : 1.156 ) was developed by ﬁne - tuning sentence- bert [ reimers et al . , 2019 ] ( with finbert at the backend ) over an extended labelled set created us- ing the hierarchy of labels present in fibo . introduction 1 ontologies are rich sources of information that provide deep information about the underlying concepts and entities . this information is described for a speciﬁc domain , contains the clearly deﬁned relationship , and organizes in a deﬁned struc- ture mostly as a hierarchy . these properties make ontologies a great source for getting a deeper understanding of the rela- tionship and properties of resources from the domain in con- sideration . public knowledge graphs and ontologies like dbpedia and yago have been shown to work on various applications like ∗contact author †equal contribution the ones described in [ kobilarov et al . , 2009 ] and [ hahm et al . , 2014 ] . this has motivated and paved ways for the creation of domain focused ontologies like fibo1 . effective techniques that enable identifying lexical similar- ity between the terms or concepts increase the effectiveness of the ontologies . these methods not only help in building new ontologies faster or augment the existing ones , but also it helps in the effective querying and concept search . finsim [ maarouf et al . , 2020 ; mansar et al . , 2021 ] com- petitions are being held to promote the development of effec- tive similarity measures . in the third edition of the competi- tion finsim-32 ( being held in conjunction with 30th interna- tional joint conference on artiﬁcial intelligence ( ijcai-21 ) ) , the participants are challenged to develop methods and sys- tems to assign hypernym and synonyms to ﬁnancial terms by mapping them to one of the 17 high - level ﬁnancial concepts present in fibo . in this paper , we present the systems developed by our team lipi for hypernym and synonym assignment . we ex- perimented with basic featurization methods like tf - idf and advanced methods like pre - trained embedding models . our top 3 systems use pre - trained finbert [ araci , 2019 ] embed- ding model that was ﬁne - tuned on the data speciﬁc to ﬁnan- cial domain . we also augmented the training data by utilizing the knowledge from dbpedia , investopedia , fibo and text corpus of prospectus shared with us . we describe the works related to our solution in the next section . section 3 contains the formal problem statement , followed by data description in section 4 . we describe our top three systems in section 5 . section 6 contains the details of the experimentation that we performed and the results from some of them . we draw our conclusions in section 7 while giving a glimpse of things that we would like to try in the future . 2 related works hypernym - hyponym extraction and learning text similarity using semantic representations have been very challenging areas of research for the nlp community . semeval-2018 task 9 [ camacho - collados et al . , 2018 ] was such an instance . 1https://spec.edmcouncil.org/ﬁbo/ 2https://sites.google.com/nlg.csie.ntu.edu.tw/ﬁnnlp2021/shared- task-ﬁnsim ( accessed on 8th july 2021 ) proceedings of the third workshop on financial technology and natural language processing ( finnlp@ijcai 2021 ) , pages 46 - 51 , online , august 19 , 2021 .     \\n\\n 46 \\x0c team crim [ bernier - colborne and barri`ere , 2018 ] per- formed the best in this shared task . they combined a super- vised word embedding based approach with an unsupervised pattern discovery based approach . the finsim shared tasks [ maarouf et al . , 2020 ; mansar et al . , 2021 ] deal with adopt- ing these challenges speciﬁc to the financial domain . team iit - k [ keswani et al . , 2020 ] won finsim-1 using a combi- nation of context - free static embedding word2vec [ mikolov et al . , 2013 ] and contextualized dynamic embedding bert [ devlin et al . , 2019 ] . anand et al . [ anand et al . , 2020 ] from the team finsim20 explored the use of cosine similarity be- tween terms and labels encoded using universal sentence en- coder [ cer et al . , 2018 ] . they also tried to extract hypernyms automatically using graph based approaches . team polyu- cbs [ chersoni and huang , 2021 ] won finsim-2 shared task using logistic regression trained over word embedding and probabilities derived from bert [ devlin et al . , 2019 ] model . they also experimented with gpt-2 [ radford et al . , 2019 ] . team l3i - lbpam [ nguyen et al . , 2021 ] compris- ing nguyen et al . performed better than the baseline by us- ing sentence bert [ reimers et al . , 2019 ] to calculate co- sine similarity between terms and hypernyms . [ saini , 2020 ; pei and zhang , 2021 ] and [ jurgens and pilehvar , 2016 ] dis- cussed various techniques to enrich the data which was avail- able for training . in this edition of finsim , the number of training samples and labels ( ﬁnancial concepts ) were more than the previous two editions . 3 problem statement given a set f consisting of n tuples of ﬁnancial terms and their hypernyms / top - level concepts / labels i.e. f = { ( t1 , h1 ) , ( t2 , h2 ) , ... ( tn , hn ) } where hi represents the hyper- nym corresponding to the ith term ti and hi(cid:15 ) set of labels men- tioned in table 1 . for every unseen ﬁnancial term , our task is to generate a ranked list ˆyi consisting of these 17 hypernyms in order of decreasing semantic similarity . evaluation metrics the expected output is a raked list of predicted labels for every scored instance . the proposed sys- tems are evaluated based on accuracy and mean rank met- rices as per the shared task rules . evaluation script was pro- vided by organizers , where accuracy and mean rank were de- ﬁned as : accuracy = 1 n m eanrank = 1 i=1 ( ˆyi.index(yi ) ) n where ˆyi is the ranked list ( with index starting from 1 ) of pre- dicted labels corresponding to the expected label yi . i is an identity matrix . i=1 i(yi = ˆyi[1 ] ) ( cid:80)n ( cid:80)n 4 data 4.1 data description the training dataset shared for this task has a total of 1050 single and multi - word terms tagged to 17 different classes / labels . more than 91 % of the terms have 6 words or less and the longest term has 22 words . there were 10 du- plicate entries , and 3 terms were assigned 2 different labels . along with this , a corpus of prospectuses in english was pro- vided that had 211 documents . some of the terms mentioned label equity index regulatory agency credit index central securities depository debt pricing and yields bonds swap stock corporation option funds future credit events mmis stocks parametric schedules forward securities restrictions total count 280 205 125 107 58 55 36 25 24 22 19 18 17 17 15 9 8 1040 table 1 : label distribution in the training set in the training data were present in the corpus . table 1 shows the distribution of these labels in the training set . 4.2 data augmentation since the majority of the terms had only a few tokens , we decided to expand the terms wherever possible using various sources . this approach had also been adopted by [ saini , 2020 ] and [ pei and zhang , 2021 ] while participating in finsim-1 and finsim-2 respectively . acronym expansion : as mentioned by keswani et al . [ keswani et al . , 2020 ] , the presence of acronyms created a major issue in maintaining consistency . we used the abbre- viation extractor available in spacy3[honnibal et al . , 2020 ] package on the corpus of the prospectus to extract all the acronyms and their expansions . upon manual inspection of a sample output , we identiﬁed that not all the extracted items were valid acronyms and their expansions . we cleaned the extracted list by dropping the records where : • expansion had equal or less length than the acronym . • expansion had parenthesis • extracted acronym was a valid english word such as ” fund ” or ” germany ” . • the expansion had less than or equal to 5 characters . we managed to extract 635 acronyms from the prospectus corpus after applying the above exclusions . we used this data to expand the matching terms in the given train set and test sets . deﬁnitions from dbpedia : we used the dbpedia search api4 to extract the description of the terms present in the 3https://spacy.io/ 4https://lookup.dbpedia.org/api/search 47 \\x0c train and test sets . we present such an example in fig- ure 1 . in addition to the description , the label was also re- tained from the result payload to identify the right descrip- tion for the input terms . we tried token overlap - based simi- larity of input terms with both matching labels and descrip- tions . we decided to use the label to term match for descrip- tion matching after going through a randomly drawn sam- ple . we cleaned both input terms and labels from dbpedia results by converting them to lower case , replacing punctua- tions by space , removing repetitive spaces , and singularizing the text . we calculated the token overlap ratios for cleaned term and dbpedia labels using the formulas mentioned be- low : ratio1 = length(s1 ∩ s2)/length(s1 ) , ratio2 = length(s2 / length(s1 where s1 and s2 represents sets of to- kenized cleaned terms and tokenized and cleaned dbpedia labels respectively . we empirically decided to use all the in- stances with ratio1 = 1 and ratio2 < = 1.25 for matching a dbpedia label ( and hence description ) to the input term . deﬁnitions from investopedia and fibo : inspired by [ saini , 2020 ] , we obtained deﬁnitions of the terms present in investopedia ’s data dictionary5 by crawling it . we down- loaded a glossary of ﬁnancial terms from the website of fibo . we cleaned all the terms from the train and test set and also the terms present in investopedia ’s data dictionary using the steps described in the above dbpedia section . we then as- signed the investopedia or fibo deﬁnition to the terms from the train and test sets where cleaned terms from train and test data matched to cleaned investopedia terms perfectly . the test set which was provided to us had 326 terms . we augmented the original train and test set with the records where we could either ﬁnd deﬁnition or expansion using the above sources . the train set size increased to 1801 records and the test set size increased to 607 after the data augmen- tation . we present an example of data augmentation for the term ” callable bond ” in table 2 . table 3 states the number of instances we used from each of the sources to augment the data we had . 5 system description we tried to solve this problem as the term classiﬁcation and term similarity problems . two of our 3 submissions are mod- elled as the term classiﬁcation problem , whereas the third sys- tem is designed to be a phrase / sentence similarity problem be- tween terms ( or expanded terms from the augmented dataset ) and the deﬁnitions of 17 class labels that were extracted from fibo / internet . all the systems rely on semantic similarity and use finbert model to generate the term or token embed- ding representations . we divided the given data into training and validation sets having 841 and 209 terms respectively . 5.1 system - 1 ( s1 ) this is the simplest of our proposed systems , where we did not use the augmented dataset and stuck to the original set that was shared by organizers . we loaded finbert pre - trained 5https://www.investopedia.com/ﬁnancial-term-dictionary- 4769738 model and ﬁne - tuned it by trying to classify the representa- tion of [ cls ] token into one of the 17 labels mentioned pre- viously . since the original data did not have longer terms , we kept the maximum length to 32 , and train and validation batch sizes of 64 . we used adam optimizer with a learning rate of 0.00002 . we ran the model for 40 epochs and picked the model saved after 18th epoch based on the performance on the validation set . finally , we ranked the predictions based on the predicted probability of each class . 5.2 system - 2 ( s2 ) this system is similar to system-1 with the only difference that data being the augmented set and not the original dataset . since the augmented dataset has the descriptions of the terms , the input is considerably longer . hence , we increased the maximum length to 256 while keeping all the other hyper- parameters the same . after , training the model for 40 epochs we selected the model saved after the 17th epoch as the best model based on validation set performance . 5.3 system -3 ( s3 ) we explored the fibo ontology to understand the hierarchy [ stepiˇsnik perdih et al . , 2021 ] of the 17 labels as depicted in figure 2 . we used the augmented data described in sec- tion 4.2 to create a labelled dataset having similarity scores . for every term deﬁnition ( t ) to label deﬁnition ( l ) mapping which existed in the extended training set , we assigned a sim- ilarity score of 1.0 to the ( t , l ) pair and picked up 10 train- ing instances randomly ensuring none of their label deﬁnition was same as l. for each of the label deﬁnitions ( ll ) present in this sample , we extracted its root node and ﬁrst child node . we did the same for the original label deﬁnition ( l ) . then , we compared these nodes . if the root node and ﬁrst child node of l were different from that of ll then we assigned a similar- ity score of 0 to the ( t , ll ) pair . if the root nodes were the same , we assigned a similarity score of ’ k ’ when the ﬁrst child nodes differed and a similarity score of ’ 2k ’ when they were the same ( where 0 < k < 1 ) . we empirically ﬁgured out that k=0.4 works the best . as expected , the number of instances with a similarity score equal to 0 increased substantially . we under - sampled such instances and the new training set had 30 % instances with similarity score 1.0 , 12 % instances with similarity score ’ k ’ , 28 % instances with similarity score ’ 2k ’ and 30 % instances with similarity score 0 . after that , we ﬁne- tuned a finbert [ araci , 2019 ] model using sentence bert [ reimers et al . , 2019 ] framework with this newly generated labelled data for 25 epochs with a batch size of 20 . our ob- jective was to minimize the multiple negatives ranking loss and online contrastive loss . we used a margin of 0.5 and co- sine distance as a distance metric while training this model . finally , we converted all of the 17 labels ’ deﬁnitions and term deﬁnitions from the validation set to vectors using this ﬁne- tuned model . for every such term deﬁnition , we performed a semantic search over the label vectors and ranked them in decreasing order of similarity . system 2 and 3 take advantage of term expansion during both model training and scoring phases , which causes certain ob- servations to appear more than once ( reference : table 3 ) . we 48 \\x0c figure 1 : sample output from dbpedia search api expanded term / term deﬁnition callable bond bond that includes a stipulation allowing the issuer the right to repurchase and retire the bond at the call price after the call protection period a callable bond ( also called redeemable bond ) is a type of bond ( debt security ) that allows the issuer of the bond to retain the privilege of redeeming the bond at some point before the bond reaches its date of maturity . table 2 : result of data augmentation of the term ” callable bond ” label bonds source original and acronym expansion bonds fibo bonds dbpedia data source original modelling data dbpedia fibo investopedia acronym expansion count 1040 257 236 85 218 table 3 : details of various data sources derive the ﬁnal prediction by averaging the output probabili- ties for all the 17 classes for all the occurrences of the term . 6 experimentation and results we had 1040 observations after removing the duplicates . we did an 80:20 split to create a training and validation set from this . we augmented the given modelling set by incorporating deﬁnitions from dbpedia , fibo and investopedia . we used the list of acronyms extracted from the prospectus corpus to create a copy with acronym expansion . this helped us to in- crease the original data to 1836 records ( mentioned in table 1 ) . it should be noted that we could not ﬁnd the expansions for all the terms given in the modelling set . train and valida- tion set sizes for the original modelling set and expanded data were ( 832 & 208 ) and ( 1469 & 366 ) respectively . we established a baseline by running the scripts provided by the organizers . then , we considered original modelling data and ﬁne - tuned base bert - cased model [ devlin et al . , 2019 ] to predict the class label by taking the representa- tion of [ cls ] token while passing it through few layers of a feed - forward network . this performed better than base- line . we then tried the same bert - base model on the ex- panded dataset , which gave us further performance improve- ment . since the only change between these runs was the data , the improvement can be attributed to the expanded data . we experimented with a few of the other pre - trained mod- els that are available on the huggingface model repository [ wolf et al . , 2020 ] . we observed clear improvement when we used the finbert model which was trained on data spe- ciﬁc to the ﬁnancial domain . the model performance succes- sively increased when we used a combination of data expan- sion with finbert . furthermore , we tried to ﬁne - tune fin- bert using sentence transformers [ reimers et al . , 2019 ] to capture semantic textual similarity . for this , we used several combinations of term and term deﬁnitions with label and la- bel deﬁnitions . all the hyperparameters for the ﬁnal 3 models are already given in the system description . after rigorous experimenta- tion , these hyperparameters were selected empirically based on validation set performance . the results are presented in table 4 . since the number of submissions was restricted to 3 for each team , we do not have the performance numbers of the bert models in the test set . analysing the results we see that sentencebert trained with finbert at the backed as mentioned in section-5.3 performed the best . 7 conclusion and future works in this work , we attempted to solve the hypernym and syn- onym discovery hosted at finsim-3 . this challenge aimed to enable the better use of ontologies like fibo using hy- pernyms and synonyms , and we used these ontologies them- selves to develop our systems which perform signiﬁcantly better than the provided baseline systems . this proves the present use of these ontologies . the presented solution is recursive in a sense as it uses knowledge from ontologies to further increase the effectiveness and use of the same . apart from data augmentation , our solution relies upon se- mantic similarity learnt from pre - trained embedding models 49 \\x0c figure 2 : label hierarchy from fibo . bold ( leaf nodes ) denotes the labels . validation set test set data rank acc . model 0.498 2.158 org . base-1 0.876 1.201 org . base-2 0.899 1.177 org . bert 0.928 1.153 bert ext . 0.928 1.117 finbert(s1 ) org . 0.942 1.110 finbert(s2 ) ext . 0.947 1.086 ext . sbert(s3 ) rank acc . 0.564 1.941 0.669 1.75 - - - - 0.886 1.257 0.895 1.220 0.917 1.156 table 4 : results on validation and test set . org . represents original and ext . represents extended . base refers to baseline . that were learnt on the relevant domain . we observed the clear beneﬁts of domain speciﬁc pretraining during the ex- perimentation . in future , we would like to explore knowledge graphs ( as described in [ portisch et al . , 2021 ] ) to further improve the improve performance of the models . we also want to ex- plore other variants of finbert [ araci , 2019 ] and ﬁne - tune them using the masked language modeling technique ( as mentioned by the winner of finsim-2 [ chersoni and huang , 2021 ] ) and next sentence prediction objective . moreover , this research can be extended by extracting sentences present in the prospectus ( similar to [ goel et al . , 2021 ] ) to create pos- itive and negative samples . references [ anand et al . , 2020 ] vivek anand , yash agrawal , aarti pol , and vasudeva varma . finsim20 at the finsim task : mak- ing sense of text in ﬁnancial domain . in proceedings of the second workshop on financial technology and natu- ral language processing , pages 104–107 , kyoto , japan , 5 january 2020 . [ araci , 2019 ] dogu araci . finbert : financial sentiment analysis with pre - trained language models , 2019 . [ auer et al . , 2007 ] s¨oren auer , christian bizer , georgi ko- bilarov , jens lehmann , richard cyganiak , and zachary ives . dbpedia : a nucleus for a web of open data , 2007 . [ bernier - colborne and barri`ere , 2018 ] gabriel bernier- colborne and caroline barri`ere . crim at semeval-2018 task 9 : a hybrid approach to hypernym discovery . in pro- ceedings of the 12th international workshop on semantic evaluation , pages 725–731 , new orleans , louisiana , june 2018 . association for computational linguistics . [ camacho - collados et al . , 2018 ] jose camacho - collados , claudio delli bovi , luis espinosa - anke , sergio oramas , tommaso pasini , enrico santus , vered shwartz , roberto navigli , and horacio saggion . semeval-2018 task 9 : hypernym discovery . in proceedings of the 12th interna- tional workshop on semantic evaluation , pages 712–724 , new orleans , louisiana , june 2018 . association for computational linguistics . [ cer et al . , 2018 ] daniel cer , yinfei yang , sheng yi kong , nan hua , nicole limtiaco , rhomni st . john , noah con- stant , mario guajardo - cespedes , steve yuan , chris tar , yun - hsuan sung , brian strope , and ray kurzweil . uni- versal sentence encoder , 2018 . [ chersoni and huang , 2021 ] emmanuele chersoni and chu- ren huang . polyu - cbs at the finsim-2 task : combin- ing distributional , string - based and transformers - based features for hypernymy detection in the financial do- main , page 316–319 . association for computing machin- ery , new york , ny , usa , 2021 . [ devlin et al . , 2019 ] jacob devlin , ming - wei chang , ken- ton lee , and kristina toutanova . bert : pre - training of deep bidirectional transformers for language understand- ing . in proceedings of the 2019 conference of the north american chapter of the association for computational linguistics : human language technologies , volume 1 ( long and short papers ) , pages 4171–4186 , minneapo- lis , minnesota , june 2019 . association for computational linguistics . [ goel et al . , 2021 ] tushar goel , vipul chauhan , ishan verma , tirthankar dasgupta , and lipika dey . tcs witm 2021 @finsim-2 : transformer based models for auto- matic classiﬁcation of financial terms , page 311–315 . 50 \\x0c in companion pro- cial data with customized corpus . ceedings of the web conference 2021 , www ’ 21 , page 307–310 , new york , ny , usa , 2021 . association for computing machinery . [ portisch et al . , 2021 ] jan portisch , michael hladik , and heiko paulheim . finmatcher at finsim-2 : hypernym de- tection in the financial services domain using knowl- edge graphs , page 293–297 . association for computing machinery , new york , ny , usa , 2021 . [ radford et al . , 2019 ] alec radford , jeff wu , rewon child , david luan , dario amodei , and ilya sutskever . language models are unsupervised multitask learners , 2019 . [ reimers et al . , 2019 ] nils reimers , iryna gurevych , nils reimers , iryna gurevych , nandan thakur , nils reimers , johannes daxenberger , and iryna gurevych . sentence- bert : sentence embeddings using siamese bert - networks . in proceedings of the 2019 conference on empirical methods in natural language processing . association for computational linguistics , 2019 . [ saini , 2020 ] anuj saini . anuj at the finsim task : anuj@finsim¡vlearning semantic representation of ﬁ- nancial domain with investopedia . in proceedings of the second workshop on financial technology and natural language processing , pages 93–97 , kyoto , japan , 5 jan- uary 2020 . [ stepiˇsnik perdih et al . , 2021 ] timen perdih , senja pollak , and blaˇz ˇskrlj . jsi at the finsim-2 task : ontology - augmented financial concept classiﬁcation , page 298–301 . association for computing machinery , new york , ny , usa , 2021 . stepiˇsnik [ wolf et al . , 2020 ] thomas wolf , lysandre debut , victor sanh , julien chaumond , clement delangue , anthony moi , pierric cistac , tim rault , r´emi louf , morgan funtowicz , joe davison , sam shleifer , patrick von platen , clara ma , yacine jernite , julien plu , canwen xu , teven le scao , sylvain gugger , mariama drame , quentin lhoest , and alexander m. rush . huggingface ’s transformers : state - of - the - art natural language processing , 2020 . association for computing machinery , new york , ny , usa , 2021 . [ hahm et al . , 2014 ] younggyun hahm , jungyeul park , kyungtae lim , youngsik kim , dosam hwang , and key - sun choi . named entity corpus construction us- in lrec , pages ing wikipedia and dbpedia ontology . 2565–2569 , 2014 . [ honnibal et al . , 2020 ] matthew honnibal , ines montani , soﬁe van landeghem , and adriane boyd . spacy : industrial - strength natural language processing in python , 2020 . [ jurgens and pilehvar , 2016 ] david jurgens and moham- mad taher pilehvar . semeval-2016 task 14 : semantic taxonomy enrichment . in proceedings of the 10th interna- tional workshop on semantic evaluation ( semeval-2016 ) , pages 1092–1102 , san diego , california , june 2016 . as- sociation for computational linguistics . [ keswani et al . , 2020 ] vishal keswani , sakshi singh , and ashutosh modi . iitk at the finsim task : hypernym de- tection in ﬁnancial domain via context - free and contextu- in proceedings of the second alized word embeddings . workshop on financial technology and natural language processing , pages 87–92 , kyoto , japan , 5 january 2020 . [ kobilarov et al . , 2009 ] georgi kobilarov , tom scott , yves raimond , silver oliver , chris sizemore , michael smethurst , christian bizer , and robert lee . media meets semantic web – how the bbc uses dbpedia and linked data to make connections . in lora aroyo , paolo traverso , fabio ciravegna , philipp cimiano , tom heath , eero hyv¨onen , riichiro mizoguchi , eyal oren , marta sabou , and elena simperl , editors , the semantic web : re- search and applications , pages 723–737 , berlin , heidel- berg , 2009 . springer berlin heidelberg . [ maarouf et al . , 2020 ] ismail el maarouf , youness mansar , virginie mouilleron , and dialekti valsamou - stanislawski . the finsim 2020 shared task : learning semantic repre- sentations for the ﬁnancial domain . in proceedings of the second workshop on financial technology and natural language processing , pages 81–86 , kyoto , japan , 5 jan- uary 2020 . [ mansar et al . , 2021 ] youness mansar , juyeon kang , and is- mail el maarouf . the finsim-2 2021 shared task : learn- ing semantic similarities for the financial domain , page 288–292 . association for computing machinery , new york , ny , usa , 2021 . [ mikolov et al . , 2013 ] tomas mikolov , kai chen , greg cor- rado , and jeffrey dean . efﬁcient estimation of word rep- resentations in vector space , 2013 . [ nguyen et al . , 2021 ] nhu khoa nguyen , emanuela boros , gael lejeune , antoine doucet , and thierry delahaut . l3i lbpam at the finsim-2 task : learning financial seman- tic similarities with siamese transformers , page 302–306 . association for computing machinery , new york , ny , usa , 2021 . [ pei and zhang , 2021 ] yulong pei and qian zhang . goat at the ﬁnsim-2 task : learning word representations of ﬁnan- 51 \\x0c'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_Anth = \" \".join(Anth_lst)\n",
    "s_Anth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1519a021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'term expansion and finbert ﬁne - tuning for hypernym and synonym ranking of financial terms ankush chopra∗† , sohom ghosh† fidelity investments , ai coe , bengaluru , india { ankush01729 , sohom1ghosh}@gmail.com 1 2 0 2 \\n \\n l u j \\n \\n 9 2 \\n \\n \\n ] l c . s c [ \\n \\n \\n 1 v 4 6 7 3 1 . 7 0 1 2 : v i x r a abstract hypernym and synonym matching are one of the mainstream natural language processing ( nlp ) tasks . in this paper , we present systems that at- tempt to solve this problem . we designed these systems to participate in the finsim-3 , a shared task of finnlp workshop at ijcai-2021 . the shared task is focused on solving this problem for the ﬁnancial domain . we experimented with var- ious transformer based pre - trained embeddings by ﬁne - tuning these for either classiﬁcation or phrase similarity tasks . we also augmented the provided dataset with abbreviations derived from prospectus provided by the organizers and deﬁnitions of the ﬁnancial terms from dbpedia [ auer et al . , 2007 ] , investopedia , and the financial industry business ontology ( fibo ) . our best performing system uses both finbert [ araci , 2019 ] and data augmenta- tion from the afore - mentioned sources . we ob- served that term expansion using data augmentation in conjunction with semantic similarity is beneﬁcial for this task and could be useful for the other tasks that deal with short phrases . our best performing model ( accuracy : 0.917 , rank : 1.156 ) was devel- oped by ﬁne - tuning sentencebert [ reimers et al . , 2019 ] ( with finbert at the backend ) over an ex- tended labelled set created using the hierarchy of labels present in fibo . 1 introduction ontologies are rich sources of information that provide deep information about the underlying concepts and entities . this information is described for a speciﬁc domain . it contains the clearly deﬁned relationships , and it is organized in a deﬁned structure mostly as a hierarchy . these properties make on- tologies a great source for getting a deeper understanding of the relationship and properties of resources of the domain in consideration . public knowledge graphs and ontologies like dbpedia and yago have been shown to work on various applications like ∗contact author †equal contribution the ones described in [ kobilarov et al . , 2009 ] and [ hahm et al . , 2014 ] . this has motivated and paved ways for the creation of domain focused ontologies like fibo1 . effective techniques that enable identifying lexical similar- ity between the terms or concepts increase the effectiveness of the ontologies . these methods not only help in building new ontologies faster or augment the existing ones , but also it helps in the effective querying and searching of concepts . finsim [ maarouf et al . , 2020 ; mansar et al . , 2021 ] compe- titions are being held to promote the development of effective similarity measures . in the third edition of the competition finsim-32 ( being held in conjunction with the 30th interna- tional joint conference on artiﬁcial intelligence ( ijcai-21 ) ) , the participants are challenged to develop methods and sys- tems to rank hypernym and synonyms to ﬁnancial terms by mapping them to one of the 17 high - level ﬁnancial concepts present in fibo . in this paper , we present the systems developed by our team lipi for hypernym and synonym ranking . we experi- mented with basic featurization methods like tf - idf and ad- vanced methods like pre - trained embedding models . our top 3 systems use pre - trained finbert [ araci , 2019 ] embedding model that was ﬁne - tuned on the data speciﬁc to ﬁnancial do- main . we also augmented the training data by utilizing the knowledge from dbpedia , investopedia , fibo and text cor- pus of prospectus shared with us . we describe the works re- lated to our solution in the next section . section 3 contains the formal problem statement , followed by data description in section 4 . we describe our top three systems in section 5 . section 6 contains the details of the experimentation that we performed and the results obtained from some of them . we draw our conclusions in section 7 while giving a glimpse of things that we would like to try in the future . 2 related works hypernym - hyponym extraction and learning text similarity using semantic representations have been very challenging areas of research for the nlp community . semeval-2018 task 9 [ camacho - collados et al . , 2018 ] was such an instance . 1https://spec.edmcouncil.org/ﬁbo/ 2https://sites.google.com/nlg.csie.ntu.edu.tw/ﬁnnlp2021/shared- task-ﬁnsim ( accessed on 8th july 2021 ) \\n\\n\\x0c team crim [ bernier - colborne and barri`ere , 2018 ] per- formed the best in this shared task . they combined a super- vised word embedding based approach with an unsupervised pattern discovery based approach . the finsim shared tasks [ maarouf et al . , 2020 ; mansar et al . , 2021 ] deal with adopt- ing these challenges speciﬁc to the financial domain . team iit - k [ keswani et al . , 2020 ] won finsim-1 using a combi- nation of context - free static embedding word2vec [ mikolov et al . , 2013 ] and contextualized dynamic embedding bert [ devlin et al . , 2019 ] . anand et al . [ anand et al . , 2020 ] from the team finsim20 explored the use of cosine similarity be- tween terms and labels encoded using universal sentence en- coder [ cer et al . , 2018 ] . they also tried to extract hypernyms automatically using graph based approaches . team polyu- cbs [ chersoni and huang , 2021 ] won finsim-2 shared task using logistic regression trained over word embedding and probabilities derived from bert [ devlin et al . , 2019 ] model . they also experimented with gpt-2 [ radford et al . , 2019 ] . team l3i - lbpam [ nguyen et al . , 2021 ] compris- ing nguyen et al . performed better than the baseline by us- ing sentence bert [ reimers et al . , 2019 ] to calculate co- sine similarity between terms and hypernyms . [ saini , 2020 ; pei and zhang , 2021 ] and [ jurgens and pilehvar , 2016 ] dis- cussed various techniques to enrich the data which was avail- able for training . in this edition of finsim , the number of training samples and labels ( ﬁnancial concepts ) were more than the previous two editions . their 3 problem statement terms given a set f consisting of n tuples of ﬁnancial i.e. and concepts / labels hypernyms / top - level f = { ( t1 , h1 ) , ( t2 , h2 ) , ... ( tn , hn ) } where hi represents the hypernym corresponding to the ith term ti and hi(cid:15 ) set of labels mentioned in table 1 . for every unseen ﬁnancial term , our task is to generate a ranked list ˆyi consisting of these 17 hypernyms in order of decreasing semantic similarity . evaluation metrics the expected output is a raked list of predicted labels for every scored instance . the proposed sys- tems are evaluated based on accuracy and mean rank met- rices as per the shared task rules . evaluation script was pro- vided by organizers , where accuracy and mean rank were de- ﬁned as : accuracy = 1 n m eanrank = 1 i=1 ( ˆyi.index(yi ) ) n where ˆyi is the ranked list ( with index starting from 1 ) of pre- dicted labels corresponding to the expected label yi . i is an identity matrix . i=1 i(yi = ˆyi[1 ] ) ( cid:80)n ( cid:80)n 4 data 4.1 data description the training dataset shared for this task has a total of 1050 single and multi - word terms tagged to 17 different classes / labels out of which 1040 term - label pairs are unique . more than 91 % of the terms have 6 words or less and the longest term has 22 words . there were 10 duplicate entries , and 3 terms were assigned 2 different labels . along with this , label equity index regulatory agency credit index central securities depository debt pricing and yields bonds swap stock corporation option funds future credit events mmis stocks parametric schedules forward securities restrictions total count 280 205 125 107 58 55 36 25 24 22 19 18 17 17 15 9 8 1040 table 1 : label distribution in the training set a corpus of prospectuses in english that had 211 documents was provided . some of the terms mentioned in the training data were present in the corpus . table 1 shows the distribu- tion of these labels in the training set . 4.2 data augmentation since the majority of the terms had only a few tokens , we decided to expand the terms wherever possible using various sources . this approach had also been adopted by [ saini , 2020 ] and [ pei and zhang , 2021 ] while participating in finsim-1 and finsim-2 respectively . acronym expansion : as mentioned by keswani et al . [ keswani et al . , 2020 ] , the presence of acronyms created a major issue in maintaining consistency . we used the abbre- viation extractor available in spacy3[honnibal et al . , 2020 ] package on the corpus of the prospectus to extract all the acronyms and their expansions . upon manual inspection of a sample output , we identiﬁed that not all the extracted items were valid acronyms and their expansions . we cleaned the extracted list by dropping the records where : • expansion had equal or less length than the acronym . • expansion had parenthesis • extracted acronym was a valid english word such as ” fund ” or ” germany ” . • the expansion had less than or equal to 5 characters . we managed to extract 635 acronyms from the prospectus corpus after applying the above exclusions . we used this data to expand the matching terms in the given train set and test sets . 3https://spacy.io/ \\n\\n\\x0c deﬁnitions from dbpedia : we used the dbpedia search api4 to extract the description of the terms present in the train and test sets . we present such an example in figure 1 . in ad- dition to the description , the label was also retained from the result payload to identify the right description for the input terms . we tried token overlap - based similarity of input terms with both matching labels and descriptions . we decided to use the label to term match for description matching after go- ing through a randomly drawn sample . we cleaned both input terms and labels from dbpedia results by converting them to lower case , replacing punctuations by space , removing repet- itive spaces , and singularizing the text . we calculated the token overlap ratios for cleaned term and dbpedia labels us- ing these formulas : ratio1 = length(s1 ∩ s2)/length(s1 ) , ratio2 = length(s2)/length(s1 ) where s1 and s2 represents sets of tokenized cleaned terms and tokenized cleaned dbpe- dia labels respectively . we empirically decided to use all the instances with ratio1 = 1 and ratio2 < = 1.25 for match- ing a dbpedia label ( and hence description ) to the input term . deﬁnitions from investopedia and fibo : inspired by [ saini , 2020 ] , we obtained deﬁnitions of the terms present in investopedia ’s data dictionary5 by crawling it . we down- loaded a glossary of ﬁnancial terms from the website of fibo . we cleaned all the terms from the train and test set and also the terms present in investopedia ’s data dictionary using the steps described in the above dbpedia section . we then as- signed the investopedia or fibo deﬁnition to the terms from the train and test sets where cleaned terms from train and test data matched to cleaned investopedia terms perfectly . the test set which was provided to us had 326 terms . we augmented the original train and test set with the records where we could either ﬁnd deﬁnition or expansion using the above sources . the train set size increased to 1836 records and the test set size increased to 607 after the data augmen- tation . we present an example of data augmentation for the term “ callable bond ” in table 2 . table 3 states the number of instances we used from each of the sources to augment the data we had . 5 system description we tried to solve this problem as the term classiﬁcation and term similarity problems . two of our 3 submissions are mod- elled as the term classiﬁcation problem , whereas the third sys- tem is designed to be a phrase / sentence similarity problem be- tween terms ( or expanded terms from the augmented dataset ) and the deﬁnitions of 17 class labels that were extracted from fibo / internet . all the systems rely on semantic similarity and use finbert model to generate the term or token embed- ding representations . we divided the given data into training and validation sets having 832 and 208 terms respectively . 5.1 system - 1 ( s1 ) this is the simplest of our proposed systems , where we did not use the augmented dataset and used only the original set 4https://lookup.dbpedia.org/api/search 5https://www.investopedia.com/ﬁnancial-term-dictionary- 4769738 that was shared by organizers . we loaded finbert pre- trained model and ﬁne - tuned it by trying to classify the repre- sentation of [ cls ] token into one of the 17 labels mentioned previously . since the original data did not have longer terms , we kept the maximum length to 32 , and train and validation batch sizes of 64 . we used adam optimizer with a learning rate of 0.00002 . we ran the model for 40 epochs and picked the model saved after 18th epoch based on the performance on the validation set . finally , we ranked the predictions based on the predicted probability of each class . 5.2 system - 2 ( s2 ) this system is similar to system-1 with the only difference that data being the augmented set and not the original dataset . since the augmented dataset had the descriptions of the terms , the inputs were considerably longer . hence , we increased the maximum length to 256 while keeping all the other hyper- parameters the same . after , training the model for 40 epochs we selected the model saved after the 17th epoch as the best model based on validation set performance . 5.3 system -3 ( s3 ) we explored the fibo ontology to understand the hierarchy [ stepiˇsnik perdih et al . , 2021 ] of the 17 labels as depicted in figure 2 . we used the augmented data described in sec- tion 4.2 to create a labelled dataset having similarity scores . for every term deﬁnition ( t ) to label deﬁnition ( l ) mapping which existed in the extended training set , we assigned a sim- ilarity score of 1.0 to the ( t , l ) pair and picked up 10 train- ing instances randomly ensuring none of their label deﬁnition was same as l. for each of the label deﬁnitions ( ll ) present in this sample , we extracted its root node and ﬁrst child node . we did the same for the original label deﬁnition ( l ) . then , we compared these nodes . if the root node and ﬁrst child node of l were different from that of ll then we assigned a similar- ity score of 0 to the ( t , ll ) pair . if the root nodes were the same , we assigned a similarity score of ’ k ’ when the ﬁrst child nodes differed and a similarity score of ’ 2k ’ when they were the same ( where 0 < k < 1 ) . we empirically ﬁgured out that k=0.4 works the best . as expected , the number of instances with a similarity score equal to 0 increased substantially . we under - sampled such instances and the new training set had 30 % instances with similarity score 1.0 , 12 % instances with similarity score ’ k ’ , 28 % instances with similarity score ’ 2k ’ and 30 % instances with similarity score 0 . after that , we ﬁne- tuned a finbert [ araci , 2019 ] model using sentence bert [ reimers et al . , 2019 ] framework with this newly generated labelled data for 25 epochs with a batch size of 20 . our ob- jective was to minimize the multiple negatives ranking loss and online contrastive loss . we used a margin of 0.5 and co- sine distance as a distance metric while training this model . finally , we converted all of the 17 labels ’ deﬁnitions and term deﬁnitions from the validation set to vectors using this ﬁne- tuned model . for every such term deﬁnition , we performed a semantic search over the label vectors and ranked them in decreasing order of cosine similarity . system 2 and 3 take advantage of term expansion during both model training and scoring phases , which causes certain ob- servations to appear more than once ( reference : table 3 ) . we \\n\\n\\x0c figure 1 : sample output from dbpedia search api expanded term / term deﬁnition callable bond bond that includes a stipulation allowing the issuer the right to repurchase and retire the bond at the call price after the call protection period a callable bond ( also called redeemable bond ) is a type of bond ( debt security ) that allows the issuer of the bond to retain the privilege of redeeming the bond at some point before the bond reaches its date of maturity . table 2 : result of data augmentation of the term ” callable bond ” label bonds source original and acronym expansion bonds fibo bonds dbpedia data source original modelling data dbpedia fibo investopedia acronym expansion count 1040 257 236 85 218 table 3 : details of various data sources derive the ﬁnal prediction by averaging the output probabili- ties for all the 17 classes for all the occurrences of the term . 6 experimentation and results we had 1040 observations after removing the duplicates . we did an 80:20 split to create a training and validation set from this . we augmented the given modelling set by incorporating deﬁnitions from dbpedia , fibo and investopedia . we used the list of acronyms extracted from the prospectus corpus to create a copy with acronym expansion . this helped us to in- crease the original data to 1836 records ( mentioned in table 1 ) . it should be noted that we could not ﬁnd the expansions for all the terms given in the modelling set . train and valida- tion set sizes for the original modelling set and expanded data were ( 832 & 208 ) and ( 1470 & 366 ) respectively . we established a baseline by running the scripts provided by the organizers . then , we considered original modelling data and ﬁne - tuned base bert - cased model [ devlin et al . , 2019 ] to predict the class label by taking the representa- tion of [ cls ] token while passing it through few layers of a feed - forward network . this performed better than base- line . we then tried the same bert - base model on the ex- panded dataset , which gave us further performance improve- ment . since the only major change between these runs was the data , the improvement can be attributed to the expanded data . we experimented with a few of the other pre - trained mod- els that are available on the huggingface model repository [ wolf et al . , 2020 ] . we observed clear improvement when we used the finbert model which was trained on data spe- ciﬁc to the ﬁnancial domain . the model performance succes- sively increased when we used a combination of data expan- sion with finbert . furthermore , we tried to ﬁne - tune fin- bert using sentence transformers [ reimers et al . , 2019 ] to capture semantic textual similarity . for this , we used several combinations of term and term deﬁnitions with label and la- bel deﬁnitions . all the hyperparameters for the ﬁnal 3 models have been already mentioned in the system description . after rigorous experimentation , these hyperparameters were selected empir- ically based on validation set performance . the results are presented in table 4 . since the number of submissions was restricted to 3 for each team , we do not have the performance numbers of the bert models in the test set . analysing the results we see that sentencebert trained with finbert at the backed as mentioned in section-5.3 performed the best . 7 conclusion and future works in this work , we attempted to solve the hypernym and syn- onym discovery hosted at finsim-3 . this challenge aimed to enable the better use of ontologies like fibo using hy- pernyms and synonyms , and we used these ontologies them- selves to develop our systems which perform signiﬁcantly better than the provided baseline systems . this proves the present use of these ontologies . the presented solution is recursive in a sense as it uses knowledge from ontologies to further increase the effectiveness and use of the same . \\n\\n\\x0c figure 2 : label hierarchy from fibo . bold ( leaf nodes ) denotes the labels . validation set test set data rank acc . model 0.498 2.158 org . base-1 0.876 1.201 org . base-2 0.899 1.177 org . bert 0.928 1.153 bert ext . 0.928 1.117 finbert(s1 ) org . 0.942 1.110 finbert(s2 ) ext . 0.947 1.086 ext . sbert(s3 ) rank acc . 0.564 1.941 0.669 1.75 - - - - 0.886 1.257 0.895 1.220 0.917 1.156 table 4 : results on validation and test set . org . represents original and ext . represents extended . base refers to baseline . apart from data augmentation , our solution relies upon se- mantic similarity learnt from pre - trained embedding models that were learnt on the relevant domain . we observed the clear beneﬁts of domain speciﬁc pretraining during the ex- perimentation . in future , we would like to explore knowledge graphs ( as described in [ portisch et al . , 2021 ] ) to further improve the improve performance of the models . we also want to ex- plore other variants of finbert [ araci , 2019 ] and ﬁne - tune them using the masked language modeling technique ( as mentioned by the winner of finsim-2 [ chersoni and huang , 2021 ] ) and next sentence prediction objective . moreover , this research can be extended by extracting sentences present in the prospectus ( similar to [ goel et al . , 2021 ] ) to create more positive and negative samples . references [ anand et al . , 2020 ] vivek anand , yash agrawal , aarti pol , and vasudeva varma . finsim20 at the finsim task : mak- ing sense of text in ﬁnancial domain . in proceedings of the second workshop on financial technology and natu- ral language processing , pages 104–107 , kyoto , japan , 5 january 2020 . [ auer et al . , 2007 ] s¨oren auer , christian bizer , georgi ko- bilarov , jens lehmann , richard cyganiak , and zachary ives . dbpedia : a nucleus for a web of open data , 2007 . [ bernier - colborne and barri`ere , 2018 ] gabriel bernier- colborne and caroline barri`ere . crim at semeval-2018 task 9 : a hybrid approach to hypernym discovery . in pro- ceedings of the 12th international workshop on semantic evaluation , pages 725–731 , new orleans , louisiana , june 2018 . association for computational linguistics . [ camacho - collados et al . , 2018 ] jose camacho - collados , claudio delli bovi , luis espinosa - anke , sergio oramas , tommaso pasini , enrico santus , vered shwartz , roberto navigli , and horacio saggion . semeval-2018 task 9 : hypernym discovery . in proceedings of the 12th interna- tional workshop on semantic evaluation , pages 712–724 , new orleans , louisiana , june 2018 . association for computational linguistics . [ cer et al . , 2018 ] daniel cer , yinfei yang , sheng yi kong , nan hua , nicole limtiaco , rhomni st . john , noah con- stant , mario guajardo - cespedes , steve yuan , chris tar , yun - hsuan sung , brian strope , and ray kurzweil . uni- versal sentence encoder , 2018 . [ chersoni and huang , 2021 ] emmanuele chersoni and chu- ren huang . polyu - cbs at the finsim-2 task : combin- ing distributional , string - based and transformers - based features for hypernymy detection in the financial do- main , page 316–319 . association for computing machin- ery , new york , ny , usa , 2021 . [ devlin et al . , 2019 ] jacob devlin , ming - wei chang , ken- ton lee , and kristina toutanova . bert : pre - training of deep bidirectional transformers for language understand- ing . in proceedings of the 2019 conference of the north american chapter of the association for computational linguistics : human language technologies , volume 1 ( long and short papers ) , pages 4171–4186 , minneapo- lis , minnesota , june 2019 . association for computational linguistics . [ araci , 2019 ] dogu araci . finbert : financial sentiment analysis with pre - trained language models , 2019 . [ goel et al . , 2021 ] tushar goel , vipul chauhan , ishan verma , tirthankar dasgupta , and lipika dey . tcs witm \\n\\n\\x0c [ pei and zhang , 2021 ] yulong pei and qian zhang . goat at the ﬁnsim-2 task : learning word representations of ﬁnan- in companion pro- cial data with customized corpus . ceedings of the web conference 2021 , www ’ 21 , page 307–310 , new york , ny , usa , 2021 . association for computing machinery . [ portisch et al . , 2021 ] jan portisch , michael hladik , and heiko paulheim . finmatcher at finsim-2 : hypernym de- tection in the financial services domain using knowl- edge graphs , page 293–297 . association for computing machinery , new york , ny , usa , 2021 . [ radford et al . , 2019 ] alec radford , jeff wu , rewon child , david luan , dario amodei , and ilya sutskever . language models are unsupervised multitask learners , 2019 . [ reimers et al . , 2019 ] nils reimers , iryna gurevych , nils reimers , iryna gurevych , nandan thakur , nils reimers , johannes daxenberger , and iryna gurevych . sentence- bert : sentence embeddings using siamese bert - networks . in proceedings of the 2019 conference on empirical methods in natural language processing . association for computational linguistics , 2019 . [ saini , 2020 ] anuj saini . anuj at the finsim task : anuj@finsim¡vlearning semantic representation of ﬁ- nancial domain with investopedia . in proceedings of the second workshop on financial technology and natural language processing , pages 93–97 , kyoto , japan , 5 jan- uary 2020 . [ stepiˇsnik perdih et al . , 2021 ] timen perdih , senja pollak , and blaˇz ˇskrlj . jsi at the finsim-2 task : ontology - augmented financial concept classiﬁcation , page 298–301 . association for computing machinery , new york , ny , usa , 2021 . stepiˇsnik [ wolf et al . , 2020 ] thomas wolf , lysandre debut , victor sanh , julien chaumond , clement delangue , anthony moi , pierric cistac , tim rault , r´emi louf , morgan funtowicz , joe davison , sam shleifer , patrick von platen , clara ma , yacine jernite , julien plu , canwen xu , teven le scao , sylvain gugger , mariama drame , quentin lhoest , and alexander m. rush . huggingface ’s transformers : state - of - the - art natural language processing , 2020 . 2021 @finsim-2 : transformer based models for auto- matic classiﬁcation of financial terms , page 311–315 . association for computing machinery , new york , ny , usa , 2021 . [ hahm et al . , 2014 ] younggyun hahm , jungyeul park , kyungtae lim , youngsik kim , dosam hwang , and key - sun choi . named entity corpus construction us- in lrec , pages ing wikipedia and dbpedia ontology . 2565–2569 , 2014 . [ honnibal et al . , 2020 ] matthew honnibal , ines montani , spacy : soﬁe van landeghem , and adriane boyd . industrial - strength natural language processing in python , 2020 . [ jurgens and pilehvar , 2016 ] david jurgens and moham- mad taher pilehvar . semeval-2016 task 14 : semantic taxonomy enrichment . in proceedings of the 10th interna- tional workshop on semantic evaluation ( semeval-2016 ) , pages 1092–1102 , san diego , california , june 2016 . as- sociation for computational linguistics . [ keswani et al . , 2020 ] vishal keswani , sakshi singh , and ashutosh modi . iitk at the finsim task : hypernym de- tection in ﬁnancial domain via context - free and contextu- in proceedings of the second alized word embeddings . workshop on financial technology and natural language processing , pages 87–92 , kyoto , japan , 5 january 2020 . [ kobilarov et al . , 2009 ] georgi kobilarov , tom scott , yves raimond , silver oliver , chris sizemore , michael smethurst , christian bizer , and robert lee . media meets semantic web – how the bbc uses dbpedia and linked data to make connections . in lora aroyo , paolo traverso , fabio ciravegna , philipp cimiano , tom heath , eero hyv¨onen , riichiro mizoguchi , eyal oren , marta sabou , and elena simperl , editors , the semantic web : re- search and applications , pages 723–737 , berlin , heidel- berg , 2009 . springer berlin heidelberg . [ maarouf et al . , 2020 ] ismail el maarouf , youness mansar , virginie mouilleron , and dialekti valsamou - stanislawski . the finsim 2020 shared task : learning semantic repre- sentations for the ﬁnancial domain . in proceedings of the second workshop on financial technology and natural language processing , pages 81–86 , kyoto , japan , 5 jan- uary 2020 . [ mansar et al . , 2021 ] youness mansar , juyeon kang , and is- mail el maarouf . the finsim-2 2021 shared task : learn- ing semantic similarities for the financial domain , page 288–292 . association for computing machinery , new york , ny , usa , 2021 . [ mikolov et al . , 2013 ] tomas mikolov , kai chen , greg cor- rado , and jeffrey dean . efﬁcient estimation of word rep- resentations in vector space , 2013 . [ nguyen et al . , 2021 ] nhu khoa nguyen , emanuela boros , gael lejeune , antoine doucet , and thierry delahaut . l3i lbpam at the finsim-2 task : learning financial seman- tic similarities with siamese transformers , page 302–306 . association for computing machinery , new york , ny , usa , 2021 . \\n\\n\\x0c'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_Arx = \" \".join(Arx_lst)\n",
    "s_Arx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f90b1",
   "metadata": {},
   "source": [
    "# Cosin similarity\n",
    "source: https://www.machinelearningplus.com/nlp/cosine-similarity/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7ff3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8fb1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47edab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00002</th>\n",
       "      <th>086</th>\n",
       "      <th>10</th>\n",
       "      <th>104</th>\n",
       "      <th>1040</th>\n",
       "      <th>1050</th>\n",
       "      <th>107</th>\n",
       "      <th>1092</th>\n",
       "      <th>10th</th>\n",
       "      <th>110</th>\n",
       "      <th>...</th>\n",
       "      <th>ﬁgured</th>\n",
       "      <th>ﬁnal</th>\n",
       "      <th>ﬁnan</th>\n",
       "      <th>ﬁnancial</th>\n",
       "      <th>ﬁnd</th>\n",
       "      <th>ﬁne</th>\n",
       "      <th>ﬁned</th>\n",
       "      <th>ﬁnnlp2021</th>\n",
       "      <th>ﬁnsim</th>\n",
       "      <th>ﬁrst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_Arx</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_Anth</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1438 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          00002  086  10  104  1040  1050  107  1092  10th  110  ...  ﬁgured  \\\n",
       "doc_Arx       1    1   2    1     4     1    2     1     1    1  ...       1   \n",
       "doc_Anth      1    1   2    1     3     1    2     1     1    1  ...       1   \n",
       "\n",
       "          ﬁnal  ﬁnan  ﬁnancial  ﬁnd  ﬁne  ﬁned  ﬁnnlp2021  ﬁnsim  ﬁrst  \n",
       "doc_Arx      2     1        14    2   10     1          1      2     3  \n",
       "doc_Anth     2     2        13    2   10     1          1      2     3  \n",
       "\n",
       "[2 rows x 1438 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [s_Arx,s_Anth]\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer = CountVectorizer()\n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word frequencies.\n",
    "doc_term_matrix = sparse_matrix.todense()\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names(), \n",
    "                  index=['doc_Arx', 'doc_Anth'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90005ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cdb9d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99923514]\n",
      " [0.99923514 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(df, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a35a0d",
   "metadata": {},
   "source": [
    "5. Soft Cosine Similarity\n",
    "\n",
    "Suppose if you have another set of documents on a completely different topic, say ‘food’, you want a similarity metric that gives higher scores for documents belonging to the same topic and lower scores when comparing docs from different topics.\n",
    "\n",
    "In such case, we need to consider the semantic meaning should be considered.\n",
    "\n",
    "That is, words similar in meaning should be treated as similar.\n",
    "\n",
    "For Example, ‘President’ vs ‘Prime minister’, ‘Food’ vs ‘Dish’, ‘Hi’ vs ‘Hello’ should be considered similar.\n",
    "\n",
    "For this, converting the words into respective word vectors, and then, computing the similarities can address this problem.\n",
    "\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_scm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4a256f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\20193635\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dde2bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging.\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "801d0cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\20193635\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import and download stopwords from NLTK.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "download('stopwords')  # Download stopwords list.\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(sentence):\n",
    "    return [w for w in sentence.lower().split() if w not in stop_words]\n",
    "\n",
    "sentence_Arx = preprocess(s_Arx)\n",
    "sentence_Anth = preprocess(s_Anth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "249e7e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 16:27:00,867 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2022-05-04 16:27:00,880 : INFO : built Dictionary<1437 unique tokens: ['%', '&', '(', ')', ',']...> from 2 documents (total 8113 corpus positions)\n",
      "2022-05-04 16:27:00,881 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<1437 unique tokens: ['%', '&', '(', ')', ',']...> from 2 documents (total 8113 corpus positions)\", 'datetime': '2022-05-04T16:27:00.881662', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "2022-05-04 16:27:00,890 : INFO : collecting document frequencies\n",
      "2022-05-04 16:27:00,891 : INFO : PROGRESS: processing document #0\n",
      "2022-05-04 16:27:00,900 : INFO : TfidfModel lifecycle event {'msg': 'calculated IDF weights for 2 documents and 1437 features (2771 matrix non-zeros)', 'datetime': '2022-05-04T16:27:00.900828', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'initialize'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "documents = [sentence_Arx,sentence_Anth]\n",
    "dictionary = Dictionary(documents)\n",
    "\n",
    "sentence_Anth = dictionary.doc2bow(sentence_Anth)\n",
    "sentence_Arx = dictionary.doc2bow(sentence_Arx)\n",
    "# sentence_orange = dictionary.doc2bow(sentence_orange)\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "# documents = [sentence_obama, sentence_president, sentence_orange]\n",
    "documents = [sentence_Arx,sentence_Anth]\n",
    "tfidf = TfidfModel(documents)\n",
    "\n",
    "sentence_Anth = tfidf[sentence_Anth]\n",
    "sentence_Arx = tfidf[sentence_Arx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41521ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 16:27:01,487 : INFO : loading projection weights from C:\\Users\\20193635/gensim-data\\word2vec-google-news-300\\word2vec-google-news-300.gz\n",
      "2022-05-04 16:27:59,782 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from C:\\\\Users\\\\20193635/gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2022-05-04T16:27:59.782331', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'load_word2vec_format'}\n",
      "2022-05-04 16:27:59,790 : INFO : constructing a sparse term similarity matrix using WordEmbeddingSimilarityIndex<keyedvectors=KeyedVectors<vector_size=300, 3000000 keys>, threshold=0.0, exponent=2.0, kwargs={}>\n",
      "2022-05-04 16:27:59,832 : INFO : iterating over 1437 columns in tf-idf order\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1437/1437 [06:02<00:00,  3.96it/s]\n",
      "2022-05-04 16:34:02,385 : INFO : constructed a sparse term similarity matrix with 0.238018% density\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('word2vec-google-news-300')\n",
    "\n",
    "from gensim.similarities import SparseTermSimilarityMatrix, WordEmbeddingSimilarityIndex\n",
    "termsim_index = WordEmbeddingSimilarityIndex(model)\n",
    "termsim_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b95d4d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity = 0.0232\n"
     ]
    }
   ],
   "source": [
    "similarity = termsim_matrix.inner_product(sentence_Anth, sentence_Arx, normalized=(True, True))\n",
    "print('similarity = %.4f' % similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6547ad",
   "metadata": {},
   "source": [
    "# Spacy sentence encoding\n",
    "https://pypi.org/project/spacy-universal-sentence-encoder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31160cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy-universal-sentence-encoder in c:\\users\\20193635\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy-universal-sentence-encoder) (3.2.3)\n",
      "Requirement already satisfied: tensorflow<3.0.0,>=2.4.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy-universal-sentence-encoder) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-hub in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy-universal-sentence-encoder) (0.12.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (1.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (21.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (8.0.15)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (2.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (1.20.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (0.9.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (1.0.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (0.4.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (2.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (0.7.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (0.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (1.26.7)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (3.2.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.5.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.25.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.46.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (2.0)\n",
      "\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.1.2)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (14.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (3.20.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (2.6.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\20193635\\anaconda3\\lib\\site-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "pip install spacy-universal-sentence-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b9f76eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Op type not registered 'SentencepieceOp' in binary running on 20193635. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4176\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4177\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op_def_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4178\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SentencepieceOp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    973\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[0;32m    975\u001b[0m                             ckpt_options, options, filters)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    148\u001b[0m     self._concrete_functions = (\n\u001b[1;32m--> 149\u001b[1;33m         function_deserialization.load_function_def_library(\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0mlibrary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py\u001b[0m in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m       func_graph = function_def_lib.function_def_to_graph(\n\u001b[0m\u001b[0;32m    407\u001b[0m           \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes)\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shapes_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m   graph_def, nested_to_flat_tensor_name = function_def_to_graph_def(\n\u001b[0m\u001b[0;32m     71\u001b[0m       fdef, input_shapes)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph_def\u001b[1;34m(fdef, input_shapes)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m       \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_op_def\u001b[1;34m(self, type)\u001b[0m\n\u001b[0;32m   4180\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4181\u001b[1;33m         pywrap_tf_session.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type),\n\u001b[0m\u001b[0;32m   4182\u001b[0m                                            buf)\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Op type not registered 'SentencepieceOp' in binary running on 20193635. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13936/533641880.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy_universal_sentence_encoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy_universal_sentence_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xx_use_lg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy_universal_sentence_encoder\\util.py\u001b[0m in \u001b[0;36mcreate_lang\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Model \"{model_name}\" not available'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mselected_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'meta'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34mf'{model_name}.json'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy_universal_sentence_encoder\\language.py\u001b[0m in \u001b[0;36mcreate_nlp\u001b[1;34m(cfg, nlp)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspacy_base_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentencizer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'universal_sentence_encoder'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'use_model_url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0muse_model_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'preprocessor_url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpreprocessor_url\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m                     \u001b[0mlang_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 )\n\u001b[1;32m--> 792\u001b[1;33m             pipe_component = self.create_pipe(\n\u001b[0m\u001b[0;32m    793\u001b[0m                 \u001b[0mfactory_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mcreate_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# We're calling the internal _fill here to avoid constructing the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;31m# registered functions twice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mresolved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"cfg\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cfg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mfilled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(cls, config, schema, overrides, validate)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m     ) -> Dict[str, Any]:\n\u001b[1;32m--> 746\u001b[1;33m         resolved, _ = cls._make(\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36m_make\u001b[1;34m(cls, config, schema, overrides, resolve, validate)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_interpolated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m         filled, _, resolved = cls._fill(\n\u001b[0m\u001b[0;32m    796\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolve\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\thinc\\config.py\u001b[0m in \u001b[0;36m_fill\u001b[1;34m(cls, config, schema, validate, resolve, parent, overrides)\u001b[0m\n\u001b[0;32m    865\u001b[0m                     \u001b[1;31m# We don't want to try/except this and raise our own error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                     \u001b[1;31m# here, because we want the traceback if the function fails.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                     \u001b[0mgetter_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[1;31m# We're not resolving and calling the function, so replace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy_universal_sentence_encoder\\language.py\u001b[0m in \u001b[0;36muse_model_factory\u001b[1;34m(nlp, name, use_model_url, preprocessor_url, model_name, enable_cache, debug)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUniversalSentenceEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessor_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy_universal_sentence_encoder\\language.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_url, preprocessor_url, enable_cache, debug)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# load it now so that when the extension getter will call it, the model will be already loaded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUniversalSentenceEncoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessor_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy_universal_sentence_encoder\\language.py\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(use_model_url, preprocessor_url, enable_cache, debug)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;31m# print('model not in cache')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFHubWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_model_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessor_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menable_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m             \u001b[0mUniversalSentenceEncoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muse_model_url\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy_universal_sentence_encoder\\language.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, use_model_url, preprocessor_url, enable_cache, debug)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;31m# show download info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TFHUB_DOWNLOAD_PROGRESS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Impossible to load model with use_model_url={use_model_url}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m   \"\"\"\n\u001b[1;32m--> 936\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    975\u001b[0m                             ckpt_options, options, filters)\n\u001b[0;32m    976\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m         raise FileNotFoundError(\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n You may be trying to load on a different device \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[1;34m\"from the computational device. Consider setting the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Op type not registered 'SentencepieceOp' in binary running on 20193635. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "# import spacy_universal_sentence_encoder\n",
    "# nlp = spacy_universal_sentence_encoder.load_model('xx_use_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "141f26ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_universal_sentence_encoder.language.UniversalSentenceEncoder at 0x141839bc6a0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# this is your nlp object that can be any spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# add the pipeline stage (will be mapped to the most adequate model from the table above, en_use_md)\n",
    "nlp.add_pipe('universal_sentence_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b365f93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "(512,)\n",
      "how (512,)\n",
      "how are you (512,)\n",
      "0.9739387183187921\n"
     ]
    }
   ],
   "source": [
    "# load as before\n",
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_lg\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe('universal_sentence_encoder')\n",
    "\n",
    "# get two documents\n",
    "doc_1 = nlp('Hi there, how are you?')\n",
    "doc_2 = nlp('Hello there, how are you doing today?')\n",
    "# Inspect the shape of the Doc, Span and Token vectors\n",
    "print(doc_1.vector.shape) # the full document representation\n",
    "print(doc_1[3], doc_1[3].vector.shape) # the word \"how\"\n",
    "print(doc_1[3:6], doc_1[3:6].vector.shape) # the span \"how are you\"\n",
    "\n",
    "# or use the similarity method that is based on the vectors, on Doc, Span or Token\n",
    "print(doc_1.similarity(doc_2[0:7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c55fb463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "finbert (512,)\n",
      "finbert ﬁne - (512,)\n",
      "0.04908928937826832\n"
     ]
    }
   ],
   "source": [
    "doc_1 = nlp(s_Anth)\n",
    "doc_2 = nlp(s_Arx)\n",
    "# Inspect the shape of the Doc, Span and Token vectors\n",
    "print(doc_1.vector.shape) # the full document representation\n",
    "print(doc_1[3], doc_1[3].vector.shape) # the word \"how\"\n",
    "print(doc_1[3:6], doc_1[3:6].vector.shape) # the span \"how are you\"\n",
    "\n",
    "# or use the similarity method that is based on the vectors, on Doc, Span or Token\n",
    "print(doc_1.similarity(doc_2[0:7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea8c7cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9996117206695805\n"
     ]
    }
   ],
   "source": [
    "print(doc_1.similarity(doc_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78b29c",
   "metadata": {},
   "source": [
    "# Good site\n",
    "https://blog.floydhub.com/when-the-best-nlp-model-is-not-the-best-choice/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b7ea1",
   "metadata": {},
   "source": [
    "# Paper BEP\n",
    "universal sentence encoding\n",
    "\n",
    "\n",
    "Sentence: https://arxiv.org/abs/1803.11175\n",
    "\n",
    "\n",
    "https://tfhub.dev/google/universal-sentence-encoder/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8e43cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.03133016 -0.06338632 -0.01607501 ... -0.03242781 -0.04575741\n",
      "   0.05370456]\n",
      " [ 0.05080862 -0.01652432  0.01573779 ...  0.00976659  0.0317012\n",
      "   0.01788118]], shape=(2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed([\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\"])\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac08eb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's_Anth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7260/331206032.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms_Anth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_Arx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's_Anth' is not defined"
     ]
    }
   ],
   "source": [
    "# import tensorflow_hub as hub\n",
    "\n",
    "# embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed([s_Anth, s_Arx])\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894890d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(embeddings, embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca337c8",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75a8ebf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba4e187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d64b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6df653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
